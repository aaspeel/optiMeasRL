{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"#\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/antoine/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/antoine/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/antoine/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/antoine/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/antoine/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/antoine/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import estimator class\n",
    "from estimators.rnnEstimator import RnnEstimator\n",
    "from estimators.kalmanEstimator import KalmanEstimator\n",
    "\n",
    "#import rewarder class\n",
    "from rewarders.thresholdRewarder import ThresholdRewarder\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from utils.sequences_treatment import *\n",
    "from utils.agent_treatment import *\n",
    "\n",
    "# import functions from Keras for the RNN\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, SimpleRNN#, Dropout, Embedding, Masking, Bidirectional\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "estimatorType='rnn' # kalman or rnn\n",
    "seeAction=True\n",
    "seeMeasurement=False\n",
    "seeEstimate=False\n",
    "T=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/antoine/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 20)          1760      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 20)          3280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1)           21        \n",
      "=================================================================\n",
      "Total params: 5,061\n",
      "Trainable params: 5,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/antoine/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      " - 37s - loss: 0.0857 - val_loss: 0.0501\n",
      "Epoch 2/5\n",
      " - 34s - loss: 0.0327 - val_loss: 0.0271\n",
      "Epoch 3/5\n",
      " - 33s - loss: 0.0271 - val_loss: 0.0251\n",
      "Epoch 4/5\n",
      " - 37s - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 5/5\n",
      " - 33s - loss: 0.0254 - val_loss: 0.0244\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "if estimatorType=='rnn':\n",
    "    # construct and train a Sequential RNN model with keras\n",
    "    numberSamples_trainRNN=1000\n",
    "    T_trainRNN=T\n",
    "    generatorType='random01'\n",
    "\n",
    "    # generate sequences for training\n",
    "    (objectives_trainRNN,measurements_trainRNN)=generateSequence(T_trainRNN,numberSamples=numberSamples_trainRNN,generatorType=generatorType)\n",
    "    sigmas_trainRNN=randomSigma(T_trainRNN,numberSamples=numberSamples_trainRNN,p0=0.3)\n",
    "    measurements_corrupted_trainRNN=corruptSequence_outOfRange(measurements_trainRNN,sigmas_trainRNN)\n",
    "\n",
    "    n_dim_meas=np.shape(measurements_corrupted_trainRNN)[2]\n",
    "    n_dim_obj=np.shape(objectives_trainRNN)[2]\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(20,input_shape=(None,n_dim_meas),return_sequences=True))\n",
    "    model.add(LSTM(20,return_sequences=True))\n",
    "    model.add(Dense(n_dim_obj,activation=None))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    model.summary()\n",
    "\n",
    "    # train the RNN\n",
    "    history=model.fit(x=measurements_corrupted_trainRNN,y=objectives_trainRNN,batch_size=1,epochs=5,validation_split=0.2,verbose=2)\n",
    "\n",
    "    # plot loss\n",
    "    plotRNNresults(history)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "if estimatorType=='rnn':\n",
    "    idx_sample=0\n",
    "    estimates_trainRNN=model.predict(measurements_corrupted_trainRNN[idx_sample:(idx_sample+1),:,:])\n",
    "    plotErrors(objectives_trainRNN, estimates_trainRNN, sigmas_trainRNN,idx_sample=idx_sample)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN estimator\n",
      "observationsDimensions: [(5,)]\n",
      "seeAction= True\n",
      "seeMeasurement= False\n",
      "seeEstimate= False\n",
      "threshold rewarder\n",
      "window size: 4\n",
      "threshold: 2\n",
      "cost: 5000\n",
      "number of measures in the window: 0\n"
     ]
    }
   ],
   "source": [
    "# construct estimator\n",
    "if estimatorType=='rnn':\n",
    "    estimator=RnnEstimator(model,generatorType,seeAction=seeAction,seeMeasurement=seeMeasurement,seeEstimate=seeEstimate)\n",
    "elif estimatorType=='kalman':\n",
    "    estimator=KalmanEstimator(seeAction=seeAction,seeMeasurement=seeMeasurement,seeEstimate=seeEstimate)\n",
    "else:\n",
    "    print('ERROR: no valid estimatorType')\n",
    "    \n",
    "estimator.summarize()\n",
    "\n",
    "# contruct rewarder\n",
    "rewarder=ThresholdRewarder(threshold=2, cost=5000, windowSize=4)\n",
    "rewarder.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape objectives: (100, 12, 1)\n",
      "shape measurements: (100, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "# generate sequences for training the agent\n",
    "numberSamples_trainAgent=100\n",
    "T_trainAgent=T\n",
    "\n",
    "(objectives_trainAgent,measurements_trainAgent)=estimator.generateSequence(T_trainAgent,numberSamples=numberSamples_trainAgent)\n",
    "\n",
    "print('shape objectives:',np.shape(objectives_trainAgent))\n",
    "print('shape measurements:',np.shape(measurements_trainAgent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment parameters\n",
      "  REWARDER= <rewarders.thresholdRewarder.ThresholdRewarder object at 0xb377617b8>\n",
      "  inputDimensions= [(5,)]\n",
      "Sequences parameters\n",
      "  outOfRangeValue= -1\n",
      "  numerSamples= 100\n",
      "  n_dim_obj= 1\n",
      "  n_dim_meas= 1\n",
      "Agent constructed\n"
     ]
    }
   ],
   "source": [
    "# construct agent\n",
    "agent=constructAgent(estimator,rewarder,objectives_trainAgent,measurements_trainAgent)\n",
    "print('Agent constructed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 1894.0648193359375\n",
      "Episode average V value: -0.04817802831530571\n",
      "Average (on the epoch) training loss: 2569.172119140625\n",
      "Episode average V value: -2.4834455139935017\n",
      "Average (on the epoch) training loss: 2412.01025390625\n",
      "Episode average V value: -23.68320655822754\n",
      "Average (on the epoch) training loss: 2203.93115234375\n",
      "Episode average V value: -86.18897088368733\n",
      "Average (on the epoch) training loss: 2037.0311279296875\n",
      "Episode average V value: -232.08731079101562\n",
      "Average (on the epoch) training loss: 1878.819580078125\n",
      "Episode average V value: -492.8666159889915\n",
      "Average (on the epoch) training loss: 1731.111572265625\n",
      "Episode average V value: -700.81201171875\n",
      "Average (on the epoch) training loss: 1610.58056640625\n",
      "Episode average V value: -576.2876841227213\n",
      "Average (on the epoch) training loss: 1507.876953125\n",
      "Episode average V value: -604.478515625\n",
      "Average (on the epoch) training loss: 1409.14013671875\n",
      "Episode average V value: -436.6860605875651\n",
      "Average (on the epoch) training loss: 1323.7862548828125\n",
      "Episode average V value: -485.1011962890625\n",
      "Average (on the epoch) training loss: 1243.936767578125\n",
      "Episode average V value: -298.3747253417969\n",
      "Average (on the epoch) training loss: 1172.5399169921875\n",
      "Episode average V value: -167.46875762939453\n",
      "Average (on the epoch) training loss: 1111.3968505859375\n",
      "Episode average V value: -77.70330047607422\n",
      "Average (on the epoch) training loss: 1055.7056884765625\n",
      "Episode average V value: -11.66901683807373\n",
      "Average (on the epoch) training loss: 1002.4929809570312\n",
      "Episode average V value: -356.18544743955135\n",
      "Average (on the epoch) training loss: 959.7327270507812\n",
      "Episode average V value: -580.1379770636559\n",
      "Average (on the epoch) training loss: 922.1834716796875\n",
      "Episode average V value: -577.3810424804688\n",
      "Average (on the epoch) training loss: 886.3016357421875\n",
      "Episode average V value: -473.9461364746094\n",
      "Average (on the epoch) training loss: 854.0765991210938\n",
      "Episode average V value: -191.86610412597656\n",
      "Average (on the epoch) training loss: 825.07421875\n",
      "Episode average V value: 1.3895766735076904\n",
      "Average (on the epoch) training loss: 794.8341064453125\n",
      "Episode average V value: -205.148779630661\n",
      "Average (on the epoch) training loss: 769.5953979492188\n",
      "Episode average V value: -44.22665786743164\n",
      "Average (on the epoch) training loss: 745.2630615234375\n",
      "Episode average V value: -170.7958526611328\n",
      "Average (on the epoch) training loss: 723.7442016601562\n",
      "Episode average V value: 1.9824579854806264\n",
      "Average (on the epoch) training loss: 703.2053833007812\n",
      "Episode average V value: 0.49879956245422363\n",
      "Average (on the epoch) training loss: 684.8448486328125\n",
      "Episode average V value: 0.25018925016576593\n",
      "Average (on the epoch) training loss: 666.3029174804688\n",
      "Episode average V value: -81.33464833552188\n",
      "Average (on the epoch) training loss: 647.7091674804688\n",
      "Episode average V value: -156.65728759765625\n",
      "Average (on the epoch) training loss: 632.506103515625\n",
      "Episode average V value: 0.9077480932076772\n",
      "Average (on the epoch) training loss: 617.0321044921875\n",
      "Episode average V value: -134.2307891845703\n",
      "Average (on the epoch) training loss: 600.9435424804688\n",
      "Episode average V value: -108.12091802805662\n",
      "Average (on the epoch) training loss: 586.0984497070312\n",
      "Episode average V value: 3.541172981262207\n",
      "Average (on the epoch) training loss: 574.4483642578125\n",
      "Episode average V value: 3.2858591874440513\n",
      "Average (on the epoch) training loss: 560.85107421875\n",
      "Episode average V value: 2.9665544033050537\n",
      "Average (on the epoch) training loss: 549.1148071289062\n",
      "Episode average V value: -60.20695501565933\n",
      "Average (on the epoch) training loss: 536.8980102539062\n",
      "Episode average V value: -30.47079184922305\n",
      "Average (on the epoch) training loss: 524.789306640625\n",
      "Episode average V value: -133.07333244518802\n",
      "Average (on the epoch) training loss: 514.3916625976562\n",
      "Episode average V value: -287.1286926269531\n",
      "Average (on the epoch) training loss: 504.8027648925781\n",
      "Episode average V value: -15.309253717462221\n",
      "Average (on the epoch) training loss: 495.8883361816406\n",
      "Episode average V value: -327.5785217285156\n",
      "Average (on the epoch) training loss: 488.0890197753906\n",
      "Episode average V value: -542.8638565093279\n",
      "Average (on the epoch) training loss: 480.4444885253906\n",
      "Episode average V value: -202.8391352792581\n",
      "Average (on the epoch) training loss: 472.9502868652344\n",
      "Episode average V value: 17.839445114135742\n",
      "Average (on the epoch) training loss: 466.87188720703125\n",
      "Episode average V value: -206.11923217773438\n",
      "Average (on the epoch) training loss: 458.35467529296875\n",
      "Episode average V value: -446.4201466143131\n",
      "Average (on the epoch) training loss: 451.4935607910156\n",
      "Episode average V value: -283.5815213918686\n",
      "Average (on the epoch) training loss: 446.4308166503906\n",
      "Episode average V value: -280.094482421875\n",
      "Average (on the epoch) training loss: 441.7454833984375\n",
      "Episode average V value: -187.292236328125\n",
      "Average (on the epoch) training loss: 436.12152099609375\n",
      "Episode average V value: 53.778584043184914\n",
      "Average (on the epoch) training loss: 431.280029296875\n",
      "Episode average V value: 57.157772064208984\n",
      "Average (on the epoch) training loss: 426.28790283203125\n",
      "Episode average V value: -115.30583915114403\n",
      "Average (on the epoch) training loss: 420.3475036621094\n",
      "Episode average V value: -225.9243207971255\n",
      "Average (on the epoch) training loss: 416.6286926269531\n",
      "Episode average V value: -163.55813817183176\n",
      "Average (on the epoch) training loss: 411.63311767578125\n",
      "Episode average V value: -265.5387878417969\n",
      "Average (on the epoch) training loss: 406.8034973144531\n",
      "Episode average V value: -174.2532196044922\n",
      "Average (on the epoch) training loss: 401.6741638183594\n",
      "Episode average V value: -137.01966857910156\n",
      "Average (on the epoch) training loss: 396.797119140625\n",
      "Episode average V value: -114.88279370466869\n",
      "Average (on the epoch) training loss: 393.3230895996094\n",
      "Episode average V value: -131.87186008691788\n",
      "Average (on the epoch) training loss: 388.4288330078125\n",
      "Episode average V value: 31.4708251953125\n",
      "Average (on the epoch) training loss: 383.25701904296875\n",
      "Episode average V value: -100.8869393914938\n",
      "Average (on the epoch) training loss: 378.6352233886719\n",
      "Episode average V value: 60.12381070355574\n",
      "Average (on the epoch) training loss: 374.1610412597656\n",
      "Episode average V value: 27.126511611044407\n",
      "Average (on the epoch) training loss: 369.630859375\n",
      "Episode average V value: 41.48295911153158\n",
      "Average (on the epoch) training loss: 365.0077819824219\n",
      "Episode average V value: 28.285304188728333\n",
      "Average (on the epoch) training loss: 360.1693420410156\n",
      "Episode average V value: 34.21880332628886\n",
      "Average (on the epoch) training loss: 356.08734130859375\n",
      "Episode average V value: -244.83209896087646\n",
      "Average (on the epoch) training loss: 352.52154541015625\n",
      "Episode average V value: -193.83309361067685\n",
      "Average (on the epoch) training loss: 348.71356201171875\n",
      "Episode average V value: 29.467979431152344\n",
      "Average (on the epoch) training loss: 345.40362548828125\n",
      "Episode average V value: 24.38783351580302\n",
      "Average (on the epoch) training loss: 342.1104736328125\n",
      "Episode average V value: 24.050569529334705\n",
      "Average (on the epoch) training loss: 339.3903503417969\n",
      "Episode average V value: 15.0649094581604\n",
      "Average (on the epoch) training loss: 337.0421447753906\n",
      "Episode average V value: 34.33136363824209\n",
      "Average (on the epoch) training loss: 334.6201171875\n",
      "Episode average V value: 20.71349334716797\n",
      "Average (on the epoch) training loss: 331.924560546875\n",
      "Episode average V value: 21.179773330688477\n",
      "Average (on the epoch) training loss: 328.9848937988281\n",
      "Episode average V value: -52.2902934551239\n",
      "Average (on the epoch) training loss: 326.2012634277344\n",
      "Episode average V value: -109.37630202372868\n",
      "Average (on the epoch) training loss: 323.8149108886719\n",
      "Episode average V value: 42.47679138183594\n",
      "Average (on the epoch) training loss: 321.13739013671875\n",
      "Episode average V value: 11.090342422326406\n",
      "Average (on the epoch) training loss: 319.1459045410156\n",
      "Episode average V value: 62.919551849365234\n",
      "Average (on the epoch) training loss: 317.4865417480469\n",
      "Episode average V value: 26.63393039504687\n",
      "Average (on the epoch) training loss: 314.7383117675781\n",
      "Episode average V value: 28.481544754721902\n",
      "Average (on the epoch) training loss: 311.8210144042969\n",
      "Episode average V value: 23.95659100015958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 309.2987976074219\n",
      "Episode average V value: -1.5978328635295231\n",
      "Average (on the epoch) training loss: 307.7052917480469\n",
      "Episode average V value: 1.3474353551864624\n",
      "Average (on the epoch) training loss: 306.14630126953125\n",
      "Episode average V value: 7.650452574094136\n",
      "Average (on the epoch) training loss: 304.7248840332031\n",
      "Episode average V value: 41.31606674194336\n",
      "Average (on the epoch) training loss: 303.37371826171875\n",
      "Episode average V value: -56.52460296948751\n",
      "Average (on the epoch) training loss: 301.7394714355469\n",
      "Episode average V value: 70.5066146850586\n",
      "Average (on the epoch) training loss: 300.8164978027344\n",
      "Episode average V value: 60.640132904052734\n",
      "Average (on the epoch) training loss: 298.80133056640625\n",
      "Episode average V value: 61.522409200668335\n",
      "Average (on the epoch) training loss: 296.5032653808594\n",
      "Episode average V value: 43.18218994140625\n",
      "Average (on the epoch) training loss: 294.8331604003906\n",
      "Episode average V value: 35.1674690246582\n",
      "Average (on the epoch) training loss: 293.1590270996094\n",
      "Episode average V value: 46.772372563680015\n",
      "Average (on the epoch) training loss: 291.9469299316406\n",
      "Episode average V value: 45.81028397878011\n",
      "Average (on the epoch) training loss: 289.759765625\n",
      "Episode average V value: -17.008194148540497\n",
      "Average (on the epoch) training loss: 287.8507080078125\n",
      "Episode average V value: 33.43270492553711\n",
      "Average (on the epoch) training loss: 287.00628662109375\n",
      "Episode average V value: 20.362301349639893\n",
      "Average (on the epoch) training loss: 285.1535339355469\n",
      "Episode average V value: 12.541136741638184\n",
      "Average (on the epoch) training loss: 283.6417236328125\n",
      "Episode average V value: 45.66231667498747\n",
      "epoch 1:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "epoch 2:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 123.94588470458984\n",
      "Episode average V value: 23.07525572180748\n",
      "Average (on the epoch) training loss: 119.7742919921875\n",
      "Episode average V value: 14.320552984873453\n",
      "Average (on the epoch) training loss: 124.96322631835938\n",
      "Episode average V value: 6.308873703082402\n",
      "Average (on the epoch) training loss: 115.35162353515625\n",
      "Episode average V value: 5.478231048583984\n",
      "Average (on the epoch) training loss: 109.7686538696289\n",
      "Episode average V value: 20.677825301885605\n",
      "Average (on the epoch) training loss: 112.00465393066406\n",
      "Episode average V value: 11.79224157333374\n",
      "Average (on the epoch) training loss: 114.66082763671875\n",
      "Episode average V value: 8.19753360748291\n",
      "Average (on the epoch) training loss: 110.14501190185547\n",
      "Episode average V value: -13.877830982208252\n",
      "Average (on the epoch) training loss: 110.64395141601562\n",
      "Episode average V value: 20.465850830078125\n",
      "Average (on the epoch) training loss: 110.33097076416016\n",
      "Episode average V value: 29.55691496892409\n",
      "Average (on the epoch) training loss: 113.14785766601562\n",
      "Episode average V value: 12.523943402550437\n",
      "Average (on the epoch) training loss: 111.68984985351562\n",
      "Episode average V value: 9.461984634399414\n",
      "Average (on the epoch) training loss: 109.35894775390625\n",
      "Episode average V value: 23.044214248657227\n",
      "Average (on the epoch) training loss: 107.51434326171875\n",
      "Episode average V value: 25.723052978515625\n",
      "Average (on the epoch) training loss: 107.68783569335938\n",
      "Episode average V value: 9.593443463246027\n",
      "Average (on the epoch) training loss: 110.3650131225586\n",
      "Episode average V value: 15.389330863952637\n",
      "Average (on the epoch) training loss: 109.7099380493164\n",
      "Episode average V value: -114.68595377604167\n",
      "Average (on the epoch) training loss: 107.55023956298828\n",
      "Episode average V value: 19.74326252937317\n",
      "Average (on the epoch) training loss: 107.55545806884766\n",
      "Episode average V value: 11.91990840435028\n",
      "Average (on the epoch) training loss: 108.01251983642578\n",
      "Episode average V value: -105.16347980499268\n",
      "Average (on the epoch) training loss: 109.40843963623047\n",
      "Episode average V value: 20.493391041954357\n",
      "Average (on the epoch) training loss: 109.79339599609375\n",
      "Episode average V value: 28.48585319519043\n",
      "Average (on the epoch) training loss: 110.01557159423828\n",
      "Episode average V value: 14.934221784273783\n",
      "Average (on the epoch) training loss: 107.66543579101562\n",
      "Episode average V value: 16.78266171614329\n",
      "Average (on the epoch) training loss: 108.73307800292969\n",
      "Episode average V value: 22.103708838423092\n",
      "Average (on the epoch) training loss: 108.14949798583984\n",
      "Episode average V value: 20.946184158325195\n",
      "Average (on the epoch) training loss: 106.3653564453125\n",
      "Episode average V value: 19.90297508239746\n",
      "Average (on the epoch) training loss: 105.58526611328125\n",
      "Episode average V value: 24.576589584350586\n",
      "Average (on the epoch) training loss: 107.44340515136719\n",
      "Episode average V value: 11.703407287597656\n",
      "Average (on the epoch) training loss: 107.5820083618164\n",
      "Episode average V value: -11.128998160362244\n",
      "Average (on the epoch) training loss: 106.2500228881836\n",
      "Episode average V value: 15.712756156921387\n",
      "Average (on the epoch) training loss: 106.89120483398438\n",
      "Episode average V value: 9.606471061706543\n",
      "Average (on the epoch) training loss: 106.59791564941406\n",
      "Episode average V value: -35.19177916646004\n",
      "Average (on the epoch) training loss: 105.7596664428711\n",
      "Episode average V value: 16.87467384338379\n",
      "Average (on the epoch) training loss: 106.7465591430664\n",
      "Episode average V value: 9.210170725981394\n",
      "Average (on the epoch) training loss: 105.44374084472656\n",
      "Episode average V value: 9.355065782864889\n",
      "Average (on the epoch) training loss: 103.94119262695312\n",
      "Episode average V value: 21.903262436389923\n",
      "Average (on the epoch) training loss: 104.0391616821289\n",
      "Episode average V value: -19.760881900787354\n",
      "Average (on the epoch) training loss: 103.89998626708984\n",
      "Episode average V value: 21.20538381735484\n",
      "Average (on the epoch) training loss: 102.99879455566406\n",
      "Episode average V value: 17.67248598734538\n",
      "Average (on the epoch) training loss: 103.05197143554688\n",
      "Episode average V value: 16.347201188405354\n",
      "Average (on the epoch) training loss: 103.7965087890625\n",
      "Episode average V value: 4.7987024784088135\n",
      "Average (on the epoch) training loss: 103.02437591552734\n",
      "Episode average V value: -34.61486895517869\n",
      "Average (on the epoch) training loss: 102.6671371459961\n",
      "Episode average V value: -13.815027583729137\n",
      "Average (on the epoch) training loss: 102.07754516601562\n",
      "Episode average V value: 22.713934024175007\n",
      "Average (on the epoch) training loss: 101.38499450683594\n",
      "Episode average V value: 22.157741864522297\n",
      "Average (on the epoch) training loss: 100.25698852539062\n",
      "Episode average V value: 7.772075815634294\n",
      "Average (on the epoch) training loss: 98.94583892822266\n",
      "Episode average V value: 9.966279073195023\n",
      "Average (on the epoch) training loss: 97.88880920410156\n",
      "Episode average V value: 5.206191390752792\n",
      "Average (on the epoch) training loss: 96.62963104248047\n",
      "Episode average V value: 26.123354613780975\n",
      "Average (on the epoch) training loss: 96.42747497558594\n",
      "Episode average V value: 11.286881446838379\n",
      "Average (on the epoch) training loss: 95.82564544677734\n",
      "Episode average V value: 13.11618336764249\n",
      "Average (on the epoch) training loss: 95.5315170288086\n",
      "Episode average V value: 0.5330390496687456\n",
      "Average (on the epoch) training loss: 95.24972534179688\n",
      "Episode average V value: -103.30085468292236\n",
      "Average (on the epoch) training loss: 95.585205078125\n",
      "Episode average V value: 18.64607012271881\n",
      "Average (on the epoch) training loss: 95.71118927001953\n",
      "Episode average V value: 14.302696108818054\n",
      "Average (on the epoch) training loss: 95.04373931884766\n",
      "Episode average V value: 15.589326520760855\n",
      "Average (on the epoch) training loss: 94.95514678955078\n",
      "Episode average V value: 18.751077612241108\n",
      "Average (on the epoch) training loss: 94.8471450805664\n",
      "Episode average V value: 14.742480278015137\n",
      "Average (on the epoch) training loss: 94.50164794921875\n",
      "Episode average V value: 9.376219312349955\n",
      "Average (on the epoch) training loss: 93.74248504638672\n",
      "Episode average V value: 18.439749836921692\n",
      "Average (on the epoch) training loss: 92.98950958251953\n",
      "Episode average V value: 8.291509409745535\n",
      "Average (on the epoch) training loss: 92.68338775634766\n",
      "Episode average V value: 27.03586768110593\n",
      "Average (on the epoch) training loss: 92.64136505126953\n",
      "Episode average V value: 13.305886268615723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 92.86668395996094\n",
      "Episode average V value: 19.303570573980156\n",
      "Average (on the epoch) training loss: 92.72872161865234\n",
      "Episode average V value: 11.674999809265136\n",
      "Average (on the epoch) training loss: 92.44747161865234\n",
      "Episode average V value: 2.86453777551651\n",
      "Average (on the epoch) training loss: 92.29581451416016\n",
      "Episode average V value: 9.749298969904581\n",
      "Average (on the epoch) training loss: 92.32879638671875\n",
      "Episode average V value: 26.89851188659668\n",
      "Average (on the epoch) training loss: 92.35049438476562\n",
      "Episode average V value: 29.575711647669475\n",
      "Average (on the epoch) training loss: 91.882080078125\n",
      "Episode average V value: 35.67307662963867\n",
      "Average (on the epoch) training loss: 91.56815338134766\n",
      "Episode average V value: 27.747344970703125\n",
      "Average (on the epoch) training loss: 91.65155792236328\n",
      "Episode average V value: 24.160741806030273\n",
      "Average (on the epoch) training loss: 91.14521789550781\n",
      "Episode average V value: 30.99127821488814\n",
      "Average (on the epoch) training loss: 90.61090850830078\n",
      "Episode average V value: 15.581653873125711\n",
      "Average (on the epoch) training loss: 90.25035858154297\n",
      "Episode average V value: 41.3145112991333\n",
      "Average (on the epoch) training loss: 89.65271759033203\n",
      "Episode average V value: 49.94765090942383\n",
      "Average (on the epoch) training loss: 89.14118194580078\n",
      "Episode average V value: 18.8316654364268\n",
      "Average (on the epoch) training loss: 88.87642669677734\n",
      "Episode average V value: 26.73033881187439\n",
      "Average (on the epoch) training loss: 89.10108184814453\n",
      "Episode average V value: 54.159759521484375\n",
      "Average (on the epoch) training loss: 89.01888275146484\n",
      "Episode average V value: 32.337890625\n",
      "Average (on the epoch) training loss: 88.33264923095703\n",
      "Episode average V value: 23.7883243560791\n",
      "Average (on the epoch) training loss: 88.06720733642578\n",
      "Episode average V value: 32.66807520389557\n",
      "Average (on the epoch) training loss: 88.06069946289062\n",
      "Episode average V value: 22.874359260905873\n",
      "Average (on the epoch) training loss: 87.8526840209961\n",
      "Episode average V value: 25.1945583820343\n",
      "Average (on the epoch) training loss: 87.32733917236328\n",
      "Episode average V value: 17.727920214335125\n",
      "Average (on the epoch) training loss: 87.33050537109375\n",
      "Episode average V value: 43.4327392578125\n",
      "Average (on the epoch) training loss: 86.83631896972656\n",
      "Episode average V value: 33.71357345581055\n",
      "Average (on the epoch) training loss: 87.22106170654297\n",
      "Episode average V value: 8.325397431850433\n",
      "Average (on the epoch) training loss: 86.95452117919922\n",
      "Episode average V value: -32.639169389551334\n",
      "Average (on the epoch) training loss: 86.5394515991211\n",
      "Episode average V value: 44.27870527903239\n",
      "Average (on the epoch) training loss: 86.6285629272461\n",
      "Episode average V value: 29.006019592285156\n",
      "Average (on the epoch) training loss: 86.0871353149414\n",
      "Episode average V value: 30.268597920735676\n",
      "Average (on the epoch) training loss: 85.52906799316406\n",
      "Episode average V value: 31.120695382356644\n",
      "Average (on the epoch) training loss: 85.6718521118164\n",
      "Episode average V value: 31.596609433492024\n",
      "Average (on the epoch) training loss: 85.0270004272461\n",
      "Episode average V value: 28.030627955993015\n",
      "Average (on the epoch) training loss: 84.44645690917969\n",
      "Episode average V value: 36.95855712890625\n",
      "Average (on the epoch) training loss: 84.59583282470703\n",
      "Episode average V value: 36.04199616114298\n",
      "Average (on the epoch) training loss: 83.99855041503906\n",
      "Episode average V value: 21.171478271484375\n",
      "Average (on the epoch) training loss: 83.82689666748047\n",
      "Episode average V value: 40.00815200805664\n",
      "epoch 3:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 89.78246307373047\n",
      "Episode average V value: -22.936454599553887\n",
      "Average (on the epoch) training loss: 81.29163360595703\n",
      "Episode average V value: 35.820664723714195\n",
      "Average (on the epoch) training loss: 81.46014404296875\n",
      "Episode average V value: 33.081600189208984\n",
      "Average (on the epoch) training loss: 77.8341293334961\n",
      "Episode average V value: 44.38739013671875\n",
      "Average (on the epoch) training loss: 67.05474853515625\n",
      "Episode average V value: 19.46418297290802\n",
      "Average (on the epoch) training loss: 60.13057327270508\n",
      "Episode average V value: 30.715652465820312\n",
      "Average (on the epoch) training loss: 58.070068359375\n",
      "Episode average V value: 19.262001832326252\n",
      "Average (on the epoch) training loss: 63.93092727661133\n",
      "Episode average V value: 39.89467950300737\n",
      "Average (on the epoch) training loss: 59.92417526245117\n",
      "Episode average V value: -3.0521818101406097\n",
      "Average (on the epoch) training loss: 61.854515075683594\n",
      "Episode average V value: 31.764193455378216\n",
      "Average (on the epoch) training loss: 62.40519332885742\n",
      "Episode average V value: 35.064938285134055\n",
      "Average (on the epoch) training loss: 62.21793746948242\n",
      "Episode average V value: 45.28317920366923\n",
      "Average (on the epoch) training loss: 60.59406280517578\n",
      "Episode average V value: 33.83380126953125\n",
      "Average (on the epoch) training loss: 61.45143508911133\n",
      "Episode average V value: 6.21509313583374\n",
      "Average (on the epoch) training loss: 60.8339958190918\n",
      "Episode average V value: 38.76363754272461\n",
      "Average (on the epoch) training loss: 62.65583801269531\n",
      "Episode average V value: 62.42903137207031\n",
      "Average (on the epoch) training loss: 64.57828521728516\n",
      "Episode average V value: 32.88989266482267\n",
      "Average (on the epoch) training loss: 64.56780242919922\n",
      "Episode average V value: -320.3196016550064\n",
      "Average (on the epoch) training loss: 68.13589477539062\n",
      "Episode average V value: 25.399566729863484\n",
      "Average (on the epoch) training loss: 67.14704132080078\n",
      "Episode average V value: 26.529255668322246\n",
      "Average (on the epoch) training loss: 67.27749633789062\n",
      "Episode average V value: 29.90849733352661\n",
      "Average (on the epoch) training loss: 69.32896423339844\n",
      "Episode average V value: 32.15720748901367\n",
      "Average (on the epoch) training loss: 68.42385864257812\n",
      "Episode average V value: 31.73373293876648\n",
      "Average (on the epoch) training loss: 67.53662109375\n",
      "Episode average V value: 22.859824021657307\n",
      "Average (on the epoch) training loss: 67.44837188720703\n",
      "Episode average V value: 43.33168411254883\n",
      "Average (on the epoch) training loss: 66.84358215332031\n",
      "Episode average V value: 31.311323165893555\n",
      "Average (on the epoch) training loss: 67.86355590820312\n",
      "Episode average V value: 31.112722396850586\n",
      "Average (on the epoch) training loss: 67.90908813476562\n",
      "Episode average V value: -6.8250555992126465\n",
      "Average (on the epoch) training loss: 68.28913116455078\n",
      "Episode average V value: 48.12582015991211\n",
      "Average (on the epoch) training loss: 67.2370834350586\n",
      "Episode average V value: 18.092205842336018\n",
      "Average (on the epoch) training loss: 67.0268325805664\n",
      "Episode average V value: 13.557281494140625\n",
      "Average (on the epoch) training loss: 67.23029327392578\n",
      "Episode average V value: 24.696096420288086\n",
      "Average (on the epoch) training loss: 66.57673645019531\n",
      "Episode average V value: 27.63873863220215\n",
      "Average (on the epoch) training loss: 65.95623779296875\n",
      "Episode average V value: 27.86228855450948\n",
      "Average (on the epoch) training loss: 66.17171478271484\n",
      "Episode average V value: 31.586785187323887\n",
      "Average (on the epoch) training loss: 66.17730712890625\n",
      "Episode average V value: 27.851468523343403\n",
      "Average (on the epoch) training loss: 66.2322998046875\n",
      "Episode average V value: 50.04443049430847\n",
      "Average (on the epoch) training loss: 65.37776184082031\n",
      "Episode average V value: 32.112037658691406\n",
      "Average (on the epoch) training loss: 64.95481872558594\n",
      "Episode average V value: 41.79905869563421\n",
      "Average (on the epoch) training loss: 64.44471740722656\n",
      "Episode average V value: 30.28703498840332\n",
      "Average (on the epoch) training loss: 63.8677978515625\n",
      "Episode average V value: 20.62296970685323\n",
      "Average (on the epoch) training loss: 64.28575134277344\n",
      "Episode average V value: 61.05354309082031\n",
      "Average (on the epoch) training loss: 64.35055541992188\n",
      "Episode average V value: 28.10138003031413\n",
      "Average (on the epoch) training loss: 64.50916290283203\n",
      "Episode average V value: 3.3153045177459717\n",
      "Average (on the epoch) training loss: 63.72784423828125\n",
      "Episode average V value: 31.82227897644043\n",
      "Average (on the epoch) training loss: 63.548736572265625\n",
      "Episode average V value: 25.28112967447801\n",
      "Average (on the epoch) training loss: 64.04212188720703\n",
      "Episode average V value: 32.21560525894165\n",
      "Average (on the epoch) training loss: 63.90822982788086\n",
      "Episode average V value: 38.43558883666992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 63.47405242919922\n",
      "Episode average V value: 43.94885094960531\n",
      "Average (on the epoch) training loss: 63.349220275878906\n",
      "Episode average V value: 18.882275104522705\n",
      "Average (on the epoch) training loss: 63.30827331542969\n",
      "Episode average V value: 54.0766708056132\n",
      "Average (on the epoch) training loss: 62.90920639038086\n",
      "Episode average V value: 22.3977845509847\n",
      "Average (on the epoch) training loss: 63.14262771606445\n",
      "Episode average V value: 66.51914978027344\n",
      "Average (on the epoch) training loss: 63.328102111816406\n",
      "Episode average V value: 31.261088768641155\n",
      "Average (on the epoch) training loss: 63.773983001708984\n",
      "Episode average V value: 36.768590092659\n",
      "Average (on the epoch) training loss: 63.429344177246094\n",
      "Episode average V value: 35.76047255776145\n",
      "Average (on the epoch) training loss: 63.798919677734375\n",
      "Episode average V value: 56.10040283203125\n",
      "Average (on the epoch) training loss: 63.34456253051758\n",
      "Episode average V value: -2.155714770158132\n",
      "Average (on the epoch) training loss: 62.84923553466797\n",
      "Episode average V value: 29.54461697737376\n",
      "Average (on the epoch) training loss: 62.4887809753418\n",
      "Episode average V value: 55.438486774762474\n",
      "Average (on the epoch) training loss: 62.069217681884766\n",
      "Episode average V value: 31.696906487147015\n",
      "Average (on the epoch) training loss: 61.65419006347656\n",
      "Episode average V value: 42.73719875017802\n",
      "Average (on the epoch) training loss: 61.52555465698242\n",
      "Episode average V value: 38.866844852765404\n",
      "Average (on the epoch) training loss: 61.49200439453125\n",
      "Episode average V value: 38.73708724975586\n",
      "Average (on the epoch) training loss: 61.36027145385742\n",
      "Episode average V value: 38.676292419433594\n",
      "Average (on the epoch) training loss: 61.57871627807617\n",
      "Episode average V value: 38.2038254737854\n",
      "Average (on the epoch) training loss: 62.13113784790039\n",
      "Episode average V value: 48.38132095336914\n",
      "Average (on the epoch) training loss: 62.08435821533203\n",
      "Episode average V value: 37.73283247152964\n",
      "Average (on the epoch) training loss: 61.778934478759766\n",
      "Episode average V value: 45.12564468383789\n",
      "Average (on the epoch) training loss: 61.89580535888672\n",
      "Episode average V value: 64.0736095905304\n",
      "Average (on the epoch) training loss: 61.53890609741211\n",
      "Episode average V value: 36.43935012817383\n",
      "Average (on the epoch) training loss: 61.326473236083984\n",
      "Episode average V value: 35.292343537012734\n",
      "Average (on the epoch) training loss: 61.27202224731445\n",
      "Episode average V value: 49.37900161743164\n",
      "Average (on the epoch) training loss: 60.97521209716797\n",
      "Episode average V value: 45.122344970703125\n",
      "Average (on the epoch) training loss: 60.65612030029297\n",
      "Episode average V value: 45.27647399902344\n",
      "Average (on the epoch) training loss: 60.737831115722656\n",
      "Episode average V value: 40.5354577700297\n",
      "Average (on the epoch) training loss: 60.94013214111328\n",
      "Episode average V value: 41.7919155034152\n",
      "Average (on the epoch) training loss: 61.09416580200195\n",
      "Episode average V value: 23.28969120979309\n",
      "Average (on the epoch) training loss: 60.83399963378906\n",
      "Episode average V value: 43.984066009521484\n",
      "Average (on the epoch) training loss: 60.53282928466797\n",
      "Episode average V value: 42.075748443603516\n",
      "Average (on the epoch) training loss: 60.69798278808594\n",
      "Episode average V value: 40.27448654174805\n",
      "Average (on the epoch) training loss: 60.346832275390625\n",
      "Episode average V value: 32.267704010009766\n",
      "Average (on the epoch) training loss: 60.76348876953125\n",
      "Episode average V value: 46.35271308819453\n",
      "Average (on the epoch) training loss: 61.18489456176758\n",
      "Episode average V value: 37.50068028767904\n",
      "Average (on the epoch) training loss: 61.00188446044922\n",
      "Episode average V value: 36.79801940917969\n",
      "Average (on the epoch) training loss: 60.883941650390625\n",
      "Episode average V value: 49.25910949707031\n",
      "Average (on the epoch) training loss: 60.99136734008789\n",
      "Episode average V value: 38.9594612121582\n",
      "Average (on the epoch) training loss: 60.73820114135742\n",
      "Episode average V value: 43.56020736694336\n",
      "Average (on the epoch) training loss: 60.46925735473633\n",
      "Episode average V value: 16.846200682900168\n",
      "Average (on the epoch) training loss: 60.41136169433594\n",
      "Episode average V value: 41.64556121826172\n",
      "Average (on the epoch) training loss: 60.28410339355469\n",
      "Episode average V value: 40.04929672588002\n",
      "Average (on the epoch) training loss: 60.038185119628906\n",
      "Episode average V value: 35.96701383590698\n",
      "Average (on the epoch) training loss: 60.272666931152344\n",
      "Episode average V value: 45.154205322265625\n",
      "Average (on the epoch) training loss: 60.02120590209961\n",
      "Episode average V value: 35.27967484792074\n",
      "Average (on the epoch) training loss: 59.8794059753418\n",
      "Episode average V value: 37.10606877009074\n",
      "Average (on the epoch) training loss: 59.93207550048828\n",
      "Episode average V value: 61.56266884009043\n",
      "Average (on the epoch) training loss: 60.138282775878906\n",
      "Episode average V value: 32.43888880989768\n",
      "Average (on the epoch) training loss: 59.90993118286133\n",
      "Episode average V value: 42.761051873366036\n",
      "Average (on the epoch) training loss: 59.62042236328125\n",
      "Episode average V value: 26.665815273920696\n",
      "Average (on the epoch) training loss: 59.70399856567383\n",
      "Episode average V value: 45.71201705932617\n",
      "epoch 4:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 43.61239242553711\n",
      "Episode average V value: 43.12447086970011\n",
      "Average (on the epoch) training loss: 39.11866760253906\n",
      "Episode average V value: 35.25487448952415\n",
      "Average (on the epoch) training loss: 57.96221160888672\n",
      "Episode average V value: 55.18221382300059\n",
      "Average (on the epoch) training loss: 50.7491340637207\n",
      "Episode average V value: 38.19099807739258\n",
      "Average (on the epoch) training loss: 54.64980697631836\n",
      "Episode average V value: 35.912540435791016\n",
      "Average (on the epoch) training loss: 52.58660125732422\n",
      "Episode average V value: 47.706786712010704\n",
      "Average (on the epoch) training loss: 55.210418701171875\n",
      "Episode average V value: 68.2726821899414\n",
      "Average (on the epoch) training loss: 55.31757736206055\n",
      "Episode average V value: 32.97516632080078\n",
      "Average (on the epoch) training loss: 54.79863357543945\n",
      "Episode average V value: 46.575923919677734\n",
      "Average (on the epoch) training loss: 57.06529998779297\n",
      "Episode average V value: 35.81564159393311\n",
      "Average (on the epoch) training loss: 55.986454010009766\n",
      "Episode average V value: 46.95092384020487\n",
      "Average (on the epoch) training loss: 55.20563888549805\n",
      "Episode average V value: 40.830039978027344\n",
      "Average (on the epoch) training loss: 54.185272216796875\n",
      "Episode average V value: 32.364410400390625\n",
      "Average (on the epoch) training loss: 55.352081298828125\n",
      "Episode average V value: 68.10994661847751\n",
      "Average (on the epoch) training loss: 55.30194091796875\n",
      "Episode average V value: 28.452652150934394\n",
      "Average (on the epoch) training loss: 56.64399337768555\n",
      "Episode average V value: 50.00501410166422\n",
      "Average (on the epoch) training loss: 56.3978157043457\n",
      "Episode average V value: 33.026483138402305\n",
      "Average (on the epoch) training loss: 55.50326156616211\n",
      "Episode average V value: 47.97864471782338\n",
      "Average (on the epoch) training loss: 59.63634490966797\n",
      "Episode average V value: 42.00083923339844\n",
      "Average (on the epoch) training loss: 58.82626724243164\n",
      "Episode average V value: 34.10782241821289\n",
      "Average (on the epoch) training loss: 59.43283462524414\n",
      "Episode average V value: 40.30129692771218\n",
      "Average (on the epoch) training loss: 58.85319900512695\n",
      "Episode average V value: 41.9435461362203\n",
      "Average (on the epoch) training loss: 58.47574996948242\n",
      "Episode average V value: 44.32600021362305\n",
      "Average (on the epoch) training loss: 59.38007354736328\n",
      "Episode average V value: 34.42604831854502\n",
      "Average (on the epoch) training loss: 60.0187873840332\n",
      "Episode average V value: 31.218584060668945\n",
      "Average (on the epoch) training loss: 62.90199279785156\n",
      "Episode average V value: 38.496606219898574\n",
      "Average (on the epoch) training loss: 61.898895263671875\n",
      "Episode average V value: 35.08967954462225\n",
      "Average (on the epoch) training loss: 61.323055267333984\n",
      "Episode average V value: 35.35390290617943\n",
      "Average (on the epoch) training loss: 61.18461608886719\n",
      "Episode average V value: 36.67055416107178\n",
      "Average (on the epoch) training loss: 62.08574295043945\n",
      "Episode average V value: 45.1564519405365\n",
      "Average (on the epoch) training loss: 63.244606018066406\n",
      "Episode average V value: 40.37071466445923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 62.65781021118164\n",
      "Episode average V value: 49.78982663154602\n",
      "Average (on the epoch) training loss: 62.57236862182617\n",
      "Episode average V value: 49.57584762573242\n",
      "Average (on the epoch) training loss: 62.5617561340332\n",
      "Episode average V value: 102.22690996527672\n",
      "Average (on the epoch) training loss: 62.976524353027344\n",
      "Episode average V value: 78.62259674072266\n",
      "Average (on the epoch) training loss: 62.53252410888672\n",
      "Episode average V value: 51.40023465951284\n",
      "Average (on the epoch) training loss: 62.72354507446289\n",
      "Episode average V value: 65.95364548762639\n",
      "Average (on the epoch) training loss: 62.54927444458008\n",
      "Episode average V value: 33.11900075276693\n",
      "Average (on the epoch) training loss: 63.945587158203125\n",
      "Episode average V value: 43.378499031066895\n",
      "Average (on the epoch) training loss: 64.2763900756836\n",
      "Episode average V value: 80.2530746459961\n",
      "Average (on the epoch) training loss: 65.47306823730469\n",
      "Episode average V value: 42.99795913696289\n",
      "Average (on the epoch) training loss: 66.2495346069336\n",
      "Episode average V value: 89.32746696472168\n",
      "Average (on the epoch) training loss: 66.12066650390625\n",
      "Episode average V value: 62.67143630981445\n",
      "Average (on the epoch) training loss: 66.22563171386719\n",
      "Episode average V value: 61.177611430486046\n",
      "Average (on the epoch) training loss: 66.9542236328125\n",
      "Episode average V value: 44.185190518697105\n",
      "Average (on the epoch) training loss: 66.5346450805664\n",
      "Episode average V value: 46.22508307298025\n",
      "Average (on the epoch) training loss: 66.19526672363281\n",
      "Episode average V value: 98.45213747024536\n",
      "Average (on the epoch) training loss: 66.08830261230469\n",
      "Episode average V value: 77.24473363702947\n",
      "Average (on the epoch) training loss: 66.20430755615234\n",
      "Episode average V value: 22.18967021595348\n",
      "Average (on the epoch) training loss: 66.1377182006836\n",
      "Episode average V value: 86.1578982969125\n",
      "Average (on the epoch) training loss: 65.97016906738281\n",
      "Episode average V value: 84.33312765757243\n",
      "Average (on the epoch) training loss: 65.95296478271484\n",
      "Episode average V value: 85.30927276611328\n",
      "Average (on the epoch) training loss: 65.83541870117188\n",
      "Episode average V value: 52.38820711771647\n",
      "Average (on the epoch) training loss: 65.82403564453125\n",
      "Episode average V value: 108.31145842870076\n",
      "Average (on the epoch) training loss: 65.46099090576172\n",
      "Episode average V value: 93.038076877594\n",
      "Average (on the epoch) training loss: 66.1466293334961\n",
      "Episode average V value: -425.9632400671641\n",
      "Average (on the epoch) training loss: 65.8023910522461\n",
      "Episode average V value: 84.56772682883523\n",
      "Average (on the epoch) training loss: 65.75271606445312\n",
      "Episode average V value: 98.95173128445943\n",
      "Average (on the epoch) training loss: 65.71647644042969\n",
      "Episode average V value: 82.98357407251994\n",
      "Average (on the epoch) training loss: 66.22195434570312\n",
      "Episode average V value: 57.57519513910467\n",
      "Average (on the epoch) training loss: 66.07910919189453\n",
      "Episode average V value: 79.85382493336995\n",
      "Average (on the epoch) training loss: 65.93636322021484\n",
      "Episode average V value: 95.35416412353516\n",
      "Average (on the epoch) training loss: 65.67591857910156\n",
      "Episode average V value: -357.13879498568446\n",
      "Average (on the epoch) training loss: 65.3427963256836\n",
      "Episode average V value: 64.73271560668945\n",
      "Average (on the epoch) training loss: 65.27135467529297\n",
      "Episode average V value: 101.1607437133789\n",
      "Average (on the epoch) training loss: 65.57023620605469\n",
      "Episode average V value: -390.66279541362417\n",
      "Average (on the epoch) training loss: 65.51121520996094\n",
      "Episode average V value: 41.74982706705729\n",
      "Average (on the epoch) training loss: 65.67529296875\n",
      "Episode average V value: 89.7372252146403\n",
      "Average (on the epoch) training loss: 66.14344024658203\n",
      "Episode average V value: 48.32699203491211\n",
      "Average (on the epoch) training loss: 65.97582244873047\n",
      "Episode average V value: -323.2099548975627\n",
      "Average (on the epoch) training loss: 66.53598022460938\n",
      "Episode average V value: 48.866743087768555\n",
      "Average (on the epoch) training loss: 66.92538452148438\n",
      "Episode average V value: 55.57728576660156\n",
      "Average (on the epoch) training loss: 67.65380859375\n",
      "Episode average V value: 64.84100688587536\n",
      "Average (on the epoch) training loss: 68.0060043334961\n",
      "Episode average V value: 53.79624557495117\n",
      "Average (on the epoch) training loss: 68.37043762207031\n",
      "Episode average V value: 89.77329540252686\n",
      "Average (on the epoch) training loss: 68.55998229980469\n",
      "Episode average V value: 72.79890489578247\n",
      "Average (on the epoch) training loss: 68.67303466796875\n",
      "Episode average V value: 101.21635071436565\n",
      "Average (on the epoch) training loss: 68.82823181152344\n",
      "Episode average V value: 85.76229842503865\n",
      "Average (on the epoch) training loss: 69.38790893554688\n",
      "Episode average V value: 80.54245138168335\n",
      "Average (on the epoch) training loss: 69.07360076904297\n",
      "Episode average V value: 79.5415579477946\n",
      "Average (on the epoch) training loss: 69.5161361694336\n",
      "Episode average V value: 26.780295372009277\n",
      "Average (on the epoch) training loss: 70.01383209228516\n",
      "Episode average V value: 84.93650817871094\n",
      "Average (on the epoch) training loss: 69.826904296875\n",
      "Episode average V value: 59.25130812327067\n",
      "Average (on the epoch) training loss: 69.88162231445312\n",
      "Episode average V value: 73.98580225308736\n",
      "Average (on the epoch) training loss: 69.62786865234375\n",
      "Episode average V value: 63.777748281305485\n",
      "Average (on the epoch) training loss: 69.603515625\n",
      "Episode average V value: 63.72201919555664\n",
      "Average (on the epoch) training loss: 69.35717010498047\n",
      "Episode average V value: 52.765114933252335\n",
      "Average (on the epoch) training loss: 69.11266326904297\n",
      "Episode average V value: 104.28110337257385\n",
      "Average (on the epoch) training loss: 69.2223129272461\n",
      "Episode average V value: 78.11074542999268\n",
      "Average (on the epoch) training loss: 69.23790740966797\n",
      "Episode average V value: -334.9093023935954\n",
      "Average (on the epoch) training loss: 69.33851623535156\n",
      "Episode average V value: 92.636474609375\n",
      "Average (on the epoch) training loss: 69.33086395263672\n",
      "Episode average V value: 85.09045616785686\n",
      "Average (on the epoch) training loss: 69.48731994628906\n",
      "Episode average V value: -321.18761285146076\n",
      "Average (on the epoch) training loss: 69.93621063232422\n",
      "Episode average V value: 68.73534599939983\n",
      "Average (on the epoch) training loss: 69.86029052734375\n",
      "Episode average V value: 91.08143417040507\n",
      "Average (on the epoch) training loss: 69.97227478027344\n",
      "Episode average V value: 67.94038979212444\n",
      "Average (on the epoch) training loss: 70.24844360351562\n",
      "Episode average V value: 71.37525177001953\n",
      "Average (on the epoch) training loss: 70.26006317138672\n",
      "Episode average V value: 83.67609405517578\n",
      "Average (on the epoch) training loss: 70.39997100830078\n",
      "Episode average V value: 95.10122680664062\n",
      "Average (on the epoch) training loss: 70.80829620361328\n",
      "Episode average V value: 71.8003511428833\n",
      "epoch 5:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 83.89324188232422\n",
      "Episode average V value: 59.65483585993449\n",
      "Average (on the epoch) training loss: 81.58504486083984\n",
      "Episode average V value: -385.3683360815048\n",
      "Average (on the epoch) training loss: 76.02010345458984\n",
      "Episode average V value: 80.20595995585124\n",
      "Average (on the epoch) training loss: 83.4207534790039\n",
      "Episode average V value: 90.07160707314809\n",
      "Average (on the epoch) training loss: 81.45830535888672\n",
      "Episode average V value: 91.80954869588216\n",
      "Average (on the epoch) training loss: 83.86146545410156\n",
      "Episode average V value: -282.60676606496173\n",
      "Average (on the epoch) training loss: 83.51531982421875\n",
      "Episode average V value: 96.85693327585857\n",
      "Average (on the epoch) training loss: 78.87577056884766\n",
      "Episode average V value: 82.74607729911804\n",
      "Average (on the epoch) training loss: 78.80831146240234\n",
      "Episode average V value: 104.60787322304465\n",
      "Average (on the epoch) training loss: 77.183837890625\n",
      "Episode average V value: 103.57923126220703\n",
      "Average (on the epoch) training loss: 81.79679870605469\n",
      "Episode average V value: -431.12541979009455\n",
      "Average (on the epoch) training loss: 81.09165954589844\n",
      "Episode average V value: 97.70230102539062\n",
      "Average (on the epoch) training loss: 85.67125701904297\n",
      "Episode average V value: 87.15195020039876\n",
      "Average (on the epoch) training loss: 83.07064819335938\n",
      "Episode average V value: 89.01569286982219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 81.20266723632812\n",
      "Episode average V value: 93.16715208689372\n",
      "Average (on the epoch) training loss: 81.85395050048828\n",
      "Episode average V value: -300.29884974161786\n",
      "Average (on the epoch) training loss: 80.44552612304688\n",
      "Episode average V value: 105.36675707499187\n",
      "Average (on the epoch) training loss: 81.5863265991211\n",
      "Episode average V value: 95.67482063987039\n",
      "Average (on the epoch) training loss: 80.82276153564453\n",
      "Episode average V value: 118.49162292480469\n",
      "Average (on the epoch) training loss: 83.78852844238281\n",
      "Episode average V value: 75.05667114257812\n",
      "Average (on the epoch) training loss: 84.65139770507812\n",
      "Episode average V value: 78.7306900024414\n",
      "Average (on the epoch) training loss: 84.5966796875\n",
      "Episode average V value: 96.35588455200195\n",
      "Average (on the epoch) training loss: 85.0436782836914\n",
      "Episode average V value: 98.5308609008789\n",
      "Average (on the epoch) training loss: 85.38430786132812\n",
      "Episode average V value: 97.52469635009766\n",
      "Average (on the epoch) training loss: 84.92459869384766\n",
      "Episode average V value: 79.30071258544922\n",
      "Average (on the epoch) training loss: 86.01136016845703\n",
      "Episode average V value: 70.19369506835938\n",
      "Average (on the epoch) training loss: 85.3613052368164\n",
      "Episode average V value: 96.963134765625\n",
      "Average (on the epoch) training loss: 84.37362670898438\n",
      "Episode average V value: 88.74020385742188\n",
      "Average (on the epoch) training loss: 84.23133850097656\n",
      "Episode average V value: 115.85678609212239\n",
      "Average (on the epoch) training loss: 84.83026123046875\n",
      "Episode average V value: 67.27039623260498\n",
      "Average (on the epoch) training loss: 83.9692153930664\n",
      "Episode average V value: 95.49585723876953\n",
      "Average (on the epoch) training loss: 83.52979278564453\n",
      "Episode average V value: 97.74414094289143\n",
      "Average (on the epoch) training loss: 84.48790740966797\n",
      "Episode average V value: 75.81457376480103\n",
      "Average (on the epoch) training loss: 84.55426788330078\n",
      "Episode average V value: -388.05819216641515\n",
      "Average (on the epoch) training loss: 84.65719604492188\n",
      "Episode average V value: 71.12020111083984\n",
      "Average (on the epoch) training loss: 84.61608123779297\n",
      "Episode average V value: 63.61787483908913\n",
      "Average (on the epoch) training loss: 85.19524383544922\n",
      "Episode average V value: 98.94282722473145\n",
      "Average (on the epoch) training loss: 86.01675415039062\n",
      "Episode average V value: 103.62800216674805\n",
      "Average (on the epoch) training loss: 85.47167205810547\n",
      "Episode average V value: 99.91345977783203\n",
      "Average (on the epoch) training loss: 84.9610824584961\n",
      "Episode average V value: 92.01500701904297\n",
      "Average (on the epoch) training loss: 86.66667175292969\n",
      "Episode average V value: 90.17774772644043\n",
      "Average (on the epoch) training loss: 86.63079833984375\n",
      "Episode average V value: 58.18825912475586\n",
      "Average (on the epoch) training loss: 86.55821990966797\n",
      "Episode average V value: 121.73894500732422\n",
      "Average (on the epoch) training loss: 86.57840728759766\n",
      "Episode average V value: 101.61246267954509\n",
      "Average (on the epoch) training loss: 85.97280883789062\n",
      "Episode average V value: 78.76778411865234\n",
      "Average (on the epoch) training loss: 85.91287231445312\n",
      "Episode average V value: 83.36946699354384\n",
      "Average (on the epoch) training loss: 85.82858276367188\n",
      "Episode average V value: 77.79015890757243\n",
      "Average (on the epoch) training loss: 86.09976196289062\n",
      "Episode average V value: 73.57522964477539\n",
      "Average (on the epoch) training loss: 85.85356903076172\n",
      "Episode average V value: 80.59648323059082\n",
      "Average (on the epoch) training loss: 85.37053680419922\n",
      "Episode average V value: 118.02530670166016\n",
      "Average (on the epoch) training loss: 85.72618103027344\n",
      "Episode average V value: 71.85392761230469\n",
      "Average (on the epoch) training loss: 86.2509536743164\n",
      "Episode average V value: 118.1974105834961\n",
      "Average (on the epoch) training loss: 86.3001937866211\n",
      "Episode average V value: 88.80353546142578\n",
      "Average (on the epoch) training loss: 86.23174285888672\n",
      "Episode average V value: 90.98130480448405\n",
      "Average (on the epoch) training loss: 86.3560562133789\n",
      "Episode average V value: 90.9678955078125\n",
      "Average (on the epoch) training loss: 85.98080444335938\n",
      "Episode average V value: 82.00090789794922\n",
      "Average (on the epoch) training loss: 85.98904418945312\n",
      "Episode average V value: 71.64034104347229\n",
      "Average (on the epoch) training loss: 85.96733856201172\n",
      "Episode average V value: 91.6717300415039\n",
      "Average (on the epoch) training loss: 86.53377532958984\n",
      "Episode average V value: 98.05216908454895\n",
      "Average (on the epoch) training loss: 86.37947082519531\n",
      "Episode average V value: 95.0466079711914\n",
      "Average (on the epoch) training loss: 86.06652069091797\n",
      "Episode average V value: 126.15435028076172\n",
      "Average (on the epoch) training loss: 86.0512466430664\n",
      "Episode average V value: 82.036865234375\n",
      "Average (on the epoch) training loss: 86.2889175415039\n",
      "Episode average V value: 94.91875457763672\n",
      "Average (on the epoch) training loss: 86.16785430908203\n",
      "Episode average V value: 76.9909896850586\n",
      "Average (on the epoch) training loss: 86.00054168701172\n",
      "Episode average V value: 81.2559256752332\n",
      "Average (on the epoch) training loss: 85.53286743164062\n",
      "Episode average V value: 68.60088888804118\n",
      "Average (on the epoch) training loss: 85.53103637695312\n",
      "Episode average V value: 55.97603849931197\n",
      "Average (on the epoch) training loss: 85.1417465209961\n",
      "Episode average V value: 121.82427978515625\n",
      "Average (on the epoch) training loss: 84.6627197265625\n",
      "Episode average V value: 96.77648048400879\n",
      "Average (on the epoch) training loss: 84.68313598632812\n",
      "Episode average V value: 82.17412567138672\n",
      "Average (on the epoch) training loss: 84.6784896850586\n",
      "Episode average V value: 95.74394087357955\n",
      "Average (on the epoch) training loss: 84.60948181152344\n",
      "Episode average V value: 91.6160000887784\n",
      "Average (on the epoch) training loss: 84.82992553710938\n",
      "Episode average V value: 96.56360658009847\n",
      "Average (on the epoch) training loss: 84.71284484863281\n",
      "Episode average V value: 82.86769119898479\n",
      "Average (on the epoch) training loss: 84.5995101928711\n",
      "Episode average V value: 54.271331469217934\n",
      "Average (on the epoch) training loss: 84.54180908203125\n",
      "Episode average V value: 55.346954345703125\n",
      "Average (on the epoch) training loss: 84.24495697021484\n",
      "Episode average V value: -349.14502207438153\n",
      "Average (on the epoch) training loss: 84.62336730957031\n",
      "Episode average V value: 87.28298950195312\n",
      "Average (on the epoch) training loss: 84.636962890625\n",
      "Episode average V value: 102.43888092041016\n",
      "Average (on the epoch) training loss: 84.25184631347656\n",
      "Episode average V value: 104.77448145548503\n",
      "Average (on the epoch) training loss: 84.13658905029297\n",
      "Episode average V value: 96.87393188476562\n",
      "Average (on the epoch) training loss: 84.66326141357422\n",
      "Episode average V value: 112.58177947998047\n",
      "Average (on the epoch) training loss: 84.2647476196289\n",
      "Episode average V value: 75.32361602783203\n",
      "Average (on the epoch) training loss: 84.25367736816406\n",
      "Episode average V value: 80.32264868418376\n",
      "Average (on the epoch) training loss: 84.28235626220703\n",
      "Episode average V value: 106.89805499712627\n",
      "Average (on the epoch) training loss: 84.4879379272461\n",
      "Episode average V value: 74.5724868774414\n",
      "Average (on the epoch) training loss: 84.21247863769531\n",
      "Episode average V value: 79.22207911809285\n",
      "Average (on the epoch) training loss: 84.13531494140625\n",
      "Episode average V value: 101.98416796597567\n",
      "Average (on the epoch) training loss: 84.20157623291016\n",
      "Episode average V value: 88.08313751220703\n",
      "Average (on the epoch) training loss: 84.11036682128906\n",
      "Episode average V value: 77.0069808959961\n",
      "Average (on the epoch) training loss: 84.30391693115234\n",
      "Episode average V value: 87.31927599906922\n",
      "Average (on the epoch) training loss: 84.50572967529297\n",
      "Episode average V value: 90.54063280423482\n",
      "Average (on the epoch) training loss: 84.45194244384766\n",
      "Episode average V value: 83.29261016845703\n",
      "Average (on the epoch) training loss: 84.14617919921875\n",
      "Episode average V value: 70.87540356318156\n",
      "Average (on the epoch) training loss: 84.6444320678711\n",
      "Episode average V value: 97.61630249023438\n",
      "Average (on the epoch) training loss: 84.50933074951172\n",
      "Episode average V value: 78.65784684816997\n",
      "Average (on the epoch) training loss: 84.67411804199219\n",
      "Episode average V value: 85.09458403153853\n",
      "Average (on the epoch) training loss: 84.63360595703125\n",
      "Episode average V value: 99.62464141845703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 84.59333038330078\n",
      "Episode average V value: 100.20095825195312\n",
      "Average (on the epoch) training loss: 84.9502182006836\n",
      "Episode average V value: 91.32173156738281\n",
      "epoch 6:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 65.29666900634766\n",
      "Episode average V value: -725.9062407811483\n",
      "Average (on the epoch) training loss: 95.23604583740234\n",
      "Episode average V value: 76.91515167554219\n",
      "Average (on the epoch) training loss: 83.3168716430664\n",
      "Episode average V value: 75.9277572631836\n",
      "Average (on the epoch) training loss: 89.28401947021484\n",
      "Episode average V value: 69.29139232635498\n",
      "Average (on the epoch) training loss: 91.89376068115234\n",
      "Episode average V value: 75.55621385574341\n",
      "Average (on the epoch) training loss: 97.86827087402344\n",
      "Episode average V value: 73.97622680664062\n",
      "Average (on the epoch) training loss: 98.09765625\n",
      "Episode average V value: 80.45072174072266\n",
      "Average (on the epoch) training loss: 96.17989349365234\n",
      "Episode average V value: 64.36249542236328\n",
      "Average (on the epoch) training loss: 97.02030181884766\n",
      "Episode average V value: 58.02724075317383\n",
      "Average (on the epoch) training loss: 94.94798278808594\n",
      "Episode average V value: 67.47054942448933\n",
      "Average (on the epoch) training loss: 92.35064697265625\n",
      "Episode average V value: 68.47412172953288\n",
      "Average (on the epoch) training loss: 90.95415496826172\n",
      "Episode average V value: 56.11911392211914\n",
      "Average (on the epoch) training loss: 89.1634521484375\n",
      "Episode average V value: 79.37410322825114\n",
      "Average (on the epoch) training loss: 89.06031799316406\n",
      "Episode average V value: 60.554080963134766\n",
      "Average (on the epoch) training loss: 88.45072937011719\n",
      "Episode average V value: 79.39687728881836\n",
      "Average (on the epoch) training loss: 89.2633056640625\n",
      "Episode average V value: 45.131072998046875\n",
      "Average (on the epoch) training loss: 87.79500579833984\n",
      "Episode average V value: 39.33398962020874\n",
      "Average (on the epoch) training loss: 87.15654754638672\n",
      "Episode average V value: 89.75835418701172\n",
      "Average (on the epoch) training loss: 85.11388397216797\n",
      "Episode average V value: 63.744693756103516\n",
      "Average (on the epoch) training loss: 85.8204345703125\n",
      "Episode average V value: 56.88576889038086\n",
      "Average (on the epoch) training loss: 85.02902221679688\n",
      "Episode average V value: 63.809974670410156\n",
      "Average (on the epoch) training loss: 83.13088989257812\n",
      "Episode average V value: 72.59687805175781\n",
      "Average (on the epoch) training loss: 81.520263671875\n",
      "Episode average V value: 66.01942511399587\n",
      "Average (on the epoch) training loss: 81.17176055908203\n",
      "Episode average V value: 69.48808320363362\n",
      "Average (on the epoch) training loss: 81.04654693603516\n",
      "Episode average V value: 73.10397879282634\n",
      "Average (on the epoch) training loss: 81.55265808105469\n",
      "Episode average V value: 67.62796783447266\n",
      "Average (on the epoch) training loss: 82.72666931152344\n",
      "Episode average V value: 96.902587890625\n",
      "Average (on the epoch) training loss: 82.04019927978516\n",
      "Episode average V value: 68.02237447102864\n",
      "Average (on the epoch) training loss: 81.567626953125\n",
      "Episode average V value: 57.23732089996338\n",
      "Average (on the epoch) training loss: 80.16680908203125\n",
      "Episode average V value: 74.54901123046875\n",
      "Average (on the epoch) training loss: 79.42588806152344\n",
      "Episode average V value: 78.31334686279297\n",
      "Average (on the epoch) training loss: 79.2262191772461\n",
      "Episode average V value: 44.053306579589844\n",
      "Average (on the epoch) training loss: 79.0924072265625\n",
      "Episode average V value: 54.06987682978312\n",
      "Average (on the epoch) training loss: 78.1714859008789\n",
      "Episode average V value: 63.3723030090332\n",
      "Average (on the epoch) training loss: 78.2923583984375\n",
      "Episode average V value: 70.41472244262695\n",
      "Average (on the epoch) training loss: 78.525146484375\n",
      "Episode average V value: 72.11063385009766\n",
      "Average (on the epoch) training loss: 77.73914337158203\n",
      "Episode average V value: 49.1388053894043\n",
      "Average (on the epoch) training loss: 77.02307891845703\n",
      "Episode average V value: 63.964951515197754\n",
      "Average (on the epoch) training loss: 77.05911254882812\n",
      "Episode average V value: 53.02072127660116\n",
      "Average (on the epoch) training loss: 77.2256851196289\n",
      "Episode average V value: 58.74149338404337\n",
      "Average (on the epoch) training loss: 76.50700378417969\n",
      "Episode average V value: 48.827137311299644\n",
      "Average (on the epoch) training loss: 75.92021942138672\n",
      "Episode average V value: 22.116292238235474\n",
      "Average (on the epoch) training loss: 76.22216796875\n",
      "Episode average V value: 60.093485514322914\n",
      "Average (on the epoch) training loss: 75.9615478515625\n",
      "Episode average V value: 47.74553511540095\n",
      "Average (on the epoch) training loss: 75.65546417236328\n",
      "Episode average V value: 46.18101151784261\n",
      "Average (on the epoch) training loss: 75.40436553955078\n",
      "Episode average V value: 74.31216430664062\n",
      "Average (on the epoch) training loss: 74.72032165527344\n",
      "Episode average V value: 69.34478759765625\n",
      "Average (on the epoch) training loss: 75.34503936767578\n",
      "Episode average V value: 76.60698699951172\n",
      "Average (on the epoch) training loss: 74.96346282958984\n",
      "Episode average V value: 54.12541580200195\n",
      "Average (on the epoch) training loss: 74.98121643066406\n",
      "Episode average V value: 57.4263801574707\n",
      "Average (on the epoch) training loss: 74.53380584716797\n",
      "Episode average V value: 81.09810048883611\n",
      "Average (on the epoch) training loss: 74.87623596191406\n",
      "Episode average V value: 68.78721459706624\n",
      "Average (on the epoch) training loss: 75.27299499511719\n",
      "Episode average V value: 52.5818821589152\n",
      "Average (on the epoch) training loss: 75.45848846435547\n",
      "Episode average V value: 82.89076137542725\n",
      "Average (on the epoch) training loss: 75.176513671875\n",
      "Episode average V value: 51.926727294921875\n",
      "Average (on the epoch) training loss: 74.85315704345703\n",
      "Episode average V value: 63.31882095336914\n",
      "Average (on the epoch) training loss: 74.6310043334961\n",
      "Episode average V value: 54.57948168118795\n",
      "Average (on the epoch) training loss: 74.23483276367188\n",
      "Episode average V value: 70.7883529663086\n",
      "Average (on the epoch) training loss: 73.89955139160156\n",
      "Episode average V value: 58.25457763671875\n",
      "Average (on the epoch) training loss: 74.15211486816406\n",
      "Episode average V value: 66.08369445800781\n",
      "Average (on the epoch) training loss: 73.84420013427734\n",
      "Episode average V value: 47.20292510986328\n",
      "Average (on the epoch) training loss: 74.07391357421875\n",
      "Episode average V value: 60.03367678324381\n",
      "Average (on the epoch) training loss: 74.24604034423828\n",
      "Episode average V value: 73.6164321899414\n",
      "Average (on the epoch) training loss: 73.93780517578125\n",
      "Episode average V value: 84.8804702758789\n",
      "Average (on the epoch) training loss: 73.74856567382812\n",
      "Episode average V value: 61.82225036621094\n",
      "Average (on the epoch) training loss: 73.9093017578125\n",
      "Episode average V value: 57.47087605794271\n",
      "Average (on the epoch) training loss: 73.70710754394531\n",
      "Episode average V value: 61.652365843454994\n",
      "Average (on the epoch) training loss: 73.74585723876953\n",
      "Episode average V value: 69.66060638427734\n",
      "Average (on the epoch) training loss: 74.16741943359375\n",
      "Episode average V value: 64.7252197265625\n",
      "Average (on the epoch) training loss: 74.6533432006836\n",
      "Episode average V value: 66.17593987782796\n",
      "Average (on the epoch) training loss: 74.29342651367188\n",
      "Episode average V value: 50.75009502064098\n",
      "Average (on the epoch) training loss: 73.84027862548828\n",
      "Episode average V value: 46.09123542092063\n",
      "Average (on the epoch) training loss: 73.87300109863281\n",
      "Episode average V value: 42.68674850463867\n",
      "Average (on the epoch) training loss: 74.14695739746094\n",
      "Episode average V value: 73.85059356689453\n",
      "Average (on the epoch) training loss: 74.47381591796875\n",
      "Episode average V value: 61.403533935546875\n",
      "Average (on the epoch) training loss: 74.67061614990234\n",
      "Episode average V value: 65.71916198730469\n",
      "Average (on the epoch) training loss: 75.23085021972656\n",
      "Episode average V value: 74.2517318725586\n",
      "Average (on the epoch) training loss: 75.04458618164062\n",
      "Episode average V value: 53.349246978759766\n",
      "Average (on the epoch) training loss: 74.68721771240234\n",
      "Episode average V value: 49.324582533402875\n",
      "Average (on the epoch) training loss: 74.38578796386719\n",
      "Episode average V value: 89.97758261362712\n",
      "Average (on the epoch) training loss: 74.48918914794922\n",
      "Episode average V value: 72.26663970947266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 75.3310775756836\n",
      "Episode average V value: -369.92318773269653\n",
      "Average (on the epoch) training loss: 75.0867691040039\n",
      "Episode average V value: 62.84136962890625\n",
      "Average (on the epoch) training loss: 75.6839370727539\n",
      "Episode average V value: 71.86604309082031\n",
      "Average (on the epoch) training loss: 76.04191589355469\n",
      "Episode average V value: 40.00114711125692\n",
      "Average (on the epoch) training loss: 75.579345703125\n",
      "Episode average V value: 31.402618408203125\n",
      "Average (on the epoch) training loss: 75.70256042480469\n",
      "Episode average V value: 36.085848569869995\n",
      "Average (on the epoch) training loss: 75.51461791992188\n",
      "Episode average V value: 28.45739747087161\n",
      "Average (on the epoch) training loss: 75.8138198852539\n",
      "Episode average V value: 43.452407121658325\n",
      "Average (on the epoch) training loss: 75.56057739257812\n",
      "Episode average V value: 49.3690071105957\n",
      "Average (on the epoch) training loss: 76.139892578125\n",
      "Episode average V value: 47.34132512410482\n",
      "Average (on the epoch) training loss: 75.64463806152344\n",
      "Episode average V value: 54.34878158569336\n",
      "Average (on the epoch) training loss: 75.50492858886719\n",
      "Episode average V value: 33.6863747437795\n",
      "Average (on the epoch) training loss: 75.82170104980469\n",
      "Episode average V value: 27.780316591262817\n",
      "Average (on the epoch) training loss: 75.67533111572266\n",
      "Episode average V value: 40.898834546407066\n",
      "Average (on the epoch) training loss: 75.50045776367188\n",
      "Episode average V value: 45.45267868041992\n",
      "Average (on the epoch) training loss: 75.22683715820312\n",
      "Episode average V value: 29.921148777008057\n",
      "Average (on the epoch) training loss: 74.8636703491211\n",
      "Episode average V value: 56.609745025634766\n",
      "Average (on the epoch) training loss: 74.75255584716797\n",
      "Episode average V value: 45.05984632174174\n",
      "Average (on the epoch) training loss: 74.49834442138672\n",
      "Episode average V value: 69.38550567626953\n",
      "epoch 7:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 34.116573333740234\n",
      "Episode average V value: 40.76907730102539\n",
      "Average (on the epoch) training loss: 36.78818130493164\n",
      "Episode average V value: 51.16345453262329\n",
      "Average (on the epoch) training loss: 56.01541519165039\n",
      "Episode average V value: 42.35720427831014\n",
      "Average (on the epoch) training loss: 70.98046112060547\n",
      "Episode average V value: 26.637279907862347\n",
      "Average (on the epoch) training loss: 69.24324798583984\n",
      "Episode average V value: 44.502349853515625\n",
      "Average (on the epoch) training loss: 65.69461822509766\n",
      "Episode average V value: 39.186394691467285\n",
      "Average (on the epoch) training loss: 69.26026916503906\n",
      "Episode average V value: 43.37704086303711\n",
      "Average (on the epoch) training loss: 73.67952728271484\n",
      "Episode average V value: 34.478668451309204\n",
      "Average (on the epoch) training loss: 79.06291961669922\n",
      "Episode average V value: 23.499219020207722\n",
      "Average (on the epoch) training loss: 77.17820739746094\n",
      "Episode average V value: 44.16145706176758\n",
      "Average (on the epoch) training loss: 75.50242614746094\n",
      "Episode average V value: 57.96414566040039\n",
      "Average (on the epoch) training loss: 73.13092041015625\n",
      "Episode average V value: 26.88210932413737\n",
      "Average (on the epoch) training loss: 75.58982849121094\n",
      "Episode average V value: 48.26881345113119\n",
      "Average (on the epoch) training loss: 78.42436981201172\n",
      "Episode average V value: 55.96140670776367\n",
      "Average (on the epoch) training loss: 78.77693939208984\n",
      "Episode average V value: 49.47569274902344\n",
      "Average (on the epoch) training loss: 76.10848236083984\n",
      "Episode average V value: 38.96697998046875\n",
      "Average (on the epoch) training loss: 73.89945220947266\n",
      "Episode average V value: 47.78379360834757\n",
      "Average (on the epoch) training loss: 71.97566986083984\n",
      "Episode average V value: 45.67691386829723\n",
      "Average (on the epoch) training loss: 72.76167297363281\n",
      "Episode average V value: 25.130220413208008\n",
      "Average (on the epoch) training loss: 73.06998443603516\n",
      "Episode average V value: 49.48768615722656\n",
      "Average (on the epoch) training loss: 72.59732818603516\n",
      "Episode average V value: 42.54274789492289\n",
      "Average (on the epoch) training loss: 71.74237823486328\n",
      "Episode average V value: 49.59741711616516\n",
      "Average (on the epoch) training loss: 72.85924530029297\n",
      "Episode average V value: 45.58555603027344\n",
      "Average (on the epoch) training loss: 73.44011688232422\n",
      "Episode average V value: 52.38874830802282\n",
      "Average (on the epoch) training loss: 76.19738006591797\n",
      "Episode average V value: -398.57429178555805\n",
      "Average (on the epoch) training loss: 75.45648193359375\n",
      "Episode average V value: 52.39844599637118\n",
      "Average (on the epoch) training loss: 74.864013671875\n",
      "Episode average V value: 68.5510025024414\n",
      "Average (on the epoch) training loss: 74.28924560546875\n",
      "Episode average V value: 66.92989826202393\n",
      "Average (on the epoch) training loss: 73.58794403076172\n",
      "Episode average V value: 37.97531143824259\n",
      "Average (on the epoch) training loss: 72.89512634277344\n",
      "Episode average V value: 29.10910605887572\n",
      "Average (on the epoch) training loss: 73.44050598144531\n",
      "Episode average V value: 57.830193956693016\n",
      "Average (on the epoch) training loss: 72.58611297607422\n",
      "Episode average V value: 45.05735952203924\n",
      "Average (on the epoch) training loss: 73.10448455810547\n",
      "Episode average V value: 46.218563079833984\n",
      "Average (on the epoch) training loss: 71.6928482055664\n",
      "Episode average V value: 39.20875930786133\n",
      "Average (on the epoch) training loss: 71.11921691894531\n",
      "Episode average V value: 60.28895950317383\n",
      "Average (on the epoch) training loss: 72.14885711669922\n",
      "Episode average V value: 40.66900328795115\n",
      "Average (on the epoch) training loss: 70.94178771972656\n",
      "Episode average V value: 39.35938437779745\n",
      "Average (on the epoch) training loss: 71.43130493164062\n",
      "Episode average V value: 53.43540175755819\n",
      "Average (on the epoch) training loss: 70.93768310546875\n",
      "Episode average V value: 34.20151154200236\n",
      "Average (on the epoch) training loss: 71.29290008544922\n",
      "Episode average V value: 52.4737221399943\n",
      "Average (on the epoch) training loss: 70.72074890136719\n",
      "Episode average V value: 58.44041061401367\n",
      "Average (on the epoch) training loss: 70.86295318603516\n",
      "Episode average V value: 40.616764068603516\n",
      "Average (on the epoch) training loss: 71.50836944580078\n",
      "Episode average V value: 42.891934076944985\n",
      "Average (on the epoch) training loss: 71.52401733398438\n",
      "Episode average V value: 32.09054220806468\n",
      "Average (on the epoch) training loss: 70.69847106933594\n",
      "Episode average V value: 29.255822896957397\n",
      "Average (on the epoch) training loss: 70.42646026611328\n",
      "Episode average V value: 55.23281478881836\n",
      "Average (on the epoch) training loss: 70.20467376708984\n",
      "Episode average V value: 56.44448963801066\n",
      "Average (on the epoch) training loss: 69.73628997802734\n",
      "Episode average V value: 66.9572982788086\n",
      "Average (on the epoch) training loss: 70.20954895019531\n",
      "Episode average V value: 63.58426076715643\n",
      "Average (on the epoch) training loss: 70.92501831054688\n",
      "Episode average V value: 37.80912725130717\n",
      "Average (on the epoch) training loss: 70.58847045898438\n",
      "Episode average V value: 53.2574462890625\n",
      "Average (on the epoch) training loss: 71.18559265136719\n",
      "Episode average V value: 38.58351103464762\n",
      "Average (on the epoch) training loss: 70.8107681274414\n",
      "Episode average V value: 49.86083157857259\n",
      "Average (on the epoch) training loss: 70.6176986694336\n",
      "Episode average V value: 31.689025561014812\n",
      "Average (on the epoch) training loss: 70.96183776855469\n",
      "Episode average V value: 40.59361402193705\n",
      "Average (on the epoch) training loss: 70.43585205078125\n",
      "Episode average V value: 56.14817810058594\n",
      "Average (on the epoch) training loss: 70.22923278808594\n",
      "Episode average V value: 49.060452175140384\n",
      "Average (on the epoch) training loss: 70.14726257324219\n",
      "Episode average V value: 22.68657382329305\n",
      "Average (on the epoch) training loss: 69.40274810791016\n",
      "Episode average V value: 35.54855672518412\n",
      "Average (on the epoch) training loss: 68.91291046142578\n",
      "Episode average V value: 34.430028756459556\n",
      "Average (on the epoch) training loss: 68.4299545288086\n",
      "Episode average V value: 31.66736356417338\n",
      "Average (on the epoch) training loss: 68.275634765625\n",
      "Episode average V value: 54.449002265930176\n",
      "Average (on the epoch) training loss: 67.81121826171875\n",
      "Episode average V value: 44.66896843910217\n",
      "Average (on the epoch) training loss: 68.07352447509766\n",
      "Episode average V value: 28.45355339050293\n",
      "Average (on the epoch) training loss: 68.07856750488281\n",
      "Episode average V value: 35.175743103027344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 67.50959777832031\n",
      "Episode average V value: -374.78287744522095\n",
      "Average (on the epoch) training loss: 67.533935546875\n",
      "Episode average V value: 44.83186423778534\n",
      "Average (on the epoch) training loss: 68.04953002929688\n",
      "Episode average V value: 26.76103909810384\n",
      "Average (on the epoch) training loss: 68.51844024658203\n",
      "Episode average V value: 52.830758253733315\n",
      "Average (on the epoch) training loss: 68.30020141601562\n",
      "Episode average V value: 40.79864163832231\n",
      "Average (on the epoch) training loss: 68.55631256103516\n",
      "Episode average V value: 38.62673234939575\n",
      "Average (on the epoch) training loss: 68.68193054199219\n",
      "Episode average V value: 47.915828704833984\n",
      "Average (on the epoch) training loss: 68.51582336425781\n",
      "Episode average V value: 31.697423299153645\n",
      "Average (on the epoch) training loss: 68.3259506225586\n",
      "Episode average V value: 46.01983226429332\n",
      "Average (on the epoch) training loss: 68.18515014648438\n",
      "Episode average V value: 31.73385492960612\n",
      "Average (on the epoch) training loss: 68.98797607421875\n",
      "Episode average V value: 31.9384407563643\n",
      "Average (on the epoch) training loss: 68.53934478759766\n",
      "Episode average V value: 45.78475058078766\n",
      "Average (on the epoch) training loss: 68.372314453125\n",
      "Episode average V value: 57.97998889287313\n",
      "Average (on the epoch) training loss: 68.09274291992188\n",
      "Episode average V value: 24.819216641512785\n",
      "Average (on the epoch) training loss: 67.87753295898438\n",
      "Episode average V value: 41.81917476654053\n",
      "Average (on the epoch) training loss: 67.60624694824219\n",
      "Episode average V value: 32.92731857299805\n",
      "Average (on the epoch) training loss: 67.5160903930664\n",
      "Episode average V value: 39.474687258402504\n",
      "Average (on the epoch) training loss: 67.68072509765625\n",
      "Episode average V value: 31.7924009958903\n",
      "Average (on the epoch) training loss: 67.3555679321289\n",
      "Episode average V value: 26.591565281152725\n",
      "Average (on the epoch) training loss: 67.71136474609375\n",
      "Episode average V value: 50.21146011352539\n",
      "Average (on the epoch) training loss: 67.55216217041016\n",
      "Episode average V value: 38.140235582987465\n",
      "Average (on the epoch) training loss: 67.46097564697266\n",
      "Episode average V value: 35.05640411376953\n",
      "Average (on the epoch) training loss: 67.60582733154297\n",
      "Episode average V value: 62.256202697753906\n",
      "Average (on the epoch) training loss: 67.3899917602539\n",
      "Episode average V value: 46.841668943564095\n",
      "Average (on the epoch) training loss: 67.04801940917969\n",
      "Episode average V value: 38.51469802856445\n",
      "Average (on the epoch) training loss: 66.87284088134766\n",
      "Episode average V value: 52.46298694610596\n",
      "Average (on the epoch) training loss: 66.591064453125\n",
      "Episode average V value: 61.40028038024902\n",
      "Average (on the epoch) training loss: 66.75408935546875\n",
      "Episode average V value: 23.108399152755737\n",
      "Average (on the epoch) training loss: 67.1269302368164\n",
      "Episode average V value: 35.683971616956924\n",
      "Average (on the epoch) training loss: 67.01289367675781\n",
      "Episode average V value: 48.01495472590128\n",
      "Average (on the epoch) training loss: 66.62987518310547\n",
      "Episode average V value: 35.751079385930844\n",
      "Average (on the epoch) training loss: 66.49311065673828\n",
      "Episode average V value: 39.235294342041016\n",
      "Average (on the epoch) training loss: 66.27616119384766\n",
      "Episode average V value: 33.81404495239258\n",
      "Average (on the epoch) training loss: 66.24344635009766\n",
      "Episode average V value: 16.9950749874115\n",
      "Average (on the epoch) training loss: 65.89158630371094\n",
      "Episode average V value: 41.60708503723144\n",
      "epoch 8:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 57.93357849121094\n",
      "Episode average V value: 36.70958232879639\n",
      "Average (on the epoch) training loss: 57.60795974731445\n",
      "Episode average V value: 59.281585693359375\n",
      "Average (on the epoch) training loss: 61.85165023803711\n",
      "Episode average V value: 8.769495964050293\n",
      "Average (on the epoch) training loss: 67.18961334228516\n",
      "Episode average V value: 36.18809623718262\n",
      "Average (on the epoch) training loss: 74.75653839111328\n",
      "Episode average V value: 45.693180084228516\n",
      "Average (on the epoch) training loss: 67.0759506225586\n",
      "Episode average V value: 39.79054752985636\n",
      "Average (on the epoch) training loss: 66.13973236083984\n",
      "Episode average V value: 42.69824695587158\n",
      "Average (on the epoch) training loss: 70.42021942138672\n",
      "Episode average V value: 42.823299407958984\n",
      "Average (on the epoch) training loss: 67.80905151367188\n",
      "Episode average V value: 42.09329188953746\n",
      "Average (on the epoch) training loss: 70.20431518554688\n",
      "Episode average V value: 29.434883375962574\n",
      "Average (on the epoch) training loss: 68.9206314086914\n",
      "Episode average V value: 44.095656394958496\n",
      "Average (on the epoch) training loss: 70.12362670898438\n",
      "Episode average V value: 47.790605306625366\n",
      "Average (on the epoch) training loss: 69.91617584228516\n",
      "Episode average V value: 46.95261001586914\n",
      "Average (on the epoch) training loss: 68.08802795410156\n",
      "Episode average V value: 39.99646202723185\n",
      "Average (on the epoch) training loss: 66.3478012084961\n",
      "Episode average V value: 75.17751624367453\n",
      "Average (on the epoch) training loss: 65.5751953125\n",
      "Episode average V value: 57.10774230957031\n",
      "Average (on the epoch) training loss: 66.0050277709961\n",
      "Episode average V value: 42.063812255859375\n",
      "Average (on the epoch) training loss: 67.27003479003906\n",
      "Episode average V value: 34.04521560668945\n",
      "Average (on the epoch) training loss: 66.19113159179688\n",
      "Episode average V value: 38.17869758605957\n",
      "Average (on the epoch) training loss: 64.3393783569336\n",
      "Episode average V value: 46.11796657244364\n",
      "Average (on the epoch) training loss: 63.03340530395508\n",
      "Episode average V value: 69.09024810791016\n",
      "Average (on the epoch) training loss: 61.88524627685547\n",
      "Episode average V value: 55.33554935455322\n",
      "Average (on the epoch) training loss: 61.971961975097656\n",
      "Episode average V value: 48.78473703066508\n",
      "Average (on the epoch) training loss: 62.54946517944336\n",
      "Episode average V value: 34.15522567431132\n",
      "Average (on the epoch) training loss: 61.24789810180664\n",
      "Episode average V value: 42.405548095703125\n",
      "Average (on the epoch) training loss: 60.373260498046875\n",
      "Episode average V value: 34.20012982686361\n",
      "Average (on the epoch) training loss: 61.387054443359375\n",
      "Episode average V value: 47.668453216552734\n",
      "Average (on the epoch) training loss: 61.23169708251953\n",
      "Episode average V value: 55.639423847198486\n",
      "Average (on the epoch) training loss: 60.99535369873047\n",
      "Episode average V value: 44.20197296142578\n",
      "Average (on the epoch) training loss: 59.78692626953125\n",
      "Episode average V value: 54.27296129862467\n",
      "Average (on the epoch) training loss: 61.2220458984375\n",
      "Episode average V value: 78.15824127197266\n",
      "Average (on the epoch) training loss: 60.88151550292969\n",
      "Episode average V value: 45.34798047939936\n",
      "Average (on the epoch) training loss: 60.53786849975586\n",
      "Episode average V value: 45.28754266103109\n",
      "Average (on the epoch) training loss: 60.84795379638672\n",
      "Episode average V value: 51.06804903348287\n",
      "Average (on the epoch) training loss: 59.89258575439453\n",
      "Episode average V value: 32.04656449953715\n",
      "Average (on the epoch) training loss: 60.34429168701172\n",
      "Episode average V value: 64.56252479553223\n",
      "Average (on the epoch) training loss: 61.17779541015625\n",
      "Episode average V value: 51.11927744746208\n",
      "Average (on the epoch) training loss: 61.512454986572266\n",
      "Episode average V value: 58.36079446474711\n",
      "Average (on the epoch) training loss: 62.777008056640625\n",
      "Episode average V value: 44.39350891113281\n",
      "Average (on the epoch) training loss: 62.03583526611328\n",
      "Episode average V value: 35.12077287832896\n",
      "Average (on the epoch) training loss: 63.00205612182617\n",
      "Episode average V value: 58.880184173583984\n",
      "Average (on the epoch) training loss: 62.22924041748047\n",
      "Episode average V value: 38.57719421386719\n",
      "Average (on the epoch) training loss: 62.19156265258789\n",
      "Episode average V value: 56.3977085460316\n",
      "Average (on the epoch) training loss: 61.95595932006836\n",
      "Episode average V value: 51.01568603515625\n",
      "Average (on the epoch) training loss: 61.89231872558594\n",
      "Episode average V value: 62.63053512573242\n",
      "Average (on the epoch) training loss: 61.72344970703125\n",
      "Episode average V value: 41.273238023122154\n",
      "Average (on the epoch) training loss: 61.252132415771484\n",
      "Episode average V value: 45.7350002635609\n",
      "Average (on the epoch) training loss: 60.5107421875\n",
      "Episode average V value: 29.792621930440266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 60.15327453613281\n",
      "Episode average V value: 79.31856536865234\n",
      "Average (on the epoch) training loss: 59.960975646972656\n",
      "Episode average V value: 52.43359375\n",
      "Average (on the epoch) training loss: 60.767181396484375\n",
      "Episode average V value: 71.31851804256439\n",
      "Average (on the epoch) training loss: 60.3735237121582\n",
      "Episode average V value: 28.454360783100128\n",
      "Average (on the epoch) training loss: 60.27260971069336\n",
      "Episode average V value: 53.75787480672201\n",
      "Average (on the epoch) training loss: 59.93838119506836\n",
      "Episode average V value: 43.944031715393066\n",
      "Average (on the epoch) training loss: 59.30061721801758\n",
      "Episode average V value: 36.88808059692383\n",
      "Average (on the epoch) training loss: 59.42716598510742\n",
      "Episode average V value: 39.971830974925645\n",
      "Average (on the epoch) training loss: 60.789119720458984\n",
      "Episode average V value: 36.21936321258545\n",
      "Average (on the epoch) training loss: 60.20027542114258\n",
      "Episode average V value: 33.0228157043457\n",
      "Average (on the epoch) training loss: 59.95060729980469\n",
      "Episode average V value: 70.55278778076172\n",
      "Average (on the epoch) training loss: 59.85048294067383\n",
      "Episode average V value: 36.502507050832115\n",
      "Average (on the epoch) training loss: 59.396366119384766\n",
      "Episode average V value: 38.01317180286754\n",
      "Average (on the epoch) training loss: 59.27290344238281\n",
      "Episode average V value: 50.76387023925781\n",
      "Average (on the epoch) training loss: 60.04259490966797\n",
      "Episode average V value: 63.3741569519043\n",
      "Average (on the epoch) training loss: 60.41093063354492\n",
      "Episode average V value: 22.074037233988445\n",
      "Average (on the epoch) training loss: 60.20967483520508\n",
      "Episode average V value: 37.022866566975914\n",
      "Average (on the epoch) training loss: 60.82265853881836\n",
      "Episode average V value: 27.947560906410217\n",
      "Average (on the epoch) training loss: 60.910064697265625\n",
      "Episode average V value: 43.708784421284996\n",
      "Average (on the epoch) training loss: 60.334442138671875\n",
      "Episode average V value: 27.502069155375164\n",
      "Average (on the epoch) training loss: 60.140560150146484\n",
      "Episode average V value: 45.56633758544922\n",
      "Average (on the epoch) training loss: 60.010677337646484\n",
      "Episode average V value: 54.899993896484375\n",
      "Average (on the epoch) training loss: 60.29453659057617\n",
      "Episode average V value: 33.77717773119608\n",
      "Average (on the epoch) training loss: 60.480777740478516\n",
      "Episode average V value: 29.186758041381836\n",
      "Average (on the epoch) training loss: 60.016605377197266\n",
      "Episode average V value: 64.02454376220703\n",
      "Average (on the epoch) training loss: 60.693878173828125\n",
      "Episode average V value: 36.33178234100342\n",
      "Average (on the epoch) training loss: 60.97079086303711\n",
      "Episode average V value: 42.54391860961914\n",
      "Average (on the epoch) training loss: 60.90849304199219\n",
      "Episode average V value: 44.545928955078125\n",
      "Average (on the epoch) training loss: 60.5207405090332\n",
      "Episode average V value: 39.57712825139364\n",
      "Average (on the epoch) training loss: 60.81779098510742\n",
      "Episode average V value: 29.533975501855213\n",
      "Average (on the epoch) training loss: 60.99407196044922\n",
      "Episode average V value: -384.0431372324626\n",
      "Average (on the epoch) training loss: 60.672420501708984\n",
      "Episode average V value: 47.01244195302328\n",
      "Average (on the epoch) training loss: 60.68429183959961\n",
      "Episode average V value: 44.477011839548744\n",
      "Average (on the epoch) training loss: 60.641239166259766\n",
      "Episode average V value: 43.9495964050293\n",
      "Average (on the epoch) training loss: 60.50912094116211\n",
      "Episode average V value: 24.448678692181904\n",
      "Average (on the epoch) training loss: 60.46034622192383\n",
      "Episode average V value: 31.539973172274504\n",
      "Average (on the epoch) training loss: 60.41337966918945\n",
      "Episode average V value: 20.35736147562663\n",
      "Average (on the epoch) training loss: 60.26050567626953\n",
      "Episode average V value: 31.905270258585613\n",
      "Average (on the epoch) training loss: 59.962799072265625\n",
      "Episode average V value: 23.029384930928547\n",
      "Average (on the epoch) training loss: 60.98927688598633\n",
      "Episode average V value: -346.5934076309204\n",
      "Average (on the epoch) training loss: 61.077598571777344\n",
      "Episode average V value: 41.94435898462931\n",
      "Average (on the epoch) training loss: 61.05221939086914\n",
      "Episode average V value: 34.201040744781494\n",
      "Average (on the epoch) training loss: 60.972328186035156\n",
      "Episode average V value: 48.355220794677734\n",
      "Average (on the epoch) training loss: 60.61176681518555\n",
      "Episode average V value: 44.4009682337443\n",
      "Average (on the epoch) training loss: 61.06587600708008\n",
      "Episode average V value: 41.869070053100586\n",
      "Average (on the epoch) training loss: 60.81934356689453\n",
      "Episode average V value: 55.19853210449219\n",
      "Average (on the epoch) training loss: 60.46391677856445\n",
      "Episode average V value: 38.56638558705648\n",
      "Average (on the epoch) training loss: 60.43775177001953\n",
      "Episode average V value: 50.09736855824789\n",
      "Average (on the epoch) training loss: 60.180233001708984\n",
      "Episode average V value: 44.980024337768555\n",
      "Average (on the epoch) training loss: 59.82164001464844\n",
      "Episode average V value: 10.867896874745687\n",
      "Average (on the epoch) training loss: 60.27397537231445\n",
      "Episode average V value: 57.97425524393717\n",
      "Average (on the epoch) training loss: 59.93535232543945\n",
      "Episode average V value: 53.19688034057617\n",
      "epoch 9:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 122.38897705078125\n",
      "Episode average V value: 38.459046045939125\n",
      "Average (on the epoch) training loss: 114.4082260131836\n",
      "Episode average V value: 27.1947021484375\n",
      "Average (on the epoch) training loss: 87.78431701660156\n",
      "Episode average V value: 49.04620361328125\n",
      "Average (on the epoch) training loss: 86.80973052978516\n",
      "Episode average V value: 38.33557287851969\n",
      "Average (on the epoch) training loss: 80.84882354736328\n",
      "Episode average V value: 33.13197342554728\n",
      "Average (on the epoch) training loss: 76.27190399169922\n",
      "Episode average V value: 37.32365036010742\n",
      "Average (on the epoch) training loss: 68.78340911865234\n",
      "Episode average V value: 39.749603271484375\n",
      "Average (on the epoch) training loss: 64.83928680419922\n",
      "Episode average V value: 41.53460709253947\n",
      "Average (on the epoch) training loss: 64.19029235839844\n",
      "Episode average V value: 29.389808257420857\n",
      "Average (on the epoch) training loss: 61.00011444091797\n",
      "Episode average V value: 48.625484466552734\n",
      "Average (on the epoch) training loss: 60.034549713134766\n",
      "Episode average V value: 55.044065648859196\n",
      "Average (on the epoch) training loss: 62.82958984375\n",
      "Episode average V value: 34.46498187383016\n",
      "Average (on the epoch) training loss: 64.12744140625\n",
      "Episode average V value: 37.07645034790039\n",
      "Average (on the epoch) training loss: 62.91074752807617\n",
      "Episode average V value: 23.31960105895996\n",
      "Average (on the epoch) training loss: 64.23226928710938\n",
      "Episode average V value: 43.817203521728516\n",
      "Average (on the epoch) training loss: 62.35408401489258\n",
      "Episode average V value: 30.814485549926758\n",
      "Average (on the epoch) training loss: 60.58000183105469\n",
      "Episode average V value: 63.17738405863444\n",
      "Average (on the epoch) training loss: 59.02986526489258\n",
      "Episode average V value: 37.471757094065346\n",
      "Average (on the epoch) training loss: 58.409400939941406\n",
      "Episode average V value: 36.06861011187235\n",
      "Average (on the epoch) training loss: 59.282020568847656\n",
      "Episode average V value: 15.966776053110758\n",
      "Average (on the epoch) training loss: 57.64812088012695\n",
      "Episode average V value: 44.04739761352539\n",
      "Average (on the epoch) training loss: 57.182437896728516\n",
      "Episode average V value: 30.016845703125\n",
      "Average (on the epoch) training loss: 58.01888656616211\n",
      "Episode average V value: 23.68339729309082\n",
      "Average (on the epoch) training loss: 56.89987564086914\n",
      "Episode average V value: 43.06926647822062\n",
      "Average (on the epoch) training loss: 55.67167282104492\n",
      "Episode average V value: 49.29547230402628\n",
      "Average (on the epoch) training loss: 54.88707733154297\n",
      "Episode average V value: 44.5613864551891\n",
      "Average (on the epoch) training loss: 55.62205123901367\n",
      "Episode average V value: 24.525536000728607\n",
      "Average (on the epoch) training loss: 54.68165969848633\n",
      "Episode average V value: 62.792564392089844\n",
      "Average (on the epoch) training loss: 55.88571548461914\n",
      "Episode average V value: 51.0471023718516\n",
      "Average (on the epoch) training loss: 56.83443832397461\n",
      "Episode average V value: -402.6815568606059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 57.36750793457031\n",
      "Episode average V value: 26.56163191795349\n",
      "Average (on the epoch) training loss: 56.95487976074219\n",
      "Episode average V value: 35.08120699723562\n",
      "Average (on the epoch) training loss: 57.46983337402344\n",
      "Episode average V value: 45.38765001296997\n",
      "Average (on the epoch) training loss: 58.60548782348633\n",
      "Episode average V value: 36.41127395629883\n",
      "Average (on the epoch) training loss: 57.97949981689453\n",
      "Episode average V value: 57.041839599609375\n",
      "Average (on the epoch) training loss: 58.37285614013672\n",
      "Episode average V value: 55.3868293762207\n",
      "Average (on the epoch) training loss: 59.84027099609375\n",
      "Episode average V value: 41.36197073260943\n",
      "Average (on the epoch) training loss: 60.12434768676758\n",
      "Episode average V value: 49.79853439331055\n",
      "Average (on the epoch) training loss: 60.00923156738281\n",
      "Episode average V value: -344.36647349596024\n",
      "Average (on the epoch) training loss: 60.47171401977539\n",
      "Episode average V value: 30.516556653109465\n",
      "Average (on the epoch) training loss: 61.91415786743164\n",
      "Episode average V value: 45.49024097124735\n",
      "Average (on the epoch) training loss: 61.9880256652832\n",
      "Episode average V value: 36.02939642559398\n",
      "Average (on the epoch) training loss: 61.69279861450195\n",
      "Episode average V value: 47.81793626149496\n",
      "Average (on the epoch) training loss: 61.701942443847656\n",
      "Episode average V value: 50.864620208740234\n",
      "Average (on the epoch) training loss: 61.72404479980469\n",
      "Episode average V value: 42.92545700073242\n",
      "Average (on the epoch) training loss: 62.63187789916992\n",
      "Episode average V value: 46.59722129503886\n",
      "Average (on the epoch) training loss: 63.013214111328125\n",
      "Episode average V value: 51.17968307841908\n",
      "Average (on the epoch) training loss: 63.49641799926758\n",
      "Episode average V value: 50.72280196348826\n",
      "Average (on the epoch) training loss: 63.04695510864258\n",
      "Episode average V value: 37.864122112592064\n",
      "Average (on the epoch) training loss: 62.53286361694336\n",
      "Episode average V value: 66.81751251220703\n",
      "Average (on the epoch) training loss: 62.63530349731445\n",
      "Episode average V value: 44.099151611328125\n",
      "Average (on the epoch) training loss: 62.183982849121094\n",
      "Episode average V value: 50.67403976122538\n",
      "Average (on the epoch) training loss: 61.83295440673828\n",
      "Episode average V value: 43.97208786010742\n",
      "Average (on the epoch) training loss: 61.88216018676758\n",
      "Episode average V value: 28.97800636291504\n",
      "Average (on the epoch) training loss: 61.71712875366211\n",
      "Episode average V value: -387.33675988515216\n",
      "Average (on the epoch) training loss: 62.30683898925781\n",
      "Episode average V value: 48.429256439208984\n",
      "Average (on the epoch) training loss: 61.8271598815918\n",
      "Episode average V value: 48.64976930618286\n",
      "Average (on the epoch) training loss: 61.40364456176758\n",
      "Episode average V value: 45.427527080882676\n",
      "Average (on the epoch) training loss: 61.8293342590332\n",
      "Episode average V value: 51.508499492298476\n",
      "Average (on the epoch) training loss: 61.802452087402344\n",
      "Episode average V value: 57.25948222478231\n",
      "Average (on the epoch) training loss: 61.395042419433594\n",
      "Episode average V value: 60.491196950276695\n",
      "Average (on the epoch) training loss: 61.6943473815918\n",
      "Episode average V value: 38.38147222995758\n",
      "Average (on the epoch) training loss: 61.535858154296875\n",
      "Episode average V value: 17.20471779505412\n",
      "Average (on the epoch) training loss: 61.57045364379883\n",
      "Episode average V value: 66.34344482421875\n",
      "Average (on the epoch) training loss: 62.07272720336914\n",
      "Episode average V value: 35.42811367909113\n",
      "Average (on the epoch) training loss: 62.66128921508789\n",
      "Episode average V value: 35.60873838265737\n",
      "Average (on the epoch) training loss: 62.2376708984375\n",
      "Episode average V value: 49.54719988505045\n",
      "Average (on the epoch) training loss: 61.863006591796875\n",
      "Episode average V value: 53.79598021507263\n",
      "Average (on the epoch) training loss: 61.48160171508789\n",
      "Episode average V value: -351.68916908899945\n",
      "Average (on the epoch) training loss: 61.32852554321289\n",
      "Episode average V value: 57.122440338134766\n",
      "Average (on the epoch) training loss: 61.25867462158203\n",
      "Episode average V value: 63.02945113182068\n",
      "Average (on the epoch) training loss: 61.28260040283203\n",
      "Episode average V value: 51.45749600728353\n",
      "Average (on the epoch) training loss: 61.193538665771484\n",
      "Episode average V value: 38.77284415562948\n",
      "Average (on the epoch) training loss: 60.92634582519531\n",
      "Episode average V value: 26.737966060638428\n",
      "Average (on the epoch) training loss: 60.70558166503906\n",
      "Episode average V value: 26.94200587272644\n",
      "Average (on the epoch) training loss: 61.22352981567383\n",
      "Episode average V value: -323.2752300103505\n",
      "Average (on the epoch) training loss: 61.709678649902344\n",
      "Episode average V value: 32.44262067476908\n",
      "Average (on the epoch) training loss: 62.18075180053711\n",
      "Episode average V value: 31.97337015469869\n",
      "Average (on the epoch) training loss: 62.27455520629883\n",
      "Episode average V value: 51.5837516784668\n",
      "Average (on the epoch) training loss: 61.978004455566406\n",
      "Episode average V value: -384.27419900894165\n",
      "Average (on the epoch) training loss: 61.70402526855469\n",
      "Episode average V value: 37.76212024688721\n",
      "Average (on the epoch) training loss: 61.649723052978516\n",
      "Episode average V value: 48.318344513575234\n",
      "Average (on the epoch) training loss: 61.925575256347656\n",
      "Episode average V value: 54.64461016654968\n",
      "Average (on the epoch) training loss: 61.54850769042969\n",
      "Episode average V value: 52.01223639647166\n",
      "Average (on the epoch) training loss: 61.299747467041016\n",
      "Episode average V value: 53.014694611231484\n",
      "Average (on the epoch) training loss: 61.25891876220703\n",
      "Episode average V value: 40.43000062306722\n",
      "Average (on the epoch) training loss: 61.47508239746094\n",
      "Episode average V value: -428.7919761657715\n",
      "Average (on the epoch) training loss: 61.4729118347168\n",
      "Episode average V value: -348.2433195114136\n",
      "Average (on the epoch) training loss: 61.869293212890625\n",
      "Episode average V value: 49.880367279052734\n",
      "Average (on the epoch) training loss: 61.6030387878418\n",
      "Episode average V value: 50.16843795776367\n",
      "Average (on the epoch) training loss: 61.534141540527344\n",
      "Episode average V value: -361.58169889450073\n",
      "Average (on the epoch) training loss: 61.82765197753906\n",
      "Episode average V value: 50.59899282455444\n",
      "Average (on the epoch) training loss: 62.00871658325195\n",
      "Episode average V value: 49.765106757481895\n",
      "Average (on the epoch) training loss: 61.722774505615234\n",
      "Episode average V value: -370.4107486406962\n",
      "Average (on the epoch) training loss: 61.41725540161133\n",
      "Episode average V value: -361.52259341875714\n",
      "Average (on the epoch) training loss: 61.62662887573242\n",
      "Episode average V value: 55.07972717285156\n",
      "Average (on the epoch) training loss: 61.6978645324707\n",
      "Episode average V value: 34.234716614087425\n",
      "Average (on the epoch) training loss: 61.548397064208984\n",
      "Episode average V value: 56.21704943974813\n",
      "Average (on the epoch) training loss: 61.416770935058594\n",
      "Episode average V value: 89.13563601175944\n",
      "Average (on the epoch) training loss: 61.9849739074707\n",
      "Episode average V value: 51.02854919433594\n",
      "epoch 10:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 53.56597900390625\n",
      "Episode average V value: 51.97296396891276\n",
      "Average (on the epoch) training loss: 49.299468994140625\n",
      "Episode average V value: 72.47056579589844\n",
      "Average (on the epoch) training loss: 45.63805389404297\n",
      "Episode average V value: 66.1592788696289\n",
      "Average (on the epoch) training loss: 56.763729095458984\n",
      "Episode average V value: 39.26806640625\n",
      "Average (on the epoch) training loss: 69.77490234375\n",
      "Episode average V value: -362.4230950673421\n",
      "Average (on the epoch) training loss: 72.16001892089844\n",
      "Episode average V value: 43.151336669921875\n",
      "Average (on the epoch) training loss: 77.41577911376953\n",
      "Episode average V value: 51.6800328095754\n",
      "Average (on the epoch) training loss: 75.16539764404297\n",
      "Episode average V value: 28.729280471801758\n",
      "Average (on the epoch) training loss: 80.50304412841797\n",
      "Episode average V value: 59.89094161987305\n",
      "Average (on the epoch) training loss: 85.60755920410156\n",
      "Episode average V value: 40.66956603527069\n",
      "Average (on the epoch) training loss: 81.85987091064453\n",
      "Episode average V value: 34.005142291386925\n",
      "Average (on the epoch) training loss: 82.47139739990234\n",
      "Episode average V value: -356.7630883852641\n",
      "Average (on the epoch) training loss: 83.2967758178711\n",
      "Episode average V value: 49.039546966552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 81.4020004272461\n",
      "Episode average V value: 34.33161544799805\n",
      "Average (on the epoch) training loss: 83.42073822021484\n",
      "Episode average V value: 59.04407835006714\n",
      "Average (on the epoch) training loss: 84.36531829833984\n",
      "Episode average V value: 45.64945602416992\n",
      "Average (on the epoch) training loss: 81.44847106933594\n",
      "Episode average V value: 54.014984130859375\n",
      "Average (on the epoch) training loss: 81.2535629272461\n",
      "Episode average V value: 76.59064483642578\n",
      "Average (on the epoch) training loss: 78.89183807373047\n",
      "Episode average V value: 26.390718460083008\n",
      "Average (on the epoch) training loss: 79.14859771728516\n",
      "Episode average V value: 38.973697443803154\n",
      "Average (on the epoch) training loss: 77.26348876953125\n",
      "Episode average V value: 37.206997553507485\n",
      "Average (on the epoch) training loss: 79.15388488769531\n",
      "Episode average V value: 43.7974495454268\n",
      "Average (on the epoch) training loss: 78.08438873291016\n",
      "Episode average V value: 57.127227783203125\n",
      "Average (on the epoch) training loss: 77.53500366210938\n",
      "Episode average V value: 48.80682214101156\n",
      "Average (on the epoch) training loss: 76.54071807861328\n",
      "Episode average V value: 30.610981941223145\n",
      "Average (on the epoch) training loss: 76.11779022216797\n",
      "Episode average V value: 40.13852310180664\n",
      "Average (on the epoch) training loss: 74.69584655761719\n",
      "Episode average V value: 65.16611925760905\n",
      "Average (on the epoch) training loss: 74.59806060791016\n",
      "Episode average V value: 61.836917877197266\n",
      "Average (on the epoch) training loss: 75.01371002197266\n",
      "Episode average V value: 44.87404296795527\n",
      "Average (on the epoch) training loss: 74.53306579589844\n",
      "Episode average V value: 12.733705838521322\n",
      "Average (on the epoch) training loss: 74.52313995361328\n",
      "Episode average V value: 40.453543623288475\n",
      "Average (on the epoch) training loss: 74.7996597290039\n",
      "Episode average V value: 29.31336760520935\n",
      "Average (on the epoch) training loss: 76.05693817138672\n",
      "Episode average V value: -441.27174282073975\n",
      "Average (on the epoch) training loss: 75.94990539550781\n",
      "Episode average V value: 50.405887603759766\n",
      "Average (on the epoch) training loss: 77.853515625\n",
      "Episode average V value: 47.0715704758962\n",
      "Average (on the epoch) training loss: 77.34324645996094\n",
      "Episode average V value: 43.05546569824219\n",
      "Average (on the epoch) training loss: 76.39146423339844\n",
      "Episode average V value: 41.469958464304604\n",
      "Average (on the epoch) training loss: 75.89521789550781\n",
      "Episode average V value: 44.9498124556108\n",
      "Average (on the epoch) training loss: 75.36689758300781\n",
      "Episode average V value: 49.49324417114258\n",
      "Average (on the epoch) training loss: 75.88495635986328\n",
      "Episode average V value: 31.37072253227234\n",
      "Average (on the epoch) training loss: 76.6333236694336\n",
      "Episode average V value: 35.99989573160807\n",
      "Average (on the epoch) training loss: 76.24501037597656\n",
      "Episode average V value: 53.276437759399414\n",
      "Average (on the epoch) training loss: 76.46286010742188\n",
      "Episode average V value: 47.82470099131266\n",
      "Average (on the epoch) training loss: 75.39959716796875\n",
      "Episode average V value: 47.95975732803345\n",
      "Average (on the epoch) training loss: 74.66859436035156\n",
      "Episode average V value: 58.99865053097407\n",
      "Average (on the epoch) training loss: 73.69007873535156\n",
      "Episode average V value: 39.22188870112101\n",
      "Average (on the epoch) training loss: 73.08534240722656\n",
      "Episode average V value: 43.535337130228676\n",
      "Average (on the epoch) training loss: 73.89077758789062\n",
      "Episode average V value: 45.17930221557617\n",
      "Average (on the epoch) training loss: 73.96525573730469\n",
      "Episode average V value: 47.62380361557007\n",
      "Average (on the epoch) training loss: 74.54158782958984\n",
      "Episode average V value: 46.59454107284546\n",
      "Average (on the epoch) training loss: 74.29364013671875\n",
      "Episode average V value: 46.43184200922648\n",
      "Average (on the epoch) training loss: 74.42725372314453\n",
      "Episode average V value: 36.894392331441246\n",
      "Average (on the epoch) training loss: 73.60214233398438\n",
      "Episode average V value: 48.06884202090177\n",
      "Average (on the epoch) training loss: 73.59632873535156\n",
      "Episode average V value: 34.96013641357422\n",
      "Average (on the epoch) training loss: 73.01986694335938\n",
      "Episode average V value: 47.36393610636393\n",
      "Average (on the epoch) training loss: 72.92643737792969\n",
      "Episode average V value: 37.02596457799276\n",
      "Average (on the epoch) training loss: 72.43417358398438\n",
      "Episode average V value: 22.54844180020419\n",
      "Average (on the epoch) training loss: 72.19843292236328\n",
      "Episode average V value: 71.12997833887736\n",
      "Average (on the epoch) training loss: 72.25810241699219\n",
      "Episode average V value: 50.055423736572266\n",
      "Average (on the epoch) training loss: 72.1736831665039\n",
      "Episode average V value: 42.30104064941406\n",
      "Average (on the epoch) training loss: 71.9776382446289\n",
      "Episode average V value: 42.0811413526535\n",
      "Average (on the epoch) training loss: 71.43077850341797\n",
      "Episode average V value: 26.323873281478882\n",
      "Average (on the epoch) training loss: 70.75660705566406\n",
      "Episode average V value: 36.31305122375488\n",
      "Average (on the epoch) training loss: 71.52987670898438\n",
      "Episode average V value: 44.41818046569824\n",
      "Average (on the epoch) training loss: 70.95826721191406\n",
      "Episode average V value: 59.97935485839844\n",
      "Average (on the epoch) training loss: 70.45252990722656\n",
      "Episode average V value: 47.886268297831215\n",
      "Average (on the epoch) training loss: 70.24769592285156\n",
      "Episode average V value: 34.822731812795006\n",
      "Average (on the epoch) training loss: 69.68736267089844\n",
      "Episode average V value: 51.06097865104675\n",
      "Average (on the epoch) training loss: 69.4526596069336\n",
      "Episode average V value: 61.80278015136719\n",
      "Average (on the epoch) training loss: 69.34273529052734\n",
      "Episode average V value: 39.70596694946289\n",
      "Average (on the epoch) training loss: 68.818603515625\n",
      "Episode average V value: 42.304168701171875\n",
      "Average (on the epoch) training loss: 68.41514587402344\n",
      "Episode average V value: 52.73065757751465\n",
      "Average (on the epoch) training loss: 68.29350280761719\n",
      "Episode average V value: 29.379096508026123\n",
      "Average (on the epoch) training loss: 68.14187622070312\n",
      "Episode average V value: 37.11506271362305\n",
      "Average (on the epoch) training loss: 68.27501678466797\n",
      "Episode average V value: 39.244078636169434\n",
      "Average (on the epoch) training loss: 68.82598876953125\n",
      "Episode average V value: 44.92709732055664\n",
      "Average (on the epoch) training loss: 68.53974914550781\n",
      "Episode average V value: 36.943402449289955\n",
      "Average (on the epoch) training loss: 68.56733703613281\n",
      "Episode average V value: 62.97285842895508\n",
      "Average (on the epoch) training loss: 68.51660919189453\n",
      "Episode average V value: 36.27897489070892\n",
      "Average (on the epoch) training loss: 68.75818634033203\n",
      "Episode average V value: 38.26530838012695\n",
      "Average (on the epoch) training loss: 68.32513427734375\n",
      "Episode average V value: 44.22918701171875\n",
      "Average (on the epoch) training loss: 68.77386474609375\n",
      "Episode average V value: 48.31175231933594\n",
      "Average (on the epoch) training loss: 68.86922454833984\n",
      "Episode average V value: 29.608636339505512\n",
      "Average (on the epoch) training loss: 68.67156982421875\n",
      "Episode average V value: 44.259296576182045\n",
      "Average (on the epoch) training loss: 68.28913116455078\n",
      "Episode average V value: 59.70163345336914\n",
      "Average (on the epoch) training loss: 67.95784759521484\n",
      "Episode average V value: 40.48787530263265\n",
      "Average (on the epoch) training loss: 67.76714324951172\n",
      "Episode average V value: 43.97289673487345\n",
      "Average (on the epoch) training loss: 67.73591613769531\n",
      "Episode average V value: 45.17407512664795\n",
      "Average (on the epoch) training loss: 67.63196563720703\n",
      "Episode average V value: 40.87511412302653\n",
      "Average (on the epoch) training loss: 67.78070831298828\n",
      "Episode average V value: 31.01839788754781\n",
      "Average (on the epoch) training loss: 67.74040985107422\n",
      "Episode average V value: 31.76373052597046\n",
      "Average (on the epoch) training loss: 67.88866424560547\n",
      "Episode average V value: 47.33243942260742\n",
      "Average (on the epoch) training loss: 67.9217300415039\n",
      "Episode average V value: 51.68405532836914\n",
      "Average (on the epoch) training loss: 67.74252319335938\n",
      "Episode average V value: 52.96223449707031\n",
      "Average (on the epoch) training loss: 67.51713562011719\n",
      "Episode average V value: 48.994491736094155\n",
      "Average (on the epoch) training loss: 67.5728530883789\n",
      "Episode average V value: 32.94665348529816\n",
      "Average (on the epoch) training loss: 67.2690200805664\n",
      "Episode average V value: 35.649654388427734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 67.33709716796875\n",
      "Episode average V value: 39.90724563598633\n",
      "Average (on the epoch) training loss: 67.1836166381836\n",
      "Episode average V value: 30.24442179997762\n",
      "Average (on the epoch) training loss: 67.19612121582031\n",
      "Episode average V value: 42.60039043426514\n",
      "epoch 11:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 71.62702941894531\n",
      "Episode average V value: 45.00735092163086\n",
      "Average (on the epoch) training loss: 70.91973114013672\n",
      "Episode average V value: 50.29875564575195\n",
      "Average (on the epoch) training loss: 65.00467681884766\n",
      "Episode average V value: 47.62528053919474\n",
      "Average (on the epoch) training loss: 61.585391998291016\n",
      "Episode average V value: 51.60258865356445\n",
      "Average (on the epoch) training loss: 69.90634155273438\n",
      "Episode average V value: 42.92911911010742\n",
      "Average (on the epoch) training loss: 73.09326171875\n",
      "Episode average V value: 44.52664852142334\n",
      "Average (on the epoch) training loss: 71.28424835205078\n",
      "Episode average V value: 20.93777188387784\n",
      "Average (on the epoch) training loss: 68.63510131835938\n",
      "Episode average V value: 37.72409749031067\n",
      "Average (on the epoch) training loss: 67.3211669921875\n",
      "Episode average V value: 58.466495513916016\n",
      "Average (on the epoch) training loss: 63.75069808959961\n",
      "Episode average V value: 34.70427862803141\n",
      "Average (on the epoch) training loss: 61.50703430175781\n",
      "Episode average V value: 27.4585416217645\n",
      "Average (on the epoch) training loss: 62.05263137817383\n",
      "Episode average V value: 64.36325232187907\n",
      "Average (on the epoch) training loss: 60.18276596069336\n",
      "Episode average V value: 36.189030726750694\n",
      "Average (on the epoch) training loss: 60.03629684448242\n",
      "Episode average V value: 56.262330532073975\n",
      "Average (on the epoch) training loss: 63.51911926269531\n",
      "Episode average V value: 40.02280139923096\n",
      "Average (on the epoch) training loss: 62.702728271484375\n",
      "Episode average V value: 35.353155461224645\n",
      "Average (on the epoch) training loss: 61.23748779296875\n",
      "Episode average V value: 41.495792388916016\n",
      "Average (on the epoch) training loss: 60.26601791381836\n",
      "Episode average V value: 56.28343137105306\n",
      "Average (on the epoch) training loss: 59.85833740234375\n",
      "Episode average V value: 39.91840863227844\n",
      "Average (on the epoch) training loss: 60.06916809082031\n",
      "Episode average V value: 44.43534469604492\n",
      "Average (on the epoch) training loss: 61.40022277832031\n",
      "Episode average V value: 41.41979265213013\n",
      "Average (on the epoch) training loss: 59.84477996826172\n",
      "Episode average V value: 40.75971984863281\n",
      "Average (on the epoch) training loss: 61.08088302612305\n",
      "Episode average V value: 43.06875880559286\n",
      "Average (on the epoch) training loss: 60.47675323486328\n",
      "Episode average V value: 38.24136225382487\n",
      "Average (on the epoch) training loss: 60.110050201416016\n",
      "Episode average V value: 32.77602074363015\n",
      "Average (on the epoch) training loss: 60.6130485534668\n",
      "Episode average V value: 26.51095660527547\n",
      "Average (on the epoch) training loss: 59.49375915527344\n",
      "Episode average V value: 59.81949996948242\n",
      "Average (on the epoch) training loss: 58.502166748046875\n",
      "Episode average V value: 48.25276426835494\n",
      "Average (on the epoch) training loss: 59.93254852294922\n",
      "Episode average V value: -390.22276496887207\n",
      "Average (on the epoch) training loss: 59.894283294677734\n",
      "Episode average V value: 55.33208188143644\n",
      "Average (on the epoch) training loss: 61.646419525146484\n",
      "Episode average V value: 45.799041748046875\n",
      "Average (on the epoch) training loss: 63.8742561340332\n",
      "Episode average V value: 50.56150817871094\n",
      "Average (on the epoch) training loss: 63.362674713134766\n",
      "Episode average V value: 48.0255126953125\n",
      "Average (on the epoch) training loss: 62.943992614746094\n",
      "Episode average V value: 45.674003254283555\n",
      "Average (on the epoch) training loss: 61.97526168823242\n",
      "Episode average V value: 40.53293991088867\n",
      "Average (on the epoch) training loss: 62.67728042602539\n",
      "Episode average V value: 45.15973377227783\n",
      "Average (on the epoch) training loss: 62.015254974365234\n",
      "Episode average V value: 48.474700927734375\n",
      "Average (on the epoch) training loss: 61.07566833496094\n",
      "Episode average V value: 32.680231461922325\n",
      "Average (on the epoch) training loss: 61.49453353881836\n",
      "Episode average V value: 51.01801681518555\n",
      "Average (on the epoch) training loss: 61.354549407958984\n",
      "Episode average V value: 41.683281898498535\n",
      "Average (on the epoch) training loss: 60.816715240478516\n",
      "Episode average V value: 36.78363609313965\n",
      "Average (on the epoch) training loss: 61.08002471923828\n",
      "Episode average V value: 35.1523646513621\n",
      "Average (on the epoch) training loss: 62.02046203613281\n",
      "Episode average V value: 43.0131950378418\n",
      "Average (on the epoch) training loss: 61.41410446166992\n",
      "Episode average V value: 45.94425217310587\n",
      "Average (on the epoch) training loss: 60.905887603759766\n",
      "Episode average V value: 55.02778832117716\n",
      "Average (on the epoch) training loss: 61.23453140258789\n",
      "Episode average V value: 40.30395956039429\n",
      "Average (on the epoch) training loss: 61.43036651611328\n",
      "Episode average V value: 40.26152420043945\n",
      "Average (on the epoch) training loss: 61.11425018310547\n",
      "Episode average V value: 38.12404731909434\n",
      "Average (on the epoch) training loss: 61.87831497192383\n",
      "Episode average V value: 46.335045337677\n",
      "Average (on the epoch) training loss: 61.29605484008789\n",
      "Episode average V value: 52.0789794921875\n",
      "Average (on the epoch) training loss: 60.80414581298828\n",
      "Episode average V value: 49.72576904296875\n",
      "Average (on the epoch) training loss: 60.46186447143555\n",
      "Episode average V value: 55.30486583709717\n",
      "Average (on the epoch) training loss: 61.02513122558594\n",
      "Episode average V value: 35.835475047429405\n",
      "Average (on the epoch) training loss: 60.38508987426758\n",
      "Episode average V value: 35.302665869394936\n",
      "Average (on the epoch) training loss: 59.8414306640625\n",
      "Episode average V value: 40.83797836303711\n",
      "Average (on the epoch) training loss: 60.2343864440918\n",
      "Episode average V value: 41.924081007639565\n",
      "Average (on the epoch) training loss: 60.030029296875\n",
      "Episode average V value: 35.079734007517494\n",
      "Average (on the epoch) training loss: 60.1893424987793\n",
      "Episode average V value: 45.4334770043691\n",
      "Average (on the epoch) training loss: 59.9462776184082\n",
      "Episode average V value: 36.83829037348429\n",
      "Average (on the epoch) training loss: 59.658817291259766\n",
      "Episode average V value: 55.41317240397135\n",
      "Average (on the epoch) training loss: 59.522056579589844\n",
      "Episode average V value: 61.87924416859945\n",
      "Average (on the epoch) training loss: 59.85697937011719\n",
      "Episode average V value: 49.182658672332764\n",
      "Average (on the epoch) training loss: 59.495845794677734\n",
      "Episode average V value: 28.66826033592224\n",
      "Average (on the epoch) training loss: 59.979583740234375\n",
      "Episode average V value: 34.89313364028931\n",
      "Average (on the epoch) training loss: 59.593143463134766\n",
      "Episode average V value: 49.01148136456808\n",
      "Average (on the epoch) training loss: 59.043148040771484\n",
      "Episode average V value: 31.913273493448894\n",
      "Average (on the epoch) training loss: 59.50143814086914\n",
      "Episode average V value: 62.69680833816528\n",
      "Average (on the epoch) training loss: 59.010406494140625\n",
      "Episode average V value: 26.008933703104656\n",
      "Average (on the epoch) training loss: 59.680511474609375\n",
      "Episode average V value: 56.3576774597168\n",
      "Average (on the epoch) training loss: 59.395851135253906\n",
      "Episode average V value: 34.12190922101339\n",
      "Average (on the epoch) training loss: 59.42378234863281\n",
      "Episode average V value: 43.6882209777832\n",
      "Average (on the epoch) training loss: 59.36875915527344\n",
      "Episode average V value: 52.968631744384766\n",
      "Average (on the epoch) training loss: 59.988338470458984\n",
      "Episode average V value: 44.35214161872864\n",
      "Average (on the epoch) training loss: 59.70637893676758\n",
      "Episode average V value: 50.791141510009766\n",
      "Average (on the epoch) training loss: 59.4681510925293\n",
      "Episode average V value: 55.57625961303711\n",
      "Average (on the epoch) training loss: 59.2201042175293\n",
      "Episode average V value: 38.97280086170543\n",
      "Average (on the epoch) training loss: 59.00468444824219\n",
      "Episode average V value: 66.45458221435547\n",
      "Average (on the epoch) training loss: 59.38762283325195\n",
      "Episode average V value: 35.526253163814545\n",
      "Average (on the epoch) training loss: 59.616668701171875\n",
      "Episode average V value: 33.32930358250936\n",
      "Average (on the epoch) training loss: 59.24979019165039\n",
      "Episode average V value: 55.18960952758789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 59.043270111083984\n",
      "Episode average V value: 54.6661262512207\n",
      "Average (on the epoch) training loss: 58.91075134277344\n",
      "Episode average V value: 37.636566162109375\n",
      "Average (on the epoch) training loss: 58.59156036376953\n",
      "Episode average V value: 45.04707336425781\n",
      "Average (on the epoch) training loss: 58.51276779174805\n",
      "Episode average V value: 60.760842641194664\n",
      "Average (on the epoch) training loss: 58.32901382446289\n",
      "Episode average V value: 28.108295838038128\n",
      "Average (on the epoch) training loss: 58.081417083740234\n",
      "Episode average V value: 52.77542118231455\n",
      "Average (on the epoch) training loss: 58.32322311401367\n",
      "Episode average V value: 45.20811080932617\n",
      "Average (on the epoch) training loss: 58.416259765625\n",
      "Episode average V value: 41.741665840148926\n",
      "Average (on the epoch) training loss: 58.63760757446289\n",
      "Episode average V value: 39.64054250717163\n",
      "Average (on the epoch) training loss: 58.38371658325195\n",
      "Episode average V value: 46.034573793411255\n",
      "Average (on the epoch) training loss: 58.24775314331055\n",
      "Episode average V value: 53.950045903523765\n",
      "Average (on the epoch) training loss: 58.16218566894531\n",
      "Episode average V value: 58.48223876953125\n",
      "Average (on the epoch) training loss: 58.86048126220703\n",
      "Episode average V value: 41.34593017896017\n",
      "Average (on the epoch) training loss: 58.670806884765625\n",
      "Episode average V value: -348.52082029978436\n",
      "Average (on the epoch) training loss: 59.00564193725586\n",
      "Episode average V value: 41.65168380737305\n",
      "Average (on the epoch) training loss: 59.01625442504883\n",
      "Episode average V value: 45.269466400146484\n",
      "Average (on the epoch) training loss: 59.02543640136719\n",
      "Episode average V value: 43.45230007171631\n",
      "Average (on the epoch) training loss: 59.248809814453125\n",
      "Episode average V value: 45.482913970947266\n",
      "Average (on the epoch) training loss: 59.484004974365234\n",
      "Episode average V value: 39.60968933105469\n",
      "Average (on the epoch) training loss: 59.16929626464844\n",
      "Episode average V value: 36.15760473771529\n",
      "epoch 12:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 43.60661315917969\n",
      "Episode average V value: 35.57130209604899\n",
      "Average (on the epoch) training loss: 47.785648345947266\n",
      "Episode average V value: 45.79026444753011\n",
      "Average (on the epoch) training loss: 45.001556396484375\n",
      "Episode average V value: 47.576904296875\n",
      "Average (on the epoch) training loss: 43.62266159057617\n",
      "Episode average V value: 70.10208892822266\n",
      "Average (on the epoch) training loss: 44.093406677246094\n",
      "Episode average V value: 39.37152099609375\n",
      "Average (on the epoch) training loss: 49.5354118347168\n",
      "Episode average V value: 43.0744743347168\n",
      "Average (on the epoch) training loss: 49.5698127746582\n",
      "Episode average V value: 67.74814351399739\n",
      "Average (on the epoch) training loss: 47.53108596801758\n",
      "Episode average V value: 35.540776014328\n",
      "Average (on the epoch) training loss: 45.79736328125\n",
      "Episode average V value: 36.86582509676615\n",
      "Average (on the epoch) training loss: 45.087581634521484\n",
      "Episode average V value: 53.3897074063619\n",
      "Average (on the epoch) training loss: 44.58512496948242\n",
      "Episode average V value: 68.73554992675781\n",
      "Average (on the epoch) training loss: 47.98783874511719\n",
      "Episode average V value: 56.76016012827555\n",
      "Average (on the epoch) training loss: 46.43576431274414\n",
      "Episode average V value: 38.58071653048197\n",
      "Average (on the epoch) training loss: 47.59269332885742\n",
      "Episode average V value: 75.77332801818848\n",
      "Average (on the epoch) training loss: 48.72719192504883\n",
      "Episode average V value: 35.81221532821655\n",
      "Average (on the epoch) training loss: 50.45184326171875\n",
      "Episode average V value: 35.63125022252401\n",
      "Average (on the epoch) training loss: 53.7255744934082\n",
      "Episode average V value: 44.877388974030815\n",
      "Average (on the epoch) training loss: 55.22305679321289\n",
      "Episode average V value: 47.99857807159424\n",
      "Average (on the epoch) training loss: 55.920658111572266\n",
      "Episode average V value: 36.39034732182821\n",
      "Average (on the epoch) training loss: 55.26134490966797\n",
      "Episode average V value: 25.46446442604065\n",
      "Average (on the epoch) training loss: 55.20248794555664\n",
      "Episode average V value: 29.650136947631836\n",
      "Average (on the epoch) training loss: 55.91161346435547\n",
      "Episode average V value: 37.059504667917885\n",
      "Average (on the epoch) training loss: 54.79064178466797\n",
      "Episode average V value: 32.9867338700728\n",
      "Average (on the epoch) training loss: 54.192138671875\n",
      "Episode average V value: 74.21923828125\n",
      "Average (on the epoch) training loss: 53.223060607910156\n",
      "Episode average V value: 39.57488597523082\n",
      "Average (on the epoch) training loss: 53.24651336669922\n",
      "Episode average V value: 50.125362396240234\n",
      "Average (on the epoch) training loss: 54.2099494934082\n",
      "Episode average V value: 44.452056884765625\n",
      "Average (on the epoch) training loss: 53.9810676574707\n",
      "Episode average V value: 54.58813762664795\n",
      "Average (on the epoch) training loss: 53.3696403503418\n",
      "Episode average V value: 66.655179457231\n",
      "Average (on the epoch) training loss: 55.10794448852539\n",
      "Episode average V value: 48.92611348628998\n",
      "Average (on the epoch) training loss: 55.06892013549805\n",
      "Episode average V value: 48.93579387664795\n",
      "Average (on the epoch) training loss: 54.642242431640625\n",
      "Episode average V value: 56.58875370025635\n",
      "Average (on the epoch) training loss: 54.00597381591797\n",
      "Episode average V value: 58.00150775909424\n",
      "Average (on the epoch) training loss: 55.1517219543457\n",
      "Episode average V value: 28.77498225371043\n",
      "Average (on the epoch) training loss: 54.942726135253906\n",
      "Episode average V value: 35.917899738658555\n",
      "Average (on the epoch) training loss: 54.53700256347656\n",
      "Episode average V value: 46.3983736038208\n",
      "Average (on the epoch) training loss: 54.013240814208984\n",
      "Episode average V value: 50.03473170598348\n",
      "Average (on the epoch) training loss: 55.770118713378906\n",
      "Episode average V value: 65.47808074951172\n",
      "Average (on the epoch) training loss: 55.09728240966797\n",
      "Episode average V value: 36.2520846525828\n",
      "Average (on the epoch) training loss: 54.8855094909668\n",
      "Episode average V value: 38.7540717124939\n",
      "Average (on the epoch) training loss: 54.61233901977539\n",
      "Episode average V value: 55.26474380493164\n",
      "Average (on the epoch) training loss: 54.39089584350586\n",
      "Episode average V value: 44.2217903137207\n",
      "Average (on the epoch) training loss: 54.00801086425781\n",
      "Episode average V value: 53.660998940467834\n",
      "Average (on the epoch) training loss: 54.646663665771484\n",
      "Episode average V value: 39.87637710571289\n",
      "Average (on the epoch) training loss: 54.35795593261719\n",
      "Episode average V value: 43.11591068903605\n",
      "Average (on the epoch) training loss: 53.83785629272461\n",
      "Episode average V value: 51.50783920288086\n",
      "Average (on the epoch) training loss: 53.69060134887695\n",
      "Episode average V value: 63.87425231933594\n",
      "Average (on the epoch) training loss: 54.360103607177734\n",
      "Episode average V value: 47.66371536254883\n",
      "Average (on the epoch) training loss: 54.00330352783203\n",
      "Episode average V value: 48.55172348022461\n",
      "Average (on the epoch) training loss: 53.816802978515625\n",
      "Episode average V value: 51.33052062988281\n",
      "Average (on the epoch) training loss: 53.47658157348633\n",
      "Episode average V value: 54.3547477722168\n",
      "Average (on the epoch) training loss: 54.883113861083984\n",
      "Episode average V value: 43.7703857421875\n",
      "Average (on the epoch) training loss: 54.72097396850586\n",
      "Episode average V value: 44.4920539855957\n",
      "Average (on the epoch) training loss: 54.4747314453125\n",
      "Episode average V value: 55.42214436531067\n",
      "Average (on the epoch) training loss: 54.90449905395508\n",
      "Episode average V value: 45.6401252746582\n",
      "Average (on the epoch) training loss: 54.518951416015625\n",
      "Episode average V value: 25.95426074663798\n",
      "Average (on the epoch) training loss: 54.587867736816406\n",
      "Episode average V value: 32.41283313433329\n",
      "Average (on the epoch) training loss: 55.43964767456055\n",
      "Episode average V value: 8.341681003570557\n",
      "Average (on the epoch) training loss: 55.00890350341797\n",
      "Episode average V value: 50.43916320800781\n",
      "Average (on the epoch) training loss: 54.59575271606445\n",
      "Episode average V value: 51.08283615112305\n",
      "Average (on the epoch) training loss: 54.49339294433594\n",
      "Episode average V value: 44.03563874959946\n",
      "Average (on the epoch) training loss: 54.47872543334961\n",
      "Episode average V value: 35.48843002319336\n",
      "Average (on the epoch) training loss: 54.230323791503906\n",
      "Episode average V value: 54.710567474365234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 54.09965133666992\n",
      "Episode average V value: 39.994371760975234\n",
      "Average (on the epoch) training loss: 54.49409103393555\n",
      "Episode average V value: 49.65011215209961\n",
      "Average (on the epoch) training loss: 54.38311004638672\n",
      "Episode average V value: 48.605159759521484\n",
      "Average (on the epoch) training loss: 55.03810119628906\n",
      "Episode average V value: 53.939632415771484\n",
      "Average (on the epoch) training loss: 55.879032135009766\n",
      "Episode average V value: 51.944644927978516\n",
      "Average (on the epoch) training loss: 56.002586364746094\n",
      "Episode average V value: 29.6720684224909\n",
      "Average (on the epoch) training loss: 55.583900451660156\n",
      "Episode average V value: 31.45619010925293\n",
      "Average (on the epoch) training loss: 56.032718658447266\n",
      "Episode average V value: 25.30464267730713\n",
      "Average (on the epoch) training loss: 55.93904113769531\n",
      "Episode average V value: 22.398025174935658\n",
      "Average (on the epoch) training loss: 56.83140182495117\n",
      "Episode average V value: 31.607635498046875\n",
      "Average (on the epoch) training loss: 56.62031173706055\n",
      "Episode average V value: 31.817277908325195\n",
      "Average (on the epoch) training loss: 56.59254455566406\n",
      "Episode average V value: 24.452735980351765\n",
      "Average (on the epoch) training loss: 56.51566696166992\n",
      "Episode average V value: -399.4457159837087\n",
      "Average (on the epoch) training loss: 56.290653228759766\n",
      "Episode average V value: 37.042362213134766\n",
      "Average (on the epoch) training loss: 55.88517379760742\n",
      "Episode average V value: 32.0749626159668\n",
      "Average (on the epoch) training loss: 55.629417419433594\n",
      "Episode average V value: 38.38532638549805\n",
      "Average (on the epoch) training loss: 55.383602142333984\n",
      "Episode average V value: 27.99086308479309\n",
      "Average (on the epoch) training loss: 55.20854187011719\n",
      "Episode average V value: 30.77479346593221\n",
      "Average (on the epoch) training loss: 55.0201416015625\n",
      "Episode average V value: 36.606178283691406\n",
      "Average (on the epoch) training loss: 54.86149978637695\n",
      "Episode average V value: 41.92957305908203\n",
      "Average (on the epoch) training loss: 55.1692008972168\n",
      "Episode average V value: 47.67857813835144\n",
      "Average (on the epoch) training loss: 54.84230422973633\n",
      "Episode average V value: 20.883233686288197\n",
      "Average (on the epoch) training loss: 54.46407699584961\n",
      "Episode average V value: 37.99287414550781\n",
      "Average (on the epoch) training loss: 54.309364318847656\n",
      "Episode average V value: 41.53579179445902\n",
      "Average (on the epoch) training loss: 54.65458679199219\n",
      "Episode average V value: 31.65807882944743\n",
      "Average (on the epoch) training loss: 54.31096649169922\n",
      "Episode average V value: 23.802282094955444\n",
      "Average (on the epoch) training loss: 54.02213668823242\n",
      "Episode average V value: 29.866900046666462\n",
      "Average (on the epoch) training loss: 53.77888107299805\n",
      "Episode average V value: 24.05401865641276\n",
      "Average (on the epoch) training loss: 53.60122299194336\n",
      "Episode average V value: 44.32530749927867\n",
      "Average (on the epoch) training loss: 53.43831253051758\n",
      "Episode average V value: 33.93121576309204\n",
      "Average (on the epoch) training loss: 53.22657775878906\n",
      "Episode average V value: 27.58748435974121\n",
      "Average (on the epoch) training loss: 53.668861389160156\n",
      "Episode average V value: 26.698628772388805\n",
      "Average (on the epoch) training loss: 53.45338439941406\n",
      "Episode average V value: 25.156681060791016\n",
      "Average (on the epoch) training loss: 53.33330154418945\n",
      "Episode average V value: 38.18847131729126\n",
      "Average (on the epoch) training loss: 53.16777420043945\n",
      "Episode average V value: 19.330281337102253\n",
      "Average (on the epoch) training loss: 53.101627349853516\n",
      "Episode average V value: 40.10092544555664\n",
      "Average (on the epoch) training loss: 53.71270751953125\n",
      "Episode average V value: 26.683578491210938\n",
      "epoch 13:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 68.12932586669922\n",
      "Episode average V value: 35.00635496775309\n",
      "Average (on the epoch) training loss: 78.03243255615234\n",
      "Episode average V value: -327.41563272476196\n",
      "Average (on the epoch) training loss: 64.80056762695312\n",
      "Episode average V value: 28.26407527923584\n",
      "Average (on the epoch) training loss: 64.3331527709961\n",
      "Episode average V value: 25.612581729888916\n",
      "Average (on the epoch) training loss: 62.93679428100586\n",
      "Episode average V value: 24.164884437214244\n",
      "Average (on the epoch) training loss: 60.125\n",
      "Episode average V value: 32.982154846191406\n",
      "Average (on the epoch) training loss: 62.814640045166016\n",
      "Episode average V value: 24.307199478149414\n",
      "Average (on the epoch) training loss: 61.35568618774414\n",
      "Episode average V value: 22.835365295410156\n",
      "Average (on the epoch) training loss: 57.00905990600586\n",
      "Episode average V value: 34.14517215887705\n",
      "Average (on the epoch) training loss: 55.883277893066406\n",
      "Episode average V value: 36.456796646118164\n",
      "Average (on the epoch) training loss: 54.83828353881836\n",
      "Episode average V value: 45.09537386894226\n",
      "Average (on the epoch) training loss: 53.600257873535156\n",
      "Episode average V value: 29.96950050195058\n",
      "Average (on the epoch) training loss: 52.86001205444336\n",
      "Episode average V value: 40.54166277972135\n",
      "Average (on the epoch) training loss: 52.1629753112793\n",
      "Episode average V value: 20.02435572942098\n",
      "Average (on the epoch) training loss: 51.500858306884766\n",
      "Episode average V value: 33.19025577198375\n",
      "Average (on the epoch) training loss: 53.33870315551758\n",
      "Episode average V value: 37.959636529286705\n",
      "Average (on the epoch) training loss: 52.90049743652344\n",
      "Episode average V value: 31.467483975670554\n",
      "Average (on the epoch) training loss: 51.849246978759766\n",
      "Episode average V value: 29.08683967590332\n",
      "Average (on the epoch) training loss: 53.703208923339844\n",
      "Episode average V value: 31.478580474853516\n",
      "Average (on the epoch) training loss: 52.522769927978516\n",
      "Episode average V value: 23.92881965637207\n",
      "Average (on the epoch) training loss: 51.39323806762695\n",
      "Episode average V value: 42.02346022923788\n",
      "Average (on the epoch) training loss: 50.23866271972656\n",
      "Episode average V value: 33.3968163728714\n",
      "Average (on the epoch) training loss: 49.76356887817383\n",
      "Episode average V value: 32.53538449605306\n",
      "Average (on the epoch) training loss: 50.48944854736328\n",
      "Episode average V value: 27.17063868045807\n",
      "Average (on the epoch) training loss: 51.298072814941406\n",
      "Episode average V value: 31.876855850219727\n",
      "Average (on the epoch) training loss: 52.6269645690918\n",
      "Episode average V value: 30.763756318525836\n",
      "Average (on the epoch) training loss: 52.15187454223633\n",
      "Episode average V value: 11.152022441228231\n",
      "Average (on the epoch) training loss: 53.18056106567383\n",
      "Episode average V value: 33.23978042602539\n",
      "Average (on the epoch) training loss: 54.075374603271484\n",
      "Episode average V value: 29.38052463531494\n",
      "Average (on the epoch) training loss: 53.45119857788086\n",
      "Episode average V value: 37.8116569519043\n",
      "Average (on the epoch) training loss: 52.78607940673828\n",
      "Episode average V value: 15.718576590220133\n",
      "Average (on the epoch) training loss: 53.4902458190918\n",
      "Episode average V value: 15.746819907968694\n",
      "Average (on the epoch) training loss: 52.73638153076172\n",
      "Episode average V value: 23.328267733256023\n",
      "Average (on the epoch) training loss: 52.52952194213867\n",
      "Episode average V value: 49.013404846191406\n",
      "Average (on the epoch) training loss: 52.07434844970703\n",
      "Episode average V value: 30.491565444252707\n",
      "Average (on the epoch) training loss: 52.56057357788086\n",
      "Episode average V value: 33.476905822753906\n",
      "Average (on the epoch) training loss: 53.12137222290039\n",
      "Episode average V value: 27.380565643310547\n",
      "Average (on the epoch) training loss: 53.13523864746094\n",
      "Episode average V value: 33.6069366534551\n",
      "Average (on the epoch) training loss: 52.31428527832031\n",
      "Episode average V value: 26.987516403198242\n",
      "Average (on the epoch) training loss: 51.60954666137695\n",
      "Episode average V value: 30.947725296020508\n",
      "Average (on the epoch) training loss: 51.20917510986328\n",
      "Episode average V value: 52.475698471069336\n",
      "Average (on the epoch) training loss: 51.08249282836914\n",
      "Episode average V value: 13.84003178278605\n",
      "Average (on the epoch) training loss: 51.432857513427734\n",
      "Episode average V value: 24.889906764030457\n",
      "Average (on the epoch) training loss: 52.01862716674805\n",
      "Episode average V value: 28.49022674560547\n",
      "Average (on the epoch) training loss: 51.61396789550781\n",
      "Episode average V value: 32.16320387522379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 51.05746078491211\n",
      "Episode average V value: 29.718026280403137\n",
      "Average (on the epoch) training loss: 50.59102249145508\n",
      "Episode average V value: 44.17812728881836\n",
      "Average (on the epoch) training loss: 50.33354187011719\n",
      "Episode average V value: 23.82292014360428\n",
      "Average (on the epoch) training loss: 50.958709716796875\n",
      "Episode average V value: 39.59566593170166\n",
      "Average (on the epoch) training loss: 50.67232894897461\n",
      "Episode average V value: 25.190497875213623\n",
      "Average (on the epoch) training loss: 51.02597427368164\n",
      "Episode average V value: 49.63363301257292\n",
      "Average (on the epoch) training loss: 52.17100524902344\n",
      "Episode average V value: 25.709789514541626\n",
      "Average (on the epoch) training loss: 52.00205612182617\n",
      "Episode average V value: 25.119489510854084\n",
      "Average (on the epoch) training loss: 52.214603424072266\n",
      "Episode average V value: 19.406147638956707\n",
      "Average (on the epoch) training loss: 52.33021926879883\n",
      "Episode average V value: 22.34107192357381\n",
      "Average (on the epoch) training loss: 51.88120651245117\n",
      "Episode average V value: 28.345657348632812\n",
      "Average (on the epoch) training loss: 51.51865005493164\n",
      "Episode average V value: 29.961602369944256\n",
      "Average (on the epoch) training loss: 51.592620849609375\n",
      "Episode average V value: 26.405561447143555\n",
      "Average (on the epoch) training loss: 51.552162170410156\n",
      "Episode average V value: 27.557695388793945\n",
      "Average (on the epoch) training loss: 51.45924377441406\n",
      "Episode average V value: 15.026041984558105\n",
      "Average (on the epoch) training loss: 51.345767974853516\n",
      "Episode average V value: 28.271453082561493\n",
      "Average (on the epoch) training loss: 50.885772705078125\n",
      "Episode average V value: 23.332222123940785\n",
      "Average (on the epoch) training loss: 50.579097747802734\n",
      "Episode average V value: 28.583098967870075\n",
      "Average (on the epoch) training loss: 50.21438980102539\n",
      "Episode average V value: 30.166526794433594\n",
      "Average (on the epoch) training loss: 50.0352668762207\n",
      "Episode average V value: 32.306958158810936\n",
      "Average (on the epoch) training loss: 49.656009674072266\n",
      "Episode average V value: 20.714464515447617\n",
      "Average (on the epoch) training loss: 49.55410385131836\n",
      "Episode average V value: 26.750262022018433\n",
      "Average (on the epoch) training loss: 49.74308776855469\n",
      "Episode average V value: 32.25906753540039\n",
      "Average (on the epoch) training loss: 49.48320388793945\n",
      "Episode average V value: 20.319223086039226\n",
      "Average (on the epoch) training loss: 49.13202667236328\n",
      "Episode average V value: 24.459192872047424\n",
      "Average (on the epoch) training loss: 49.565982818603516\n",
      "Episode average V value: -386.4638772010803\n",
      "Average (on the epoch) training loss: 49.36180114746094\n",
      "Episode average V value: 25.910520553588867\n",
      "Average (on the epoch) training loss: 49.27248001098633\n",
      "Episode average V value: 20.53986515601476\n",
      "Average (on the epoch) training loss: 48.98135757446289\n",
      "Episode average V value: 33.425715366999306\n",
      "Average (on the epoch) training loss: 49.293914794921875\n",
      "Episode average V value: 20.601691087086994\n",
      "Average (on the epoch) training loss: 49.26167297363281\n",
      "Episode average V value: 26.766077041625977\n",
      "Average (on the epoch) training loss: 48.9930534362793\n",
      "Episode average V value: 16.536613325277965\n",
      "Average (on the epoch) training loss: 49.14955139160156\n",
      "Episode average V value: 26.139747619628906\n",
      "Average (on the epoch) training loss: 48.83397674560547\n",
      "Episode average V value: 22.824323654174805\n",
      "Average (on the epoch) training loss: 49.31370544433594\n",
      "Episode average V value: 35.3549751440684\n",
      "Average (on the epoch) training loss: 48.96226119995117\n",
      "Episode average V value: 28.983972549438477\n",
      "Average (on the epoch) training loss: 48.92819595336914\n",
      "Episode average V value: 29.488813400268555\n",
      "Average (on the epoch) training loss: 48.849281311035156\n",
      "Episode average V value: 26.34549903869629\n",
      "Average (on the epoch) training loss: 49.17757034301758\n",
      "Episode average V value: 25.319027702013653\n",
      "Average (on the epoch) training loss: 49.629825592041016\n",
      "Episode average V value: 17.8604961308566\n",
      "Average (on the epoch) training loss: 49.30202102661133\n",
      "Episode average V value: 29.594770431518555\n",
      "Average (on the epoch) training loss: 49.18410110473633\n",
      "Episode average V value: 29.20459747314453\n",
      "Average (on the epoch) training loss: 49.374969482421875\n",
      "Episode average V value: 31.734885215759277\n",
      "Average (on the epoch) training loss: 49.21336364746094\n",
      "Episode average V value: 24.74412727355957\n",
      "Average (on the epoch) training loss: 49.14177703857422\n",
      "Episode average V value: 32.36678655942281\n",
      "Average (on the epoch) training loss: 48.95242691040039\n",
      "Episode average V value: 15.829249382019043\n",
      "Average (on the epoch) training loss: 48.80666732788086\n",
      "Episode average V value: 33.0703105059537\n",
      "Average (on the epoch) training loss: 48.51108932495117\n",
      "Episode average V value: 21.498755256334942\n",
      "Average (on the epoch) training loss: 48.52736282348633\n",
      "Episode average V value: 27.140878677368164\n",
      "Average (on the epoch) training loss: 48.43724060058594\n",
      "Episode average V value: 25.881851196289062\n",
      "Average (on the epoch) training loss: 48.41149139404297\n",
      "Episode average V value: 20.569464921951294\n",
      "Average (on the epoch) training loss: 48.11112976074219\n",
      "Episode average V value: 23.223883628845215\n",
      "Average (on the epoch) training loss: 48.353572845458984\n",
      "Episode average V value: 39.04018521308899\n",
      "Average (on the epoch) training loss: 48.25830078125\n",
      "Episode average V value: 23.68832055727641\n",
      "Average (on the epoch) training loss: 48.14372253417969\n",
      "Episode average V value: 25.656878461440403\n",
      "epoch 14:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 19.39558982849121\n",
      "Episode average V value: 25.464923620224\n",
      "Average (on the epoch) training loss: 29.244659423828125\n",
      "Episode average V value: 37.38899612426758\n",
      "Average (on the epoch) training loss: 29.000450134277344\n",
      "Episode average V value: 14.865055084228516\n",
      "Average (on the epoch) training loss: 28.7841739654541\n",
      "Episode average V value: 21.15765953063965\n",
      "Average (on the epoch) training loss: 30.08720588684082\n",
      "Episode average V value: 27.01085889339447\n",
      "Average (on the epoch) training loss: 28.98792266845703\n",
      "Episode average V value: 26.219602584838867\n",
      "Average (on the epoch) training loss: 30.890941619873047\n",
      "Episode average V value: 34.11373519897461\n",
      "Average (on the epoch) training loss: 31.905302047729492\n",
      "Episode average V value: 28.16314125061035\n",
      "Average (on the epoch) training loss: 32.49875259399414\n",
      "Episode average V value: 30.136566162109375\n",
      "Average (on the epoch) training loss: 31.634733200073242\n",
      "Episode average V value: 28.148876031239826\n",
      "Average (on the epoch) training loss: 35.158538818359375\n",
      "Episode average V value: 25.029544830322266\n",
      "Average (on the epoch) training loss: 35.41502380371094\n",
      "Episode average V value: 18.362639403343202\n",
      "Average (on the epoch) training loss: 34.63701248168945\n",
      "Episode average V value: 18.60771981875102\n",
      "Average (on the epoch) training loss: 35.74272918701172\n",
      "Episode average V value: 32.18013381958008\n",
      "Average (on the epoch) training loss: 38.24662399291992\n",
      "Episode average V value: 25.050931294759113\n",
      "Average (on the epoch) training loss: 37.37666702270508\n",
      "Episode average V value: 24.40733563899994\n",
      "Average (on the epoch) training loss: 37.17264938354492\n",
      "Episode average V value: 24.707593083381653\n",
      "Average (on the epoch) training loss: 40.573707580566406\n",
      "Episode average V value: 36.954345703125\n",
      "Average (on the epoch) training loss: 41.86704635620117\n",
      "Episode average V value: 19.651111689480867\n",
      "Average (on the epoch) training loss: 42.3676872253418\n",
      "Episode average V value: -372.7093645731608\n",
      "Average (on the epoch) training loss: 43.669342041015625\n",
      "Episode average V value: 24.98516082763672\n",
      "Average (on the epoch) training loss: 42.82227325439453\n",
      "Episode average V value: 19.058223446210224\n",
      "Average (on the epoch) training loss: 42.6555290222168\n",
      "Episode average V value: 31.9741153717041\n",
      "Average (on the epoch) training loss: 42.83988952636719\n",
      "Episode average V value: 8.090495506922403\n",
      "Average (on the epoch) training loss: 46.64045715332031\n",
      "Episode average V value: 17.745707352956135\n",
      "Average (on the epoch) training loss: 46.99258041381836\n",
      "Episode average V value: 31.222013473510742\n",
      "Average (on the epoch) training loss: 46.48441696166992\n",
      "Episode average V value: -356.8609399000804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 45.69853973388672\n",
      "Episode average V value: 33.64377212524414\n",
      "Average (on the epoch) training loss: 45.261322021484375\n",
      "Episode average V value: 38.540653402155094\n",
      "Average (on the epoch) training loss: 46.734619140625\n",
      "Episode average V value: -394.87223927179974\n",
      "Average (on the epoch) training loss: 46.61703872680664\n",
      "Episode average V value: 25.999353408813477\n",
      "Average (on the epoch) training loss: 48.223419189453125\n",
      "Episode average V value: 33.88415756225586\n",
      "Average (on the epoch) training loss: 48.590919494628906\n",
      "Episode average V value: 19.402942260106403\n",
      "Average (on the epoch) training loss: 48.741886138916016\n",
      "Episode average V value: 34.015503803888954\n",
      "Average (on the epoch) training loss: 50.041866302490234\n",
      "Episode average V value: -360.06025791168213\n",
      "Average (on the epoch) training loss: 49.73640060424805\n",
      "Episode average V value: 33.80784821510315\n",
      "Average (on the epoch) training loss: 49.49700164794922\n",
      "Episode average V value: 65.7295405069987\n",
      "Average (on the epoch) training loss: 49.89980697631836\n",
      "Episode average V value: 43.297176361083984\n",
      "Average (on the epoch) training loss: 50.08955001831055\n",
      "Episode average V value: 41.616554260253906\n",
      "Average (on the epoch) training loss: 49.76996994018555\n",
      "Episode average V value: 38.63260633295233\n",
      "Average (on the epoch) training loss: 49.780303955078125\n",
      "Episode average V value: 49.45358435312907\n",
      "Average (on the epoch) training loss: 50.45965576171875\n",
      "Episode average V value: 40.29245122273763\n",
      "Average (on the epoch) training loss: 50.73533630371094\n",
      "Episode average V value: 36.59286932511763\n",
      "Average (on the epoch) training loss: 50.28737258911133\n",
      "Episode average V value: 43.69440976778666\n",
      "Average (on the epoch) training loss: 50.16976547241211\n",
      "Episode average V value: 47.3046989440918\n",
      "Average (on the epoch) training loss: 50.05890655517578\n",
      "Episode average V value: 42.48917531967163\n",
      "Average (on the epoch) training loss: 50.295467376708984\n",
      "Episode average V value: 38.511409759521484\n",
      "Average (on the epoch) training loss: 50.9547119140625\n",
      "Episode average V value: 41.359076499938965\n",
      "Average (on the epoch) training loss: 50.987674713134766\n",
      "Episode average V value: -352.6098969777425\n",
      "Average (on the epoch) training loss: 51.111907958984375\n",
      "Episode average V value: 45.66977707544962\n",
      "Average (on the epoch) training loss: 51.54587173461914\n",
      "Episode average V value: 39.26704788208008\n",
      "Average (on the epoch) training loss: 51.79782485961914\n",
      "Episode average V value: 47.415653228759766\n",
      "Average (on the epoch) training loss: 51.730712890625\n",
      "Episode average V value: 65.57811164855957\n",
      "Average (on the epoch) training loss: 52.05437469482422\n",
      "Episode average V value: 40.127052307128906\n",
      "Average (on the epoch) training loss: 51.78976821899414\n",
      "Episode average V value: 39.08032639821371\n",
      "Average (on the epoch) training loss: 52.331809997558594\n",
      "Episode average V value: 44.770467360814415\n",
      "Average (on the epoch) training loss: 51.98042297363281\n",
      "Episode average V value: 34.45957851409912\n",
      "Average (on the epoch) training loss: 51.965545654296875\n",
      "Episode average V value: 43.846615632375084\n",
      "Average (on the epoch) training loss: 51.64021301269531\n",
      "Episode average V value: 47.43643569946289\n",
      "Average (on the epoch) training loss: 51.871917724609375\n",
      "Episode average V value: 41.72644809881846\n",
      "Average (on the epoch) training loss: 51.661224365234375\n",
      "Episode average V value: 30.140235207297586\n",
      "Average (on the epoch) training loss: 52.31105041503906\n",
      "Episode average V value: 57.27396774291992\n",
      "Average (on the epoch) training loss: 53.52272415161133\n",
      "Episode average V value: 40.54693841934204\n",
      "Average (on the epoch) training loss: 53.80373001098633\n",
      "Episode average V value: 8.316117922465006\n",
      "Average (on the epoch) training loss: 53.39162063598633\n",
      "Episode average V value: 34.7861442565918\n",
      "Average (on the epoch) training loss: 53.0774040222168\n",
      "Episode average V value: 59.694026947021484\n",
      "Average (on the epoch) training loss: 52.86315155029297\n",
      "Episode average V value: 61.623531341552734\n",
      "Average (on the epoch) training loss: 53.32586669921875\n",
      "Episode average V value: 27.92573642730713\n",
      "Average (on the epoch) training loss: 53.181819915771484\n",
      "Episode average V value: 52.60359732309977\n",
      "Average (on the epoch) training loss: 53.51014709472656\n",
      "Episode average V value: 34.45317657788595\n",
      "Average (on the epoch) training loss: 53.232669830322266\n",
      "Episode average V value: 30.625023126602173\n",
      "Average (on the epoch) training loss: 52.97782897949219\n",
      "Episode average V value: 60.795833587646484\n",
      "Average (on the epoch) training loss: 53.180240631103516\n",
      "Episode average V value: 38.11998748779297\n",
      "Average (on the epoch) training loss: 53.28179168701172\n",
      "Episode average V value: 37.04984219868978\n",
      "Average (on the epoch) training loss: 53.86125183105469\n",
      "Episode average V value: 44.22155128825795\n",
      "Average (on the epoch) training loss: 53.94771957397461\n",
      "Episode average V value: 41.5550651550293\n",
      "Average (on the epoch) training loss: 54.293190002441406\n",
      "Episode average V value: 36.410945892333984\n",
      "Average (on the epoch) training loss: 54.29798126220703\n",
      "Episode average V value: 45.28524907430013\n",
      "Average (on the epoch) training loss: 54.78860092163086\n",
      "Episode average V value: 56.812931060791016\n",
      "Average (on the epoch) training loss: 55.14907455444336\n",
      "Episode average V value: 58.33802795410156\n",
      "Average (on the epoch) training loss: 55.13621139526367\n",
      "Episode average V value: 28.78196382522583\n",
      "Average (on the epoch) training loss: 55.05425262451172\n",
      "Episode average V value: 41.82656478881836\n",
      "Average (on the epoch) training loss: 55.07167434692383\n",
      "Episode average V value: 44.276615142822266\n",
      "Average (on the epoch) training loss: 55.40516662597656\n",
      "Episode average V value: 35.08885508775711\n",
      "Average (on the epoch) training loss: 55.689483642578125\n",
      "Episode average V value: 42.033347288767494\n",
      "Average (on the epoch) training loss: 55.95563507080078\n",
      "Episode average V value: 34.00164031982422\n",
      "Average (on the epoch) training loss: 55.94325637817383\n",
      "Episode average V value: -372.7179208596547\n",
      "Average (on the epoch) training loss: 55.96876907348633\n",
      "Episode average V value: 32.84729766845703\n",
      "Average (on the epoch) training loss: 56.03438949584961\n",
      "Episode average V value: 28.65037266413371\n",
      "Average (on the epoch) training loss: 55.698089599609375\n",
      "Episode average V value: 37.244532426198326\n",
      "Average (on the epoch) training loss: 55.69206237792969\n",
      "Episode average V value: -361.78283147017163\n",
      "Average (on the epoch) training loss: 55.38606643676758\n",
      "Episode average V value: 40.12876812616984\n",
      "Average (on the epoch) training loss: 55.74073028564453\n",
      "Episode average V value: 54.25726318359375\n",
      "Average (on the epoch) training loss: 55.4715461730957\n",
      "Episode average V value: 58.4124641418457\n",
      "Average (on the epoch) training loss: 55.22069549560547\n",
      "Episode average V value: 60.369625091552734\n",
      "Average (on the epoch) training loss: 55.13710021972656\n",
      "Episode average V value: 29.367441813151043\n",
      "Average (on the epoch) training loss: 55.919532775878906\n",
      "Episode average V value: 52.4875619676378\n",
      "Average (on the epoch) training loss: 56.09366989135742\n",
      "Episode average V value: 47.78892135620117\n",
      "Average (on the epoch) training loss: 55.78921890258789\n",
      "Episode average V value: 40.7729321826588\n",
      "Average (on the epoch) training loss: 55.7806396484375\n",
      "Episode average V value: 42.415400664011635\n",
      "epoch 15:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 112.17569732666016\n",
      "Episode average V value: 39.08317073186239\n",
      "Average (on the epoch) training loss: 76.75762176513672\n",
      "Episode average V value: 37.694095611572266\n",
      "Average (on the epoch) training loss: 69.51317596435547\n",
      "Episode average V value: 42.03096389770508\n",
      "Average (on the epoch) training loss: 72.5486831665039\n",
      "Episode average V value: 36.952706495920815\n",
      "Average (on the epoch) training loss: 64.43011474609375\n",
      "Episode average V value: 38.06637839476267\n",
      "Average (on the epoch) training loss: 59.34214401245117\n",
      "Episode average V value: 37.78534968694051\n",
      "Average (on the epoch) training loss: 59.03191375732422\n",
      "Episode average V value: 46.63058058420817\n",
      "Average (on the epoch) training loss: 57.13960647583008\n",
      "Episode average V value: 31.607574462890625\n",
      "Average (on the epoch) training loss: 57.71085739135742\n",
      "Episode average V value: -375.67025740941364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 57.114315032958984\n",
      "Episode average V value: 42.137146949768066\n",
      "Average (on the epoch) training loss: 56.05546951293945\n",
      "Episode average V value: -374.64586051305133\n",
      "Average (on the epoch) training loss: 58.57789611816406\n",
      "Episode average V value: 33.99874477386474\n",
      "Average (on the epoch) training loss: 58.94542694091797\n",
      "Episode average V value: 43.154738108317055\n",
      "Average (on the epoch) training loss: 58.74958038330078\n",
      "Episode average V value: 48.4216423034668\n",
      "Average (on the epoch) training loss: 58.43504333496094\n",
      "Episode average V value: 27.344932635625202\n",
      "Average (on the epoch) training loss: 56.94786071777344\n",
      "Episode average V value: 42.972964922587074\n",
      "Average (on the epoch) training loss: 57.04656982421875\n",
      "Episode average V value: 24.976035435994465\n",
      "Average (on the epoch) training loss: 56.67869567871094\n",
      "Episode average V value: 42.963218569755554\n",
      "Average (on the epoch) training loss: 54.993377685546875\n",
      "Episode average V value: 50.75327682495117\n",
      "Average (on the epoch) training loss: 55.08253479003906\n",
      "Episode average V value: 37.44214280446371\n",
      "Average (on the epoch) training loss: 57.659812927246094\n",
      "Episode average V value: 55.02248764038086\n",
      "Average (on the epoch) training loss: 59.3311653137207\n",
      "Episode average V value: 38.42974670728048\n",
      "Average (on the epoch) training loss: 59.133705139160156\n",
      "Episode average V value: 29.768664439519245\n",
      "Average (on the epoch) training loss: 61.27349090576172\n",
      "Episode average V value: 56.92050552368164\n",
      "Average (on the epoch) training loss: 62.63540267944336\n",
      "Episode average V value: -364.7207067012787\n",
      "Average (on the epoch) training loss: 63.15686798095703\n",
      "Episode average V value: 34.76325011253357\n",
      "Average (on the epoch) training loss: 62.857547760009766\n",
      "Episode average V value: 44.863162994384766\n",
      "Average (on the epoch) training loss: 62.65903854370117\n",
      "Episode average V value: 51.42564455668131\n",
      "Average (on the epoch) training loss: 62.253379821777344\n",
      "Episode average V value: 39.72737471262614\n",
      "Average (on the epoch) training loss: 63.742427825927734\n",
      "Episode average V value: -369.42801507314044\n",
      "Average (on the epoch) training loss: 64.39945220947266\n",
      "Episode average V value: 34.99683745702108\n",
      "Average (on the epoch) training loss: 64.69902801513672\n",
      "Episode average V value: 44.40439224243164\n",
      "Average (on the epoch) training loss: 63.584861755371094\n",
      "Episode average V value: 34.30485169092814\n",
      "Average (on the epoch) training loss: 63.49480438232422\n",
      "Episode average V value: 41.29830185572306\n",
      "Average (on the epoch) training loss: 63.9139404296875\n",
      "Episode average V value: 33.93841361999512\n",
      "Average (on the epoch) training loss: 64.75159454345703\n",
      "Episode average V value: 45.433807373046875\n",
      "Average (on the epoch) training loss: 64.4518814086914\n",
      "Episode average V value: 42.90462330977122\n",
      "Average (on the epoch) training loss: 64.34178924560547\n",
      "Episode average V value: 61.4056282043457\n",
      "Average (on the epoch) training loss: 64.47987365722656\n",
      "Episode average V value: 40.66086856524149\n",
      "Average (on the epoch) training loss: 63.95481491088867\n",
      "Episode average V value: 30.317359924316406\n",
      "Average (on the epoch) training loss: 63.117774963378906\n",
      "Episode average V value: 43.48409320910772\n",
      "Average (on the epoch) training loss: 62.703468322753906\n",
      "Episode average V value: 38.63231832330877\n",
      "Average (on the epoch) training loss: 62.44343948364258\n",
      "Episode average V value: 28.222258885701496\n",
      "Average (on the epoch) training loss: 62.4405632019043\n",
      "Episode average V value: 55.25244951248169\n",
      "Average (on the epoch) training loss: 61.67628860473633\n",
      "Episode average V value: 35.60325296719869\n",
      "Average (on the epoch) training loss: 61.811256408691406\n",
      "Episode average V value: -384.8776551087697\n",
      "Average (on the epoch) training loss: 62.59499740600586\n",
      "Episode average V value: 38.74300169944763\n",
      "Average (on the epoch) training loss: 62.65677261352539\n",
      "Episode average V value: 48.842304706573486\n",
      "Average (on the epoch) training loss: 63.039241790771484\n",
      "Episode average V value: -362.56231594085693\n",
      "Average (on the epoch) training loss: 62.83482360839844\n",
      "Episode average V value: 43.493011474609375\n",
      "Average (on the epoch) training loss: 62.866153717041016\n",
      "Episode average V value: 54.47220993041992\n",
      "Average (on the epoch) training loss: 62.692195892333984\n",
      "Episode average V value: 51.31159973144531\n",
      "Average (on the epoch) training loss: 62.03197479248047\n",
      "Episode average V value: 42.908756256103516\n",
      "Average (on the epoch) training loss: 61.43085861206055\n",
      "Episode average V value: 46.386876900990806\n",
      "Average (on the epoch) training loss: 62.4798698425293\n",
      "Episode average V value: 25.2630655169487\n",
      "Average (on the epoch) training loss: 61.84828567504883\n",
      "Episode average V value: 33.35009758671125\n",
      "Average (on the epoch) training loss: 61.6213493347168\n",
      "Episode average V value: 51.65566635131836\n",
      "Average (on the epoch) training loss: 61.12915802001953\n",
      "Episode average V value: 48.64827346801758\n",
      "Average (on the epoch) training loss: 60.66476821899414\n",
      "Episode average V value: 33.16790624098344\n",
      "Average (on the epoch) training loss: 61.97855758666992\n",
      "Episode average V value: 48.43277883529663\n",
      "Average (on the epoch) training loss: 63.0686149597168\n",
      "Episode average V value: 38.63638687133789\n",
      "Average (on the epoch) training loss: 62.5544548034668\n",
      "Episode average V value: 53.299495697021484\n",
      "Average (on the epoch) training loss: 62.408668518066406\n",
      "Episode average V value: 40.77091383934021\n",
      "Average (on the epoch) training loss: 62.393001556396484\n",
      "Episode average V value: 48.703440268834434\n",
      "Average (on the epoch) training loss: 61.9277229309082\n",
      "Episode average V value: 50.61500040690104\n",
      "Average (on the epoch) training loss: 61.392173767089844\n",
      "Episode average V value: 46.18684005737305\n",
      "Average (on the epoch) training loss: 61.368690490722656\n",
      "Episode average V value: 56.498520175615944\n",
      "Average (on the epoch) training loss: 61.25594711303711\n",
      "Episode average V value: 39.733070373535156\n",
      "Average (on the epoch) training loss: 61.43406677246094\n",
      "Episode average V value: 39.12174336115519\n",
      "Average (on the epoch) training loss: 61.141788482666016\n",
      "Episode average V value: 49.24191800753275\n",
      "Average (on the epoch) training loss: 60.75226593017578\n",
      "Episode average V value: 57.93952560424805\n",
      "Average (on the epoch) training loss: 61.68861389160156\n",
      "Episode average V value: 52.098846435546875\n",
      "Average (on the epoch) training loss: 61.64015197753906\n",
      "Episode average V value: 49.3337516784668\n",
      "Average (on the epoch) training loss: 61.452903747558594\n",
      "Episode average V value: 50.18432331085205\n",
      "Average (on the epoch) training loss: 61.3150520324707\n",
      "Episode average V value: 47.44039344787598\n",
      "Average (on the epoch) training loss: 61.647422790527344\n",
      "Episode average V value: 36.09389861424764\n",
      "Average (on the epoch) training loss: 61.49729537963867\n",
      "Episode average V value: 36.59528617064158\n",
      "Average (on the epoch) training loss: 61.257164001464844\n",
      "Episode average V value: 46.81513040715998\n",
      "Average (on the epoch) training loss: 61.57158660888672\n",
      "Episode average V value: 46.63711929321289\n",
      "Average (on the epoch) training loss: 61.81845474243164\n",
      "Episode average V value: 36.76598288796165\n",
      "Average (on the epoch) training loss: 62.076263427734375\n",
      "Episode average V value: 29.404057184855144\n",
      "Average (on the epoch) training loss: 62.201236724853516\n",
      "Episode average V value: 41.04631805419922\n",
      "Average (on the epoch) training loss: 62.800411224365234\n",
      "Episode average V value: 42.66156601905823\n",
      "Average (on the epoch) training loss: 63.00962448120117\n",
      "Episode average V value: 30.599443435668945\n",
      "Average (on the epoch) training loss: 63.41091537475586\n",
      "Episode average V value: 37.135311126708984\n",
      "Average (on the epoch) training loss: 63.09318923950195\n",
      "Episode average V value: 25.267216205596924\n",
      "Average (on the epoch) training loss: 63.27177810668945\n",
      "Episode average V value: 53.90428654352824\n",
      "Average (on the epoch) training loss: 63.90483856201172\n",
      "Episode average V value: 41.194340189297996\n",
      "Average (on the epoch) training loss: 63.686344146728516\n",
      "Episode average V value: 35.24986890951792\n",
      "Average (on the epoch) training loss: 63.52352523803711\n",
      "Episode average V value: 54.18613815307617\n",
      "Average (on the epoch) training loss: 63.37209701538086\n",
      "Episode average V value: 37.07101138432821\n",
      "Average (on the epoch) training loss: 63.13450241088867\n",
      "Episode average V value: 33.16217057271437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 63.19172668457031\n",
      "Episode average V value: 59.30038070678711\n",
      "Average (on the epoch) training loss: 63.44999313354492\n",
      "Episode average V value: 47.864654541015625\n",
      "Average (on the epoch) training loss: 63.19102096557617\n",
      "Episode average V value: 42.04268264770508\n",
      "Average (on the epoch) training loss: 62.89556121826172\n",
      "Episode average V value: 32.97852555910746\n",
      "Average (on the epoch) training loss: 62.96758270263672\n",
      "Episode average V value: 45.55530961354574\n",
      "Average (on the epoch) training loss: 62.81291198730469\n",
      "Episode average V value: 46.81363836924235\n",
      "Average (on the epoch) training loss: 62.67603302001953\n",
      "Episode average V value: 35.55115925181996\n",
      "Average (on the epoch) training loss: 62.4882926940918\n",
      "Episode average V value: 44.17146301269531\n",
      "epoch 16:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 87.39464569091797\n",
      "Episode average V value: 34.38514280319214\n",
      "Average (on the epoch) training loss: 59.33613204956055\n",
      "Episode average V value: 24.687089920043945\n",
      "Average (on the epoch) training loss: 50.31779479980469\n",
      "Episode average V value: 25.087676308371805\n",
      "Average (on the epoch) training loss: 44.398712158203125\n",
      "Episode average V value: 33.62267955144247\n",
      "Average (on the epoch) training loss: 41.87094497680664\n",
      "Episode average V value: 8.574851274490356\n",
      "Average (on the epoch) training loss: 41.316280364990234\n",
      "Episode average V value: 24.296072006225586\n",
      "Average (on the epoch) training loss: 39.85852813720703\n",
      "Episode average V value: 36.728709081808724\n",
      "Average (on the epoch) training loss: 39.25557327270508\n",
      "Episode average V value: 38.219085693359375\n",
      "Average (on the epoch) training loss: 38.2159423828125\n",
      "Episode average V value: 27.64872169494629\n",
      "Average (on the epoch) training loss: 37.24844741821289\n",
      "Episode average V value: 35.694876631100975\n",
      "Average (on the epoch) training loss: 41.7532958984375\n",
      "Episode average V value: 29.472905198733013\n",
      "Average (on the epoch) training loss: 44.97800064086914\n",
      "Episode average V value: 17.672175884246826\n",
      "Average (on the epoch) training loss: 44.15285873413086\n",
      "Episode average V value: 19.205976486206055\n",
      "Average (on the epoch) training loss: 42.60187530517578\n",
      "Episode average V value: 21.738012393315632\n",
      "Average (on the epoch) training loss: 42.39971923828125\n",
      "Episode average V value: 40.96737207065929\n",
      "Average (on the epoch) training loss: 41.97407913208008\n",
      "Episode average V value: 29.57750701904297\n",
      "Average (on the epoch) training loss: 41.94346618652344\n",
      "Episode average V value: 21.576017379760742\n",
      "Average (on the epoch) training loss: 43.52775955200195\n",
      "Episode average V value: 19.471108466386795\n",
      "Average (on the epoch) training loss: 43.59577178955078\n",
      "Episode average V value: 30.15604591369629\n",
      "Average (on the epoch) training loss: 42.961448669433594\n",
      "Episode average V value: 21.7884578704834\n",
      "Average (on the epoch) training loss: 42.34548568725586\n",
      "Episode average V value: 8.936828851699829\n",
      "Average (on the epoch) training loss: 41.75258255004883\n",
      "Episode average V value: 27.228059768676758\n",
      "Average (on the epoch) training loss: 41.51576614379883\n",
      "Episode average V value: 35.90145889918009\n",
      "Average (on the epoch) training loss: 43.23394775390625\n",
      "Episode average V value: 26.508956909179688\n",
      "Average (on the epoch) training loss: 42.300872802734375\n",
      "Episode average V value: 16.734098116556805\n",
      "Average (on the epoch) training loss: 41.755558013916016\n",
      "Episode average V value: 26.86808927853902\n",
      "Average (on the epoch) training loss: 44.343719482421875\n",
      "Episode average V value: 18.472707351048786\n",
      "Average (on the epoch) training loss: 45.015445709228516\n",
      "Episode average V value: 23.68937110900879\n",
      "Average (on the epoch) training loss: 45.36478042602539\n",
      "Episode average V value: 29.784523010253906\n",
      "Average (on the epoch) training loss: 48.27970504760742\n",
      "Episode average V value: 18.13692180676894\n",
      "Average (on the epoch) training loss: 47.842594146728516\n",
      "Episode average V value: 11.066174030303955\n",
      "Average (on the epoch) training loss: 47.51234817504883\n",
      "Episode average V value: 29.01209831237793\n",
      "Average (on the epoch) training loss: 48.28857421875\n",
      "Episode average V value: 34.06283187866211\n",
      "Average (on the epoch) training loss: 48.617340087890625\n",
      "Episode average V value: 29.0910587310791\n",
      "Average (on the epoch) training loss: 49.47234344482422\n",
      "Episode average V value: 19.129820545514423\n",
      "Average (on the epoch) training loss: 49.513484954833984\n",
      "Episode average V value: 33.92246786753336\n",
      "Average (on the epoch) training loss: 51.18348693847656\n",
      "Episode average V value: -829.5650963485241\n",
      "Average (on the epoch) training loss: 51.18269348144531\n",
      "Episode average V value: 16.52893590927124\n",
      "Average (on the epoch) training loss: 50.63926696777344\n",
      "Episode average V value: 30.49379539489746\n",
      "Average (on the epoch) training loss: 51.013160705566406\n",
      "Episode average V value: 24.117801666259766\n",
      "Average (on the epoch) training loss: 51.555702209472656\n",
      "Episode average V value: 27.582420349121094\n",
      "Average (on the epoch) training loss: 51.46135711669922\n",
      "Episode average V value: 24.091548403104145\n",
      "Average (on the epoch) training loss: 50.97532272338867\n",
      "Episode average V value: 18.8203543027242\n",
      "Average (on the epoch) training loss: 50.619056701660156\n",
      "Episode average V value: 24.877484061501242\n",
      "Average (on the epoch) training loss: 50.348907470703125\n",
      "Episode average V value: 39.40982437133789\n",
      "Average (on the epoch) training loss: 51.19804382324219\n",
      "Episode average V value: 47.17561912536621\n",
      "Average (on the epoch) training loss: 51.37867736816406\n",
      "Episode average V value: 25.006842305262882\n",
      "Average (on the epoch) training loss: 51.205726623535156\n",
      "Episode average V value: 29.366186141967773\n",
      "Average (on the epoch) training loss: 50.98847198486328\n",
      "Episode average V value: 28.676530838012695\n",
      "Average (on the epoch) training loss: 51.327247619628906\n",
      "Episode average V value: 26.19686730702718\n",
      "Average (on the epoch) training loss: 50.79861068725586\n",
      "Episode average V value: 25.929171880086262\n",
      "Average (on the epoch) training loss: 50.241390228271484\n",
      "Episode average V value: 22.573349952697754\n",
      "Average (on the epoch) training loss: 51.08620071411133\n",
      "Episode average V value: 27.20151670773824\n",
      "Average (on the epoch) training loss: 50.42611312866211\n",
      "Episode average V value: 24.18079376220703\n",
      "Average (on the epoch) training loss: 50.31696701049805\n",
      "Episode average V value: -407.14985370635986\n",
      "Average (on the epoch) training loss: 50.584938049316406\n",
      "Episode average V value: 29.12182076772054\n",
      "Average (on the epoch) training loss: 50.07956314086914\n",
      "Episode average V value: 21.091442108154297\n",
      "Average (on the epoch) training loss: 49.60171890258789\n",
      "Episode average V value: 26.026981671651203\n",
      "Average (on the epoch) training loss: 50.446372985839844\n",
      "Episode average V value: 25.590466141700745\n",
      "Average (on the epoch) training loss: 50.853755950927734\n",
      "Episode average V value: 28.428179184595745\n",
      "Average (on the epoch) training loss: 50.810035705566406\n",
      "Episode average V value: 21.684518655141193\n",
      "Average (on the epoch) training loss: 50.976295471191406\n",
      "Episode average V value: 22.819865465164185\n",
      "Average (on the epoch) training loss: 50.82953643798828\n",
      "Episode average V value: 21.438688278198242\n",
      "Average (on the epoch) training loss: 50.50636672973633\n",
      "Episode average V value: 34.24752926826477\n",
      "Average (on the epoch) training loss: 50.37289810180664\n",
      "Episode average V value: 26.503816604614258\n",
      "Average (on the epoch) training loss: 51.1417350769043\n",
      "Episode average V value: 19.210795362790424\n",
      "Average (on the epoch) training loss: 50.796390533447266\n",
      "Episode average V value: 28.40235137939453\n",
      "Average (on the epoch) training loss: 50.7258415222168\n",
      "Episode average V value: 27.965845108032227\n",
      "Average (on the epoch) training loss: 50.71571350097656\n",
      "Episode average V value: 22.1864381053231\n",
      "Average (on the epoch) training loss: 50.44758987426758\n",
      "Episode average V value: 40.98828125\n",
      "Average (on the epoch) training loss: 50.09796905517578\n",
      "Episode average V value: 32.681053161621094\n",
      "Average (on the epoch) training loss: 50.130104064941406\n",
      "Episode average V value: 34.241241455078125\n",
      "Average (on the epoch) training loss: 49.95318603515625\n",
      "Episode average V value: 31.26886558532715\n",
      "Average (on the epoch) training loss: 49.6518440246582\n",
      "Episode average V value: 39.535181204477944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 50.15022659301758\n",
      "Episode average V value: 22.095293045043945\n",
      "Average (on the epoch) training loss: 49.86962127685547\n",
      "Episode average V value: 25.119464715321858\n",
      "Average (on the epoch) training loss: 50.374515533447266\n",
      "Episode average V value: 35.396976470947266\n",
      "Average (on the epoch) training loss: 49.944332122802734\n",
      "Episode average V value: 29.296031951904297\n",
      "Average (on the epoch) training loss: 49.78125\n",
      "Episode average V value: 26.8666733900706\n",
      "Average (on the epoch) training loss: 50.2510986328125\n",
      "Episode average V value: 25.610807418823242\n",
      "Average (on the epoch) training loss: 49.857704162597656\n",
      "Episode average V value: 24.08190155029297\n",
      "Average (on the epoch) training loss: 49.680870056152344\n",
      "Episode average V value: -399.95844487349194\n",
      "Average (on the epoch) training loss: 49.416038513183594\n",
      "Episode average V value: 29.849975152449176\n",
      "Average (on the epoch) training loss: 49.4018669128418\n",
      "Episode average V value: -390.80822738011676\n",
      "Average (on the epoch) training loss: 49.35345458984375\n",
      "Episode average V value: 19.14286909500758\n",
      "Average (on the epoch) training loss: 49.168941497802734\n",
      "Episode average V value: 30.979978561401367\n",
      "Average (on the epoch) training loss: 49.45994567871094\n",
      "Episode average V value: 1.5939173301060994\n",
      "Average (on the epoch) training loss: 49.28085708618164\n",
      "Episode average V value: 34.525577545166016\n",
      "Average (on the epoch) training loss: 49.43099594116211\n",
      "Episode average V value: 38.41346740722656\n",
      "Average (on the epoch) training loss: 49.71284866333008\n",
      "Episode average V value: 31.191818237304688\n",
      "Average (on the epoch) training loss: 49.474483489990234\n",
      "Episode average V value: 28.44843101501465\n",
      "Average (on the epoch) training loss: 49.68308639526367\n",
      "Episode average V value: 30.836097717285156\n",
      "Average (on the epoch) training loss: 49.968204498291016\n",
      "Episode average V value: 26.32683785756429\n",
      "Average (on the epoch) training loss: 50.25373077392578\n",
      "Episode average V value: 33.44895345514471\n",
      "Average (on the epoch) training loss: 49.99190139770508\n",
      "Episode average V value: 27.789390246073406\n",
      "Average (on the epoch) training loss: 49.851593017578125\n",
      "Episode average V value: 20.40452178319295\n",
      "Average (on the epoch) training loss: 49.708335876464844\n",
      "Episode average V value: 26.348705450693767\n",
      "Average (on the epoch) training loss: 49.64789962768555\n",
      "Episode average V value: 32.94474792480469\n",
      "Average (on the epoch) training loss: 49.445858001708984\n",
      "Episode average V value: 25.65372931957245\n",
      "Average (on the epoch) training loss: 50.33723068237305\n",
      "Episode average V value: 25.20488425095876\n",
      "epoch 17:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 50.26639175415039\n",
      "Episode average V value: 25.765228271484375\n",
      "Average (on the epoch) training loss: 61.27943801879883\n",
      "Episode average V value: 30.741988355463203\n",
      "Average (on the epoch) training loss: 84.87503051757812\n",
      "Episode average V value: 34.87141799926758\n",
      "Average (on the epoch) training loss: 78.97095489501953\n",
      "Episode average V value: 21.881291429201763\n",
      "Average (on the epoch) training loss: 78.4337158203125\n",
      "Episode average V value: 36.66672134399414\n",
      "Average (on the epoch) training loss: 73.76296997070312\n",
      "Episode average V value: 23.955433289210003\n",
      "Average (on the epoch) training loss: 69.97372436523438\n",
      "Episode average V value: 27.83667927980423\n",
      "Average (on the epoch) training loss: 73.66364288330078\n",
      "Episode average V value: 3.2249168952306113\n",
      "Average (on the epoch) training loss: 73.18067169189453\n",
      "Episode average V value: 23.331117153167725\n",
      "Average (on the epoch) training loss: 68.72844696044922\n",
      "Episode average V value: 24.515994787216187\n",
      "Average (on the epoch) training loss: 67.15557861328125\n",
      "Episode average V value: 23.32413323720296\n",
      "Average (on the epoch) training loss: 64.73673248291016\n",
      "Episode average V value: 25.52910653750102\n",
      "Average (on the epoch) training loss: 68.84343719482422\n",
      "Episode average V value: 21.749710083007812\n",
      "Average (on the epoch) training loss: 68.94794464111328\n",
      "Episode average V value: 38.82765197753906\n",
      "Average (on the epoch) training loss: 66.26737976074219\n",
      "Episode average V value: 29.286492029825848\n",
      "Average (on the epoch) training loss: 64.02841186523438\n",
      "Episode average V value: 35.634736796220146\n",
      "Average (on the epoch) training loss: 63.92469787597656\n",
      "Episode average V value: 29.05556066830953\n",
      "Average (on the epoch) training loss: 65.37620544433594\n",
      "Episode average V value: 24.212741591713645\n",
      "Average (on the epoch) training loss: 62.996315002441406\n",
      "Episode average V value: 33.28751754760742\n",
      "Average (on the epoch) training loss: 63.09730911254883\n",
      "Episode average V value: 29.994568824768066\n",
      "Average (on the epoch) training loss: 61.72168731689453\n",
      "Episode average V value: 31.185815811157227\n",
      "Average (on the epoch) training loss: 60.27557373046875\n",
      "Episode average V value: 38.19362258911133\n",
      "Average (on the epoch) training loss: 61.06625747680664\n",
      "Episode average V value: 36.893434842427574\n",
      "Average (on the epoch) training loss: 61.76588439941406\n",
      "Episode average V value: 27.670411745707195\n",
      "Average (on the epoch) training loss: 61.43232345581055\n",
      "Episode average V value: 29.91211999456088\n",
      "Average (on the epoch) training loss: 61.244415283203125\n",
      "Episode average V value: 31.396371841430664\n",
      "Average (on the epoch) training loss: 60.863521575927734\n",
      "Episode average V value: 31.20785864194234\n",
      "Average (on the epoch) training loss: 60.02754211425781\n",
      "Episode average V value: 35.939231872558594\n",
      "Average (on the epoch) training loss: 59.68996810913086\n",
      "Episode average V value: 36.910743886774235\n",
      "Average (on the epoch) training loss: 60.34144592285156\n",
      "Episode average V value: 31.185574690500896\n",
      "Average (on the epoch) training loss: 59.08905792236328\n",
      "Episode average V value: 25.810482144355774\n",
      "Average (on the epoch) training loss: 59.221710205078125\n",
      "Episode average V value: 31.298463821411133\n",
      "Average (on the epoch) training loss: 58.42155075073242\n",
      "Episode average V value: 23.32763757308324\n",
      "Average (on the epoch) training loss: 57.44732666015625\n",
      "Episode average V value: 33.24251627922058\n",
      "Average (on the epoch) training loss: 57.84441375732422\n",
      "Episode average V value: 29.3370676835378\n",
      "Average (on the epoch) training loss: 58.37806701660156\n",
      "Episode average V value: 31.04279899597168\n",
      "Average (on the epoch) training loss: 57.3917121887207\n",
      "Episode average V value: 29.29783058166504\n",
      "Average (on the epoch) training loss: 59.02562713623047\n",
      "Episode average V value: 36.427619298299156\n",
      "Average (on the epoch) training loss: 58.75826644897461\n",
      "Episode average V value: 32.71931838989258\n",
      "Average (on the epoch) training loss: 57.81527328491211\n",
      "Episode average V value: 30.556482315063477\n",
      "Average (on the epoch) training loss: 57.06974792480469\n",
      "Episode average V value: 26.85700269540151\n",
      "Average (on the epoch) training loss: 56.50439453125\n",
      "Episode average V value: 31.875333468119305\n",
      "Average (on the epoch) training loss: 56.30948257446289\n",
      "Episode average V value: 31.9395694732666\n",
      "Average (on the epoch) training loss: 55.603633880615234\n",
      "Episode average V value: 34.91029421488444\n",
      "Average (on the epoch) training loss: 54.87333679199219\n",
      "Episode average V value: 33.9802842537562\n",
      "Average (on the epoch) training loss: 56.003963470458984\n",
      "Episode average V value: 39.34396743774414\n",
      "Average (on the epoch) training loss: 56.39208984375\n",
      "Episode average V value: 30.89652442932129\n",
      "Average (on the epoch) training loss: 56.61119079589844\n",
      "Episode average V value: 31.656336625417072\n",
      "Average (on the epoch) training loss: 56.40694046020508\n",
      "Episode average V value: 29.2242374420166\n",
      "Average (on the epoch) training loss: 55.786922454833984\n",
      "Episode average V value: 28.252901713053387\n",
      "Average (on the epoch) training loss: 55.520259857177734\n",
      "Episode average V value: 44.03428390622139\n",
      "Average (on the epoch) training loss: 55.90810775756836\n",
      "Episode average V value: 34.76883598168691\n",
      "Average (on the epoch) training loss: 56.39844512939453\n",
      "Episode average V value: 24.89809187253316\n",
      "Average (on the epoch) training loss: 56.4752197265625\n",
      "Episode average V value: 29.863718032836914\n",
      "Average (on the epoch) training loss: 56.342987060546875\n",
      "Episode average V value: 21.955126921335857\n",
      "Average (on the epoch) training loss: 56.77791213989258\n",
      "Episode average V value: 43.34247064590454\n",
      "Average (on the epoch) training loss: 56.66096878051758\n",
      "Episode average V value: 24.349388122558594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 56.380882263183594\n",
      "Episode average V value: 23.25881924231847\n",
      "Average (on the epoch) training loss: 56.40375518798828\n",
      "Episode average V value: 26.00549300511678\n",
      "Average (on the epoch) training loss: 57.352420806884766\n",
      "Episode average V value: 29.294567902882893\n",
      "Average (on the epoch) training loss: 57.422218322753906\n",
      "Episode average V value: 28.74315071105957\n",
      "Average (on the epoch) training loss: 57.6107292175293\n",
      "Episode average V value: 19.86142764488856\n",
      "Average (on the epoch) training loss: 57.990509033203125\n",
      "Episode average V value: 22.50555729866028\n",
      "Average (on the epoch) training loss: 58.2393684387207\n",
      "Episode average V value: 33.03926086425781\n",
      "Average (on the epoch) training loss: 58.774131774902344\n",
      "Episode average V value: 35.581670024178244\n",
      "Average (on the epoch) training loss: 59.43765640258789\n",
      "Episode average V value: 29.07986068725586\n",
      "Average (on the epoch) training loss: 58.89793395996094\n",
      "Episode average V value: 31.953367233276367\n",
      "Average (on the epoch) training loss: 58.66997146606445\n",
      "Episode average V value: 37.35884586970011\n",
      "Average (on the epoch) training loss: 58.38131332397461\n",
      "Episode average V value: 39.68332084019979\n",
      "Average (on the epoch) training loss: 58.23358917236328\n",
      "Episode average V value: 29.69066031773885\n",
      "Average (on the epoch) training loss: 57.850425720214844\n",
      "Episode average V value: 58.96893310546875\n",
      "Average (on the epoch) training loss: 57.80720901489258\n",
      "Episode average V value: 44.40610885620117\n",
      "Average (on the epoch) training loss: 57.573551177978516\n",
      "Episode average V value: 42.90230925877889\n",
      "Average (on the epoch) training loss: 57.429969787597656\n",
      "Episode average V value: 46.37494309743246\n",
      "Average (on the epoch) training loss: 57.14650344848633\n",
      "Episode average V value: 57.852142333984375\n",
      "Average (on the epoch) training loss: 56.81911849975586\n",
      "Episode average V value: 48.79475784301758\n",
      "Average (on the epoch) training loss: 57.23554992675781\n",
      "Episode average V value: 38.684264789928086\n",
      "Average (on the epoch) training loss: 56.98540496826172\n",
      "Episode average V value: 47.187007904052734\n",
      "Average (on the epoch) training loss: 56.828834533691406\n",
      "Episode average V value: 36.35984420776367\n",
      "Average (on the epoch) training loss: 56.59279251098633\n",
      "Episode average V value: 45.719320933024086\n",
      "Average (on the epoch) training loss: 56.244728088378906\n",
      "Episode average V value: 50.2232780456543\n",
      "Average (on the epoch) training loss: 56.03837585449219\n",
      "Episode average V value: 58.63077163696289\n",
      "Average (on the epoch) training loss: 55.79907989501953\n",
      "Episode average V value: 49.183037439982094\n",
      "Average (on the epoch) training loss: 55.638370513916016\n",
      "Episode average V value: 60.7741953531901\n",
      "Average (on the epoch) training loss: 56.115257263183594\n",
      "Episode average V value: 48.88815371195475\n",
      "Average (on the epoch) training loss: 55.760372161865234\n",
      "Episode average V value: 42.30125427246094\n",
      "Average (on the epoch) training loss: 55.49628448486328\n",
      "Episode average V value: 40.709446708361305\n",
      "Average (on the epoch) training loss: 55.79811477661133\n",
      "Episode average V value: 49.08539708455404\n",
      "Average (on the epoch) training loss: 56.0653190612793\n",
      "Episode average V value: 56.1865119934082\n",
      "Average (on the epoch) training loss: 56.10054397583008\n",
      "Episode average V value: 32.34190420309702\n",
      "Average (on the epoch) training loss: 56.27763366699219\n",
      "Episode average V value: 39.92869186401367\n",
      "Average (on the epoch) training loss: 56.24741744995117\n",
      "Episode average V value: 40.61885070800781\n",
      "Average (on the epoch) training loss: 55.96181106567383\n",
      "Episode average V value: 44.559364000956215\n",
      "Average (on the epoch) training loss: 55.77128219604492\n",
      "Episode average V value: 40.88969612121582\n",
      "Average (on the epoch) training loss: 55.54852294921875\n",
      "Episode average V value: 58.971190452575684\n",
      "Average (on the epoch) training loss: 55.81239318847656\n",
      "Episode average V value: 43.68873802820841\n",
      "Average (on the epoch) training loss: 55.97058868408203\n",
      "Episode average V value: 40.73063643773397\n",
      "Average (on the epoch) training loss: 56.34767532348633\n",
      "Episode average V value: 38.742431640625\n",
      "Average (on the epoch) training loss: 56.107791900634766\n",
      "Episode average V value: 39.73727575937907\n",
      "Average (on the epoch) training loss: 55.9875373840332\n",
      "Episode average V value: 38.58425881465276\n",
      "epoch 18:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 41.98015213012695\n",
      "Episode average V value: 42.60598039627075\n",
      "Average (on the epoch) training loss: 63.64145278930664\n",
      "Episode average V value: 45.63216781616211\n",
      "Average (on the epoch) training loss: 52.67829132080078\n",
      "Episode average V value: 43.69738737742106\n",
      "Average (on the epoch) training loss: 46.36775588989258\n",
      "Episode average V value: 48.56744384765625\n",
      "Average (on the epoch) training loss: 57.9860954284668\n",
      "Episode average V value: 38.337259928385414\n",
      "Average (on the epoch) training loss: 56.48481750488281\n",
      "Episode average V value: 49.75480651855469\n",
      "Average (on the epoch) training loss: 55.17273712158203\n",
      "Episode average V value: 41.24088716506958\n",
      "Average (on the epoch) training loss: 52.38448715209961\n",
      "Episode average V value: 53.350276947021484\n",
      "Average (on the epoch) training loss: 50.17356491088867\n",
      "Episode average V value: 48.26906967163086\n",
      "Average (on the epoch) training loss: 48.65523910522461\n",
      "Episode average V value: 64.89014434814453\n",
      "Average (on the epoch) training loss: 48.815982818603516\n",
      "Episode average V value: 46.42835168043772\n",
      "Average (on the epoch) training loss: 47.763404846191406\n",
      "Episode average V value: 38.28107452392578\n",
      "Average (on the epoch) training loss: 47.17171859741211\n",
      "Episode average V value: -370.3081730206807\n",
      "Average (on the epoch) training loss: 46.54452133178711\n",
      "Episode average V value: 60.76340068470348\n",
      "Average (on the epoch) training loss: 45.78046798706055\n",
      "Episode average V value: 49.878379821777344\n",
      "Average (on the epoch) training loss: 45.35578536987305\n",
      "Episode average V value: 46.653249913995914\n",
      "Average (on the epoch) training loss: 46.908790588378906\n",
      "Episode average V value: 39.13773198561235\n",
      "Average (on the epoch) training loss: 47.64918518066406\n",
      "Episode average V value: 43.871124267578125\n",
      "Average (on the epoch) training loss: 47.85856628417969\n",
      "Episode average V value: 41.66911697387695\n",
      "Average (on the epoch) training loss: 48.584659576416016\n",
      "Episode average V value: 51.751731872558594\n",
      "Average (on the epoch) training loss: 52.386375427246094\n",
      "Episode average V value: 48.456547260284424\n",
      "Average (on the epoch) training loss: 51.88605880737305\n",
      "Episode average V value: 39.50921058654785\n",
      "Average (on the epoch) training loss: 51.5465202331543\n",
      "Episode average V value: 50.6110558943315\n",
      "Average (on the epoch) training loss: 50.72220230102539\n",
      "Episode average V value: 43.397290070851646\n",
      "Average (on the epoch) training loss: 52.41802215576172\n",
      "Episode average V value: 50.19712829589844\n",
      "Average (on the epoch) training loss: 52.45535659790039\n",
      "Episode average V value: 40.72259855270386\n",
      "Average (on the epoch) training loss: 51.75883102416992\n",
      "Episode average V value: 38.600390520962804\n",
      "Average (on the epoch) training loss: 51.394927978515625\n",
      "Episode average V value: 48.968238830566406\n",
      "Average (on the epoch) training loss: 50.91728591918945\n",
      "Episode average V value: 50.299171447753906\n",
      "Average (on the epoch) training loss: 50.45914077758789\n",
      "Episode average V value: 49.2517192363739\n",
      "Average (on the epoch) training loss: 51.462188720703125\n",
      "Episode average V value: 48.555389404296875\n",
      "Average (on the epoch) training loss: 51.08356857299805\n",
      "Episode average V value: 38.83289543787638\n",
      "Average (on the epoch) training loss: 51.85565948486328\n",
      "Episode average V value: 33.206084887186684\n",
      "Average (on the epoch) training loss: 51.16618347167969\n",
      "Episode average V value: 48.53306579589844\n",
      "Average (on the epoch) training loss: 51.760868072509766\n",
      "Episode average V value: 60.553214645385744\n",
      "Average (on the epoch) training loss: 51.49294662475586\n",
      "Episode average V value: 40.45104932785034\n",
      "Average (on the epoch) training loss: 51.31694412231445\n",
      "Episode average V value: 37.49095630645752\n",
      "Average (on the epoch) training loss: 51.84758377075195\n",
      "Episode average V value: 47.773468017578125\n",
      "Average (on the epoch) training loss: 52.65159225463867\n",
      "Episode average V value: 44.36860879262289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 53.36042785644531\n",
      "Episode average V value: 55.8052864074707\n",
      "Average (on the epoch) training loss: 54.09687423706055\n",
      "Episode average V value: 39.982714080810545\n",
      "Average (on the epoch) training loss: 54.10044479370117\n",
      "Episode average V value: 33.40833520889282\n",
      "Average (on the epoch) training loss: 54.44918441772461\n",
      "Episode average V value: 51.39921951293945\n",
      "Average (on the epoch) training loss: 55.57951736450195\n",
      "Episode average V value: 24.812538623809814\n",
      "Average (on the epoch) training loss: 56.25829315185547\n",
      "Episode average V value: 33.69963836669922\n",
      "Average (on the epoch) training loss: 56.181087493896484\n",
      "Episode average V value: 49.2635498046875\n",
      "Average (on the epoch) training loss: 57.8163948059082\n",
      "Episode average V value: 48.95960831642151\n",
      "Average (on the epoch) training loss: 57.47121810913086\n",
      "Episode average V value: 39.87358792622884\n",
      "Average (on the epoch) training loss: 56.86745834350586\n",
      "Episode average V value: 43.512195428212486\n",
      "Average (on the epoch) training loss: 56.41670608520508\n",
      "Episode average V value: 33.350064277648926\n",
      "Average (on the epoch) training loss: 56.390037536621094\n",
      "Episode average V value: 50.187005162239075\n",
      "Average (on the epoch) training loss: 55.89120864868164\n",
      "Episode average V value: 31.14420239130656\n",
      "Average (on the epoch) training loss: 56.190406799316406\n",
      "Episode average V value: 56.11167907714844\n",
      "Average (on the epoch) training loss: 55.62008285522461\n",
      "Episode average V value: 47.886531829833984\n",
      "Average (on the epoch) training loss: 55.73715591430664\n",
      "Episode average V value: 42.812808990478516\n",
      "Average (on the epoch) training loss: 57.060733795166016\n",
      "Episode average V value: 47.05113220214844\n",
      "Average (on the epoch) training loss: 56.928688049316406\n",
      "Episode average V value: 51.284507751464844\n",
      "Average (on the epoch) training loss: 57.73844528198242\n",
      "Episode average V value: 34.15530776977539\n",
      "Average (on the epoch) training loss: 58.22624206542969\n",
      "Episode average V value: 39.26847457885742\n",
      "Average (on the epoch) training loss: 58.121482849121094\n",
      "Episode average V value: 49.27302567164103\n",
      "Average (on the epoch) training loss: 58.44155502319336\n",
      "Episode average V value: 27.798807779947918\n",
      "Average (on the epoch) training loss: 59.048954010009766\n",
      "Episode average V value: 46.799897034962974\n",
      "Average (on the epoch) training loss: 58.73152160644531\n",
      "Episode average V value: 49.12919235229492\n",
      "Average (on the epoch) training loss: 58.54807662963867\n",
      "Episode average V value: 45.73753341039022\n",
      "Average (on the epoch) training loss: 58.13631820678711\n",
      "Episode average V value: 49.53378566106161\n",
      "Average (on the epoch) training loss: 58.173152923583984\n",
      "Episode average V value: 61.20075607299805\n",
      "Average (on the epoch) training loss: 58.56877899169922\n",
      "Episode average V value: 49.619053522745766\n",
      "Average (on the epoch) training loss: 59.27286148071289\n",
      "Episode average V value: 47.40948902476918\n",
      "Average (on the epoch) training loss: 59.22171401977539\n",
      "Episode average V value: 49.305519819259644\n",
      "Average (on the epoch) training loss: 59.24522399902344\n",
      "Episode average V value: 42.464210510253906\n",
      "Average (on the epoch) training loss: 59.88779067993164\n",
      "Episode average V value: 39.3382271528244\n",
      "Average (on the epoch) training loss: 60.00786209106445\n",
      "Episode average V value: 34.10967413584391\n",
      "Average (on the epoch) training loss: 59.658409118652344\n",
      "Episode average V value: 42.02590804298719\n",
      "Average (on the epoch) training loss: 59.207481384277344\n",
      "Episode average V value: 38.05193402550437\n",
      "Average (on the epoch) training loss: 59.131797790527344\n",
      "Episode average V value: 39.38823069135348\n",
      "Average (on the epoch) training loss: 58.78515625\n",
      "Episode average V value: 54.050537109375\n",
      "Average (on the epoch) training loss: 58.432960510253906\n",
      "Episode average V value: 43.25155119462447\n",
      "Average (on the epoch) training loss: 58.35301971435547\n",
      "Episode average V value: 30.336827278137207\n",
      "Average (on the epoch) training loss: 58.555015563964844\n",
      "Episode average V value: 52.29929765065511\n",
      "Average (on the epoch) training loss: 58.85453414916992\n",
      "Episode average V value: 41.38576889038086\n",
      "Average (on the epoch) training loss: 59.12943649291992\n",
      "Episode average V value: 42.15379095077515\n",
      "Average (on the epoch) training loss: 58.79817581176758\n",
      "Episode average V value: 53.72551345825195\n",
      "Average (on the epoch) training loss: 58.504390716552734\n",
      "Episode average V value: 60.35507583618164\n",
      "Average (on the epoch) training loss: 58.220794677734375\n",
      "Episode average V value: 42.76569366455078\n",
      "Average (on the epoch) training loss: 57.996028900146484\n",
      "Episode average V value: 59.70269775390625\n",
      "Average (on the epoch) training loss: 57.785457611083984\n",
      "Episode average V value: 41.37135171890259\n",
      "Average (on the epoch) training loss: 58.376243591308594\n",
      "Episode average V value: 54.799922943115234\n",
      "Average (on the epoch) training loss: 58.62720489501953\n",
      "Episode average V value: 45.44016953309377\n",
      "Average (on the epoch) training loss: 58.53239440917969\n",
      "Episode average V value: 44.577783823013306\n",
      "Average (on the epoch) training loss: 58.35004806518555\n",
      "Episode average V value: 39.446993033091225\n",
      "Average (on the epoch) training loss: 58.06704330444336\n",
      "Episode average V value: 46.00105651219686\n",
      "Average (on the epoch) training loss: 57.804622650146484\n",
      "Episode average V value: 51.09020837148031\n",
      "Average (on the epoch) training loss: 58.020912170410156\n",
      "Episode average V value: 44.08467102050781\n",
      "Average (on the epoch) training loss: 58.236873626708984\n",
      "Episode average V value: 51.76372559865316\n",
      "Average (on the epoch) training loss: 58.80130386352539\n",
      "Episode average V value: 47.84210968017578\n",
      "Average (on the epoch) training loss: 58.84160614013672\n",
      "Episode average V value: 41.97478103637695\n",
      "Average (on the epoch) training loss: 58.514652252197266\n",
      "Episode average V value: 27.922182261943817\n",
      "Average (on the epoch) training loss: 58.505672454833984\n",
      "Episode average V value: 52.52091725667318\n",
      "Average (on the epoch) training loss: 58.73115158081055\n",
      "Episode average V value: 46.81881332397461\n",
      "Average (on the epoch) training loss: 58.6889533996582\n",
      "Episode average V value: 42.049808502197266\n",
      "epoch 19:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 105.05648803710938\n",
      "Episode average V value: 39.17397960027059\n",
      "Average (on the epoch) training loss: 68.2395248413086\n",
      "Episode average V value: 53.50918197631836\n",
      "Average (on the epoch) training loss: 61.36293029785156\n",
      "Episode average V value: 53.748724619547524\n",
      "Average (on the epoch) training loss: 61.5245246887207\n",
      "Episode average V value: 31.452233227816496\n",
      "Average (on the epoch) training loss: 58.86936569213867\n",
      "Episode average V value: 42.01262982686361\n",
      "Average (on the epoch) training loss: 63.44272994995117\n",
      "Episode average V value: 47.12976058324178\n",
      "Average (on the epoch) training loss: 63.93484878540039\n",
      "Episode average V value: 51.921905517578125\n",
      "Average (on the epoch) training loss: 59.982723236083984\n",
      "Episode average V value: 48.10983657836914\n",
      "Average (on the epoch) training loss: 62.458683013916016\n",
      "Episode average V value: 47.86605850855509\n",
      "Average (on the epoch) training loss: 66.70643615722656\n",
      "Episode average V value: 44.809139251708984\n",
      "Average (on the epoch) training loss: 62.739192962646484\n",
      "Episode average V value: 36.29096380869547\n",
      "Average (on the epoch) training loss: 61.44234848022461\n",
      "Episode average V value: 53.52859592437744\n",
      "Average (on the epoch) training loss: 61.27475357055664\n",
      "Episode average V value: 48.66963195800781\n",
      "Average (on the epoch) training loss: 59.000511169433594\n",
      "Episode average V value: 40.513512351296164\n",
      "Average (on the epoch) training loss: 56.839561462402344\n",
      "Episode average V value: 42.7471923828125\n",
      "Average (on the epoch) training loss: 59.10640335083008\n",
      "Episode average V value: 41.348392486572266\n",
      "Average (on the epoch) training loss: 58.303321838378906\n",
      "Episode average V value: 42.52178188165029\n",
      "Average (on the epoch) training loss: 58.72913360595703\n",
      "Episode average V value: 42.47464460134506\n",
      "Average (on the epoch) training loss: 58.7913703918457\n",
      "Episode average V value: 39.49249839782715\n",
      "Average (on the epoch) training loss: 58.902305603027344\n",
      "Episode average V value: 42.15576171875\n",
      "Average (on the epoch) training loss: 60.621673583984375\n",
      "Episode average V value: 45.95826721191406\n",
      "Average (on the epoch) training loss: 61.3089714050293\n",
      "Episode average V value: 38.49212447079745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 61.121150970458984\n",
      "Episode average V value: 42.78361129760742\n",
      "Average (on the epoch) training loss: 60.04216766357422\n",
      "Episode average V value: 49.23137458165487\n",
      "Average (on the epoch) training loss: 58.862056732177734\n",
      "Episode average V value: 47.98471530278524\n",
      "Average (on the epoch) training loss: 59.39739227294922\n",
      "Episode average V value: 54.3553581237793\n",
      "Average (on the epoch) training loss: 59.72944259643555\n",
      "Episode average V value: -366.7395981152852\n",
      "Average (on the epoch) training loss: 60.190940856933594\n",
      "Episode average V value: 38.6330197652181\n",
      "Average (on the epoch) training loss: 61.07038116455078\n",
      "Episode average V value: 39.10771338144938\n",
      "Average (on the epoch) training loss: 60.76454544067383\n",
      "Episode average V value: 47.94438171386719\n",
      "Average (on the epoch) training loss: 61.9527473449707\n",
      "Episode average V value: 39.541986812244765\n",
      "Average (on the epoch) training loss: 60.81193923950195\n",
      "Episode average V value: 35.77406565348307\n",
      "Average (on the epoch) training loss: 60.799869537353516\n",
      "Episode average V value: 38.60218387842178\n",
      "Average (on the epoch) training loss: 61.71381759643555\n",
      "Episode average V value: 34.850324630737305\n",
      "Average (on the epoch) training loss: 60.3916015625\n",
      "Episode average V value: 21.03812837600708\n",
      "Average (on the epoch) training loss: 60.91427993774414\n",
      "Episode average V value: 31.975005467732746\n",
      "Average (on the epoch) training loss: 59.755035400390625\n",
      "Episode average V value: 31.122573852539062\n",
      "Average (on the epoch) training loss: 60.12366485595703\n",
      "Episode average V value: 30.6909236907959\n",
      "Average (on the epoch) training loss: 60.071998596191406\n",
      "Episode average V value: -441.6323087865656\n",
      "Average (on the epoch) training loss: 60.07589340209961\n",
      "Episode average V value: 27.56827211380005\n",
      "Average (on the epoch) training loss: 61.04668426513672\n",
      "Episode average V value: 33.12306594848633\n",
      "Average (on the epoch) training loss: 61.04549789428711\n",
      "Episode average V value: 28.127864201863606\n",
      "Average (on the epoch) training loss: 60.7692985534668\n",
      "Episode average V value: 20.118179321289062\n",
      "Average (on the epoch) training loss: 59.899967193603516\n",
      "Episode average V value: 31.6455078125\n",
      "Average (on the epoch) training loss: 59.71605682373047\n",
      "Episode average V value: 22.21048927307129\n",
      "Average (on the epoch) training loss: 60.214256286621094\n",
      "Episode average V value: 26.529651323954266\n",
      "Average (on the epoch) training loss: 60.6012077331543\n",
      "Episode average V value: 26.103425979614258\n",
      "Average (on the epoch) training loss: 60.00100326538086\n",
      "Episode average V value: 22.03074836730957\n",
      "Average (on the epoch) training loss: 60.491451263427734\n",
      "Episode average V value: 41.121829986572266\n",
      "Average (on the epoch) training loss: 60.19127655029297\n",
      "Episode average V value: 24.30890766779582\n",
      "Average (on the epoch) training loss: 59.54697799682617\n",
      "Episode average V value: 24.927688598632812\n",
      "Average (on the epoch) training loss: 60.58401107788086\n",
      "Episode average V value: 47.31708908081055\n",
      "Average (on the epoch) training loss: 60.0274543762207\n",
      "Episode average V value: 21.79529025337913\n",
      "Average (on the epoch) training loss: 59.40150451660156\n",
      "Episode average V value: 37.290470123291016\n",
      "Average (on the epoch) training loss: 59.799869537353516\n",
      "Episode average V value: 18.2961524327596\n",
      "Average (on the epoch) training loss: 60.05559539794922\n",
      "Episode average V value: 26.037609895070393\n",
      "Average (on the epoch) training loss: 59.9193115234375\n",
      "Episode average V value: 24.936988910039265\n",
      "Average (on the epoch) training loss: 60.264747619628906\n",
      "Episode average V value: 29.015618165334065\n",
      "Average (on the epoch) training loss: 59.88117980957031\n",
      "Episode average V value: 34.820133209228516\n",
      "Average (on the epoch) training loss: 59.60095977783203\n",
      "Episode average V value: 26.582125222682954\n",
      "Average (on the epoch) training loss: 60.374412536621094\n",
      "Episode average V value: 17.59931977589925\n",
      "Average (on the epoch) training loss: 60.47254180908203\n",
      "Episode average V value: 26.96979545553525\n",
      "Average (on the epoch) training loss: 60.60343933105469\n",
      "Episode average V value: 26.279425621032715\n",
      "Average (on the epoch) training loss: 61.06864929199219\n",
      "Episode average V value: 19.54677391052246\n",
      "Average (on the epoch) training loss: 61.040504455566406\n",
      "Episode average V value: 33.22595556577047\n",
      "Average (on the epoch) training loss: 60.440223693847656\n",
      "Episode average V value: 25.675521330399945\n",
      "Average (on the epoch) training loss: 59.86846923828125\n",
      "Episode average V value: 27.282522439956665\n",
      "Average (on the epoch) training loss: 59.82307052612305\n",
      "Episode average V value: 34.62497121637518\n",
      "Average (on the epoch) training loss: 60.11085510253906\n",
      "Episode average V value: 33.558528900146484\n",
      "Average (on the epoch) training loss: 60.3326530456543\n",
      "Episode average V value: 30.836693187554676\n",
      "Average (on the epoch) training loss: 60.083900451660156\n",
      "Episode average V value: 20.401164531707764\n",
      "Average (on the epoch) training loss: 59.65947723388672\n",
      "Episode average V value: 36.492227713267006\n",
      "Average (on the epoch) training loss: 59.20119857788086\n",
      "Episode average V value: 26.133455117543537\n",
      "Average (on the epoch) training loss: 59.21784210205078\n",
      "Episode average V value: 31.50580644607544\n",
      "Average (on the epoch) training loss: 59.761390686035156\n",
      "Episode average V value: 27.37530978520711\n",
      "Average (on the epoch) training loss: 59.477317810058594\n",
      "Episode average V value: 26.60941522771662\n",
      "Average (on the epoch) training loss: 59.35246276855469\n",
      "Episode average V value: -414.7142279148102\n",
      "Average (on the epoch) training loss: 59.77618408203125\n",
      "Episode average V value: 29.811891555786133\n",
      "Average (on the epoch) training loss: 59.60916519165039\n",
      "Episode average V value: 28.70236647129059\n",
      "Average (on the epoch) training loss: 59.43425369262695\n",
      "Episode average V value: 32.25926192601522\n",
      "Average (on the epoch) training loss: 59.525047302246094\n",
      "Episode average V value: 23.26149781545003\n",
      "Average (on the epoch) training loss: 59.67226791381836\n",
      "Episode average V value: 24.887896060943604\n",
      "Average (on the epoch) training loss: 59.17805480957031\n",
      "Episode average V value: 31.144861221313477\n",
      "Average (on the epoch) training loss: 58.773956298828125\n",
      "Episode average V value: 25.57100096615878\n",
      "Average (on the epoch) training loss: 58.36811447143555\n",
      "Episode average V value: 46.5815315246582\n",
      "Average (on the epoch) training loss: 58.2540397644043\n",
      "Episode average V value: 40.68010711669922\n",
      "Average (on the epoch) training loss: 57.897396087646484\n",
      "Episode average V value: 39.03878402709961\n",
      "Average (on the epoch) training loss: 58.026763916015625\n",
      "Episode average V value: 33.80705261230469\n",
      "Average (on the epoch) training loss: 57.94873809814453\n",
      "Episode average V value: 33.77349090576172\n",
      "Average (on the epoch) training loss: 58.24696731567383\n",
      "Episode average V value: 16.20014021613381\n",
      "Average (on the epoch) training loss: 58.41580581665039\n",
      "Episode average V value: 33.79416608810425\n",
      "Average (on the epoch) training loss: 58.58734130859375\n",
      "Episode average V value: 24.896138763427736\n",
      "Average (on the epoch) training loss: 58.888763427734375\n",
      "Episode average V value: 25.999067306518555\n",
      "Average (on the epoch) training loss: 58.85638427734375\n",
      "Episode average V value: 36.13744354248047\n",
      "Average (on the epoch) training loss: 59.03196334838867\n",
      "Episode average V value: 23.99729573726654\n",
      "Average (on the epoch) training loss: 58.97111511230469\n",
      "Episode average V value: 23.487815856933594\n",
      "Average (on the epoch) training loss: 59.09197998046875\n",
      "Episode average V value: 37.33906936645508\n",
      "Average (on the epoch) training loss: 58.779029846191406\n",
      "Episode average V value: 33.32200264930725\n",
      "Average (on the epoch) training loss: 58.648738861083984\n",
      "Episode average V value: 22.41247844696045\n",
      "Average (on the epoch) training loss: 58.5928955078125\n",
      "Episode average V value: 16.166344035755504\n",
      "epoch 20:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 21.29109001159668\n",
      "Episode average V value: 35.622963190078735\n",
      "Average (on the epoch) training loss: 24.09539794921875\n",
      "Episode average V value: 17.84893461068471\n",
      "Average (on the epoch) training loss: 41.68739318847656\n",
      "Episode average V value: 22.9160639444987\n",
      "Average (on the epoch) training loss: 36.68327331542969\n",
      "Episode average V value: 30.979576269785564\n",
      "Average (on the epoch) training loss: 38.3692512512207\n",
      "Episode average V value: 24.613073348999023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 38.77703094482422\n",
      "Episode average V value: 34.04920895894369\n",
      "Average (on the epoch) training loss: 53.440399169921875\n",
      "Episode average V value: 32.754078431562945\n",
      "Average (on the epoch) training loss: 52.192626953125\n",
      "Episode average V value: 16.39516830444336\n",
      "Average (on the epoch) training loss: 51.05598831176758\n",
      "Episode average V value: 20.803284072875975\n",
      "Average (on the epoch) training loss: 53.36241149902344\n",
      "Episode average V value: 33.221900939941406\n",
      "Average (on the epoch) training loss: 60.639102935791016\n",
      "Episode average V value: 22.516154607137043\n",
      "Average (on the epoch) training loss: 67.06539916992188\n",
      "Episode average V value: 22.52582319577535\n",
      "Average (on the epoch) training loss: 63.73966979980469\n",
      "Episode average V value: 32.458683013916016\n",
      "Average (on the epoch) training loss: 62.01349639892578\n",
      "Episode average V value: 21.59158420562744\n",
      "Average (on the epoch) training loss: 61.18341827392578\n",
      "Episode average V value: 23.65837589899699\n",
      "Average (on the epoch) training loss: 64.20565032958984\n",
      "Episode average V value: 31.419303735097248\n",
      "Average (on the epoch) training loss: 62.60247039794922\n",
      "Episode average V value: 19.204914093017578\n",
      "Average (on the epoch) training loss: 61.72581100463867\n",
      "Episode average V value: 15.360468864440918\n",
      "Average (on the epoch) training loss: 59.594482421875\n",
      "Episode average V value: 16.09202520052592\n",
      "Average (on the epoch) training loss: 58.3077278137207\n",
      "Episode average V value: 33.776729583740234\n",
      "Average (on the epoch) training loss: 60.9350700378418\n",
      "Episode average V value: 22.298163731892902\n",
      "Average (on the epoch) training loss: 60.33087158203125\n",
      "Episode average V value: 15.865746915340424\n",
      "Average (on the epoch) training loss: 59.1302604675293\n",
      "Episode average V value: 23.024085998535156\n",
      "Average (on the epoch) training loss: 57.91762924194336\n",
      "Episode average V value: 32.21737019220988\n",
      "Average (on the epoch) training loss: 56.799530029296875\n",
      "Episode average V value: 40.69368807474772\n",
      "Average (on the epoch) training loss: 55.55765914916992\n",
      "Episode average V value: 34.48893964290619\n",
      "Average (on the epoch) training loss: 54.93101501464844\n",
      "Episode average V value: 23.473374406496685\n",
      "Average (on the epoch) training loss: 55.159202575683594\n",
      "Episode average V value: 36.61001205444336\n",
      "Average (on the epoch) training loss: 56.52031707763672\n",
      "Episode average V value: 27.788648168245953\n",
      "Average (on the epoch) training loss: 56.85042953491211\n",
      "Episode average V value: 5.877057472864787\n",
      "Average (on the epoch) training loss: 55.766475677490234\n",
      "Episode average V value: 23.77873722712199\n",
      "Average (on the epoch) training loss: 54.62196350097656\n",
      "Episode average V value: 17.028723283247515\n",
      "Average (on the epoch) training loss: 53.379173278808594\n",
      "Episode average V value: 15.126906221563166\n",
      "Average (on the epoch) training loss: 52.78163146972656\n",
      "Episode average V value: 34.4072151184082\n",
      "Average (on the epoch) training loss: 52.61305236816406\n",
      "Episode average V value: 23.741281509399414\n",
      "Average (on the epoch) training loss: 51.85843276977539\n",
      "Episode average V value: 26.096747398376465\n",
      "Average (on the epoch) training loss: 51.023475646972656\n",
      "Episode average V value: 34.66544723510742\n",
      "Average (on the epoch) training loss: 50.49512481689453\n",
      "Episode average V value: 27.016632596651714\n",
      "Average (on the epoch) training loss: 50.09682846069336\n",
      "Episode average V value: 28.628483136494953\n",
      "Average (on the epoch) training loss: 49.276180267333984\n",
      "Episode average V value: 23.3012638092041\n",
      "Average (on the epoch) training loss: 49.91456604003906\n",
      "Episode average V value: 27.258443892002106\n",
      "Average (on the epoch) training loss: 49.19662094116211\n",
      "Episode average V value: 21.54027835528056\n",
      "Average (on the epoch) training loss: 48.740135192871094\n",
      "Episode average V value: 17.628220915794373\n",
      "Average (on the epoch) training loss: 48.29590606689453\n",
      "Episode average V value: 36.38999557495117\n",
      "Average (on the epoch) training loss: 47.6096305847168\n",
      "Episode average V value: 26.173187255859375\n",
      "Average (on the epoch) training loss: 47.42710876464844\n",
      "Episode average V value: 31.79305378595988\n",
      "Average (on the epoch) training loss: 47.82289505004883\n",
      "Episode average V value: 13.128722806771597\n",
      "Average (on the epoch) training loss: 47.51856231689453\n",
      "Episode average V value: 18.593183517456055\n",
      "Average (on the epoch) training loss: 46.97404479980469\n",
      "Episode average V value: 19.28798893364993\n",
      "Average (on the epoch) training loss: 46.49897766113281\n",
      "Episode average V value: 25.153915405273438\n",
      "Average (on the epoch) training loss: 46.09282302856445\n",
      "Episode average V value: 35.45075607299805\n",
      "Average (on the epoch) training loss: 47.0471076965332\n",
      "Episode average V value: 32.969597975413\n",
      "Average (on the epoch) training loss: 46.91093826293945\n",
      "Episode average V value: -383.0731647014618\n",
      "Average (on the epoch) training loss: 46.430843353271484\n",
      "Episode average V value: 30.24695348739624\n",
      "Average (on the epoch) training loss: 46.11260223388672\n",
      "Episode average V value: 33.8018319606781\n",
      "Average (on the epoch) training loss: 46.035858154296875\n",
      "Episode average V value: 27.284245057539508\n",
      "Average (on the epoch) training loss: 45.64237976074219\n",
      "Episode average V value: 42.960758209228516\n",
      "Average (on the epoch) training loss: 45.270816802978516\n",
      "Episode average V value: 27.925751845041912\n",
      "Average (on the epoch) training loss: 45.175846099853516\n",
      "Episode average V value: 19.717323303222656\n",
      "Average (on the epoch) training loss: 44.99507141113281\n",
      "Episode average V value: -396.8953821659088\n",
      "Average (on the epoch) training loss: 45.45494842529297\n",
      "Episode average V value: 25.923975706100464\n",
      "Average (on the epoch) training loss: 45.92011260986328\n",
      "Episode average V value: 16.026992451060902\n",
      "Average (on the epoch) training loss: 46.311790466308594\n",
      "Episode average V value: 16.560105562210083\n",
      "Average (on the epoch) training loss: 46.59748458862305\n",
      "Episode average V value: 7.044823169708252\n",
      "Average (on the epoch) training loss: 46.27289581298828\n",
      "Episode average V value: 30.836454391479492\n",
      "Average (on the epoch) training loss: 46.760074615478516\n",
      "Episode average V value: 19.25127601623535\n",
      "Average (on the epoch) training loss: 46.827728271484375\n",
      "Episode average V value: 22.94061787923177\n",
      "Average (on the epoch) training loss: 46.46398162841797\n",
      "Episode average V value: 33.9168586730957\n",
      "Average (on the epoch) training loss: 46.22993850708008\n",
      "Episode average V value: 18.686035633087158\n",
      "Average (on the epoch) training loss: 46.09014129638672\n",
      "Episode average V value: 30.375916401545208\n",
      "Average (on the epoch) training loss: 46.40536117553711\n",
      "Episode average V value: 41.58108901977539\n",
      "Average (on the epoch) training loss: 45.99567794799805\n",
      "Episode average V value: 14.194412231445312\n",
      "Average (on the epoch) training loss: 46.48906707763672\n",
      "Episode average V value: 26.005290667215984\n",
      "Average (on the epoch) training loss: 46.74476623535156\n",
      "Episode average V value: 31.05951499938965\n",
      "Average (on the epoch) training loss: 46.29296112060547\n",
      "Episode average V value: 19.754610061645508\n",
      "Average (on the epoch) training loss: 46.93707275390625\n",
      "Episode average V value: 28.54576301574707\n",
      "Average (on the epoch) training loss: 46.59463882446289\n",
      "Episode average V value: 10.381513595581055\n",
      "Average (on the epoch) training loss: 46.9117431640625\n",
      "Episode average V value: 18.25531045595805\n",
      "Average (on the epoch) training loss: 46.600616455078125\n",
      "Episode average V value: 21.950981934865315\n",
      "Average (on the epoch) training loss: 46.34431076049805\n",
      "Episode average V value: 24.529385089874268\n",
      "Average (on the epoch) training loss: 46.158233642578125\n",
      "Episode average V value: 17.527473883195356\n",
      "Average (on the epoch) training loss: 45.886783599853516\n",
      "Episode average V value: 36.29911581675211\n",
      "Average (on the epoch) training loss: 46.472530364990234\n",
      "Episode average V value: 18.729104562239215\n",
      "Average (on the epoch) training loss: 46.19435119628906\n",
      "Episode average V value: 19.070009231567383\n",
      "Average (on the epoch) training loss: 45.940975189208984\n",
      "Episode average V value: 34.03916931152344\n",
      "Average (on the epoch) training loss: 47.16515350341797\n",
      "Episode average V value: -379.5153419971466\n",
      "Average (on the epoch) training loss: 46.91701126098633\n",
      "Episode average V value: 23.200637470592152\n",
      "Average (on the epoch) training loss: 46.93883514404297\n",
      "Episode average V value: 23.66013773282369\n",
      "Average (on the epoch) training loss: 46.606101989746094\n",
      "Episode average V value: 21.3427595893542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 46.322181701660156\n",
      "Episode average V value: 22.360873381296795\n",
      "Average (on the epoch) training loss: 46.06017303466797\n",
      "Episode average V value: 31.906602382659912\n",
      "Average (on the epoch) training loss: 45.81264114379883\n",
      "Episode average V value: 21.490869522094727\n",
      "Average (on the epoch) training loss: 46.13246536254883\n",
      "Episode average V value: 40.4629545211792\n",
      "Average (on the epoch) training loss: 46.431610107421875\n",
      "Episode average V value: 20.368383407592773\n",
      "Average (on the epoch) training loss: 46.67495346069336\n",
      "Episode average V value: 20.07148504257202\n",
      "Average (on the epoch) training loss: 46.408843994140625\n",
      "Episode average V value: 20.595839897791546\n",
      "Average (on the epoch) training loss: 46.16316223144531\n",
      "Episode average V value: 32.85135269165039\n",
      "Average (on the epoch) training loss: 45.94765853881836\n",
      "Episode average V value: -383.7123688062032\n",
      "Average (on the epoch) training loss: 45.85418701171875\n",
      "Episode average V value: 27.689322471618652\n",
      "Average (on the epoch) training loss: 45.69483184814453\n",
      "Episode average V value: 24.307184908125137\n",
      "epoch 21:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 85.88019561767578\n",
      "Episode average V value: 42.490640714764595\n",
      "Average (on the epoch) training loss: 64.41045379638672\n",
      "Episode average V value: 16.279454112052917\n",
      "Average (on the epoch) training loss: 61.19488525390625\n",
      "Episode average V value: -10.051955223083496\n",
      "Average (on the epoch) training loss: 71.13446044921875\n",
      "Episode average V value: 18.966288407643635\n",
      "Average (on the epoch) training loss: 77.03414154052734\n",
      "Episode average V value: 17.22955246766408\n",
      "Average (on the epoch) training loss: 69.45286560058594\n",
      "Episode average V value: 23.792236328125\n",
      "Average (on the epoch) training loss: 66.57910919189453\n",
      "Episode average V value: 19.651580810546875\n",
      "Average (on the epoch) training loss: 64.2394790649414\n",
      "Episode average V value: 25.06729221343994\n",
      "Average (on the epoch) training loss: 59.86384963989258\n",
      "Episode average V value: 30.21535301208496\n",
      "Average (on the epoch) training loss: 56.6815185546875\n",
      "Episode average V value: 22.790724754333496\n",
      "Average (on the epoch) training loss: 53.72196960449219\n",
      "Episode average V value: 29.99506680170695\n",
      "Average (on the epoch) training loss: 55.844322204589844\n",
      "Episode average V value: -392.33661538362503\n",
      "Average (on the epoch) training loss: 61.31189727783203\n",
      "Episode average V value: 10.249383449554443\n",
      "Average (on the epoch) training loss: 62.53956985473633\n",
      "Episode average V value: 16.181722359223798\n",
      "Average (on the epoch) training loss: 60.45418167114258\n",
      "Episode average V value: 9.384932518005371\n",
      "Average (on the epoch) training loss: 60.29547119140625\n",
      "Episode average V value: 14.170823256174723\n",
      "Average (on the epoch) training loss: 58.290748596191406\n",
      "Episode average V value: 12.406210700670878\n",
      "Average (on the epoch) training loss: 57.56855010986328\n",
      "Episode average V value: 35.24185562133789\n",
      "Average (on the epoch) training loss: 56.064361572265625\n",
      "Episode average V value: 40.03278303146362\n",
      "Average (on the epoch) training loss: 57.47755432128906\n",
      "Episode average V value: 31.716150283813477\n",
      "Average (on the epoch) training loss: 56.205955505371094\n",
      "Episode average V value: 17.81063445409139\n",
      "Average (on the epoch) training loss: 54.840126037597656\n",
      "Episode average V value: 26.733184814453125\n",
      "Average (on the epoch) training loss: 55.285213470458984\n",
      "Episode average V value: 22.683913230895996\n",
      "Average (on the epoch) training loss: 56.3787841796875\n",
      "Episode average V value: 27.261260986328125\n",
      "Average (on the epoch) training loss: 55.93229675292969\n",
      "Episode average V value: 15.75920581817627\n",
      "Average (on the epoch) training loss: 55.06437683105469\n",
      "Episode average V value: 29.478002548217773\n",
      "Average (on the epoch) training loss: 58.05910110473633\n",
      "Episode average V value: 50.26930618286133\n",
      "Average (on the epoch) training loss: 58.41385269165039\n",
      "Episode average V value: 17.963905334472656\n",
      "Average (on the epoch) training loss: 58.879634857177734\n",
      "Episode average V value: 20.071821212768555\n",
      "Average (on the epoch) training loss: 57.93000030517578\n",
      "Episode average V value: 16.363468170166016\n",
      "Average (on the epoch) training loss: 57.15494918823242\n",
      "Episode average V value: 17.166356780312277\n",
      "Average (on the epoch) training loss: 58.803253173828125\n",
      "Episode average V value: 24.568639755249023\n",
      "Average (on the epoch) training loss: 58.735355377197266\n",
      "Episode average V value: 17.823771754900616\n",
      "Average (on the epoch) training loss: 59.480831146240234\n",
      "Episode average V value: 21.028428932030995\n",
      "Average (on the epoch) training loss: 58.888057708740234\n",
      "Episode average V value: 16.791297723849613\n",
      "Average (on the epoch) training loss: 60.42512130737305\n",
      "Episode average V value: 28.852437376976013\n",
      "Average (on the epoch) training loss: 61.001888275146484\n",
      "Episode average V value: -400.4282647479664\n",
      "Average (on the epoch) training loss: 60.53373718261719\n",
      "Episode average V value: 16.23012464696711\n",
      "Average (on the epoch) training loss: 60.74119186401367\n",
      "Episode average V value: 34.26546764373779\n",
      "Average (on the epoch) training loss: 60.022056579589844\n",
      "Episode average V value: 20.407197952270508\n",
      "Average (on the epoch) training loss: 59.55192565917969\n",
      "Episode average V value: 38.38431167602539\n",
      "Average (on the epoch) training loss: 58.98527526855469\n",
      "Episode average V value: 30.094955444335938\n",
      "Average (on the epoch) training loss: 58.332054138183594\n",
      "Episode average V value: 32.494056701660156\n",
      "Average (on the epoch) training loss: 57.43556594848633\n",
      "Episode average V value: 18.955222527186077\n",
      "Average (on the epoch) training loss: 58.19083786010742\n",
      "Episode average V value: 36.269283294677734\n",
      "Average (on the epoch) training loss: 57.57947540283203\n",
      "Episode average V value: 18.74324607849121\n",
      "Average (on the epoch) training loss: 58.045616149902344\n",
      "Episode average V value: 18.623742363669656\n",
      "Average (on the epoch) training loss: 57.45235061645508\n",
      "Episode average V value: 18.29096031188965\n",
      "Average (on the epoch) training loss: 57.826942443847656\n",
      "Episode average V value: 22.863218307495117\n",
      "Average (on the epoch) training loss: 57.25519561767578\n",
      "Episode average V value: 11.0717294216156\n",
      "Average (on the epoch) training loss: 57.387489318847656\n",
      "Episode average V value: 29.746435165405273\n",
      "Average (on the epoch) training loss: 58.13291931152344\n",
      "Episode average V value: 15.032860616842905\n",
      "Average (on the epoch) training loss: 59.589561462402344\n",
      "Episode average V value: 20.40069580078125\n",
      "Average (on the epoch) training loss: 58.7757568359375\n",
      "Episode average V value: 15.226059913635254\n",
      "Average (on the epoch) training loss: 58.87718963623047\n",
      "Episode average V value: 26.07701301574707\n",
      "Average (on the epoch) training loss: 61.272193908691406\n",
      "Episode average V value: 22.968002319335938\n",
      "Average (on the epoch) training loss: 60.60919189453125\n",
      "Episode average V value: 14.249894380569458\n",
      "Average (on the epoch) training loss: 60.59172821044922\n",
      "Episode average V value: 20.980572974681856\n",
      "Average (on the epoch) training loss: 59.8536262512207\n",
      "Episode average V value: 19.979535857836407\n",
      "Average (on the epoch) training loss: 59.52494430541992\n",
      "Episode average V value: 2.2069062319668857\n",
      "Average (on the epoch) training loss: 59.002349853515625\n",
      "Episode average V value: 23.997446060180664\n",
      "Average (on the epoch) training loss: 58.73025894165039\n",
      "Episode average V value: 23.10397243499756\n",
      "Average (on the epoch) training loss: 58.33085250854492\n",
      "Episode average V value: 27.350155274073284\n",
      "Average (on the epoch) training loss: 59.1041145324707\n",
      "Episode average V value: 24.69904136657715\n",
      "Average (on the epoch) training loss: 58.72723388671875\n",
      "Episode average V value: 20.950315872828167\n",
      "Average (on the epoch) training loss: 59.179649353027344\n",
      "Episode average V value: 18.985665877660114\n",
      "Average (on the epoch) training loss: 59.25916290283203\n",
      "Episode average V value: 22.30259028348056\n",
      "Average (on the epoch) training loss: 59.548038482666016\n",
      "Episode average V value: 30.315424621105194\n",
      "Average (on the epoch) training loss: 59.9760627746582\n",
      "Episode average V value: 10.234109242757162\n",
      "Average (on the epoch) training loss: 59.633426666259766\n",
      "Episode average V value: -336.9339360992114\n",
      "Average (on the epoch) training loss: 59.95332336425781\n",
      "Episode average V value: 14.698801040649414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 60.469608306884766\n",
      "Episode average V value: 21.82707405090332\n",
      "Average (on the epoch) training loss: 60.08086395263672\n",
      "Episode average V value: 16.75739860534668\n",
      "Average (on the epoch) training loss: 59.990631103515625\n",
      "Episode average V value: 20.90416669845581\n",
      "Average (on the epoch) training loss: 60.65269088745117\n",
      "Episode average V value: 12.693530102570852\n",
      "Average (on the epoch) training loss: 60.713294982910156\n",
      "Episode average V value: 13.921986480553945\n",
      "Average (on the epoch) training loss: 60.63002395629883\n",
      "Episode average V value: 19.796145005659625\n",
      "Average (on the epoch) training loss: 60.21002197265625\n",
      "Episode average V value: 28.876571257909138\n",
      "Average (on the epoch) training loss: 60.1147575378418\n",
      "Episode average V value: 6.5152520934740705\n",
      "Average (on the epoch) training loss: 59.63789749145508\n",
      "Episode average V value: 27.026474316914875\n",
      "Average (on the epoch) training loss: 59.6220703125\n",
      "Episode average V value: 21.33261251449585\n",
      "Average (on the epoch) training loss: 59.47465515136719\n",
      "Episode average V value: 18.274654388427734\n",
      "Average (on the epoch) training loss: 59.447608947753906\n",
      "Episode average V value: 24.158029814561207\n",
      "Average (on the epoch) training loss: 59.05459213256836\n",
      "Episode average V value: 7.921059211095174\n",
      "Average (on the epoch) training loss: 58.52473831176758\n",
      "Episode average V value: 20.498160521189373\n",
      "Average (on the epoch) training loss: 58.11321258544922\n",
      "Episode average V value: 27.05702018737793\n",
      "Average (on the epoch) training loss: 58.376129150390625\n",
      "Episode average V value: 30.541587829589844\n",
      "Average (on the epoch) training loss: 58.67799377441406\n",
      "Episode average V value: 21.533293147881825\n",
      "Average (on the epoch) training loss: 59.061256408691406\n",
      "Episode average V value: 21.050088743368786\n",
      "Average (on the epoch) training loss: 58.85758972167969\n",
      "Episode average V value: 14.002404848734537\n",
      "Average (on the epoch) training loss: 58.79995346069336\n",
      "Episode average V value: 37.5960693359375\n",
      "Average (on the epoch) training loss: 59.143096923828125\n",
      "Episode average V value: 12.346557319164276\n",
      "Average (on the epoch) training loss: 58.7383918762207\n",
      "Episode average V value: 17.298290252685547\n",
      "Average (on the epoch) training loss: 58.777164459228516\n",
      "Episode average V value: 32.086711710149594\n",
      "Average (on the epoch) training loss: 59.82490539550781\n",
      "Episode average V value: 17.113402843475342\n",
      "Average (on the epoch) training loss: 59.47642135620117\n",
      "Episode average V value: 29.257158279418945\n",
      "Average (on the epoch) training loss: 59.31717300415039\n",
      "Episode average V value: 19.533172737468373\n",
      "Average (on the epoch) training loss: 59.11456298828125\n",
      "Episode average V value: 33.83150919278463\n",
      "Average (on the epoch) training loss: 58.80586624145508\n",
      "Episode average V value: 25.500580549240112\n",
      "Average (on the epoch) training loss: 58.94935607910156\n",
      "Episode average V value: 25.500776290893555\n",
      "epoch 22:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 23.284034729003906\n",
      "Episode average V value: 23.736955960591633\n",
      "Average (on the epoch) training loss: 36.939151763916016\n",
      "Episode average V value: 31.16272735595703\n",
      "Average (on the epoch) training loss: 50.42401885986328\n",
      "Episode average V value: 35.97521710395813\n",
      "Average (on the epoch) training loss: 59.18881607055664\n",
      "Episode average V value: 21.003538688023884\n",
      "Average (on the epoch) training loss: 59.21220779418945\n",
      "Episode average V value: 18.854891300201416\n",
      "Average (on the epoch) training loss: 52.431331634521484\n",
      "Episode average V value: 25.42010235786438\n",
      "Average (on the epoch) training loss: 50.460540771484375\n",
      "Episode average V value: 37.3592417456887\n",
      "Average (on the epoch) training loss: 48.22016906738281\n",
      "Episode average V value: 25.694944540659588\n",
      "Average (on the epoch) training loss: 51.137996673583984\n",
      "Episode average V value: 24.851266860961914\n",
      "Average (on the epoch) training loss: 59.5146598815918\n",
      "Episode average V value: 26.713324785232544\n",
      "Average (on the epoch) training loss: 58.28450012207031\n",
      "Episode average V value: 17.571553508440655\n",
      "Average (on the epoch) training loss: 55.29361343383789\n",
      "Episode average V value: 32.640803813934326\n",
      "Average (on the epoch) training loss: 52.17462921142578\n",
      "Episode average V value: 26.67865562438965\n",
      "Average (on the epoch) training loss: 53.323787689208984\n",
      "Episode average V value: 22.361565430959065\n",
      "Average (on the epoch) training loss: 51.81626510620117\n",
      "Episode average V value: 18.558576663335163\n",
      "Average (on the epoch) training loss: 52.77521896362305\n",
      "Episode average V value: 24.414658719843086\n",
      "Average (on the epoch) training loss: 52.223876953125\n",
      "Episode average V value: 22.322736740112305\n",
      "Average (on the epoch) training loss: 50.40557098388672\n",
      "Episode average V value: 21.361488262812298\n",
      "Average (on the epoch) training loss: 50.830360412597656\n",
      "Episode average V value: 29.492040634155273\n",
      "Average (on the epoch) training loss: 50.1624755859375\n",
      "Episode average V value: 10.089949607849121\n",
      "Average (on the epoch) training loss: 49.71371078491211\n",
      "Episode average V value: 34.48891830444336\n",
      "Average (on the epoch) training loss: 50.78691864013672\n",
      "Episode average V value: 29.282609939575195\n",
      "Average (on the epoch) training loss: 52.7849235534668\n",
      "Episode average V value: 21.74480438232422\n",
      "Average (on the epoch) training loss: 51.18104553222656\n",
      "Episode average V value: 21.081308603286743\n",
      "Average (on the epoch) training loss: 49.96565246582031\n",
      "Episode average V value: 13.458775083223978\n",
      "Average (on the epoch) training loss: 49.66785430908203\n",
      "Episode average V value: 29.055378595987957\n",
      "Average (on the epoch) training loss: 50.08931350708008\n",
      "Episode average V value: 37.037715911865234\n",
      "Average (on the epoch) training loss: 51.73847198486328\n",
      "Episode average V value: 11.227882645346902\n",
      "Average (on the epoch) training loss: 51.29783630371094\n",
      "Episode average V value: 21.351994037628174\n",
      "Average (on the epoch) training loss: 50.25186538696289\n",
      "Episode average V value: 20.895960966746014\n",
      "Average (on the epoch) training loss: 49.846092224121094\n",
      "Episode average V value: 23.487409591674805\n",
      "Average (on the epoch) training loss: 50.28904724121094\n",
      "Episode average V value: -399.2018485069275\n",
      "Average (on the epoch) training loss: 50.88456344604492\n",
      "Episode average V value: 20.001100540161133\n",
      "Average (on the epoch) training loss: 50.46391677856445\n",
      "Episode average V value: 23.70241516828537\n",
      "Average (on the epoch) training loss: 50.640525817871094\n",
      "Episode average V value: 27.063400109608967\n",
      "Average (on the epoch) training loss: 50.642578125\n",
      "Episode average V value: 18.97687292098999\n",
      "Average (on the epoch) training loss: 49.86366653442383\n",
      "Episode average V value: 10.04288101196289\n",
      "Average (on the epoch) training loss: 50.50981521606445\n",
      "Episode average V value: -354.3338520526886\n",
      "Average (on the epoch) training loss: 49.792598724365234\n",
      "Episode average V value: 20.819958249727886\n",
      "Average (on the epoch) training loss: 49.676937103271484\n",
      "Episode average V value: 20.037671522660688\n",
      "Average (on the epoch) training loss: 49.058685302734375\n",
      "Episode average V value: 22.644696322354402\n",
      "Average (on the epoch) training loss: 48.767425537109375\n",
      "Episode average V value: 17.330446243286133\n",
      "Average (on the epoch) training loss: 49.32686233520508\n",
      "Episode average V value: 28.852508544921875\n",
      "Average (on the epoch) training loss: 50.91393280029297\n",
      "Episode average V value: 20.203340530395508\n",
      "Average (on the epoch) training loss: 50.61867904663086\n",
      "Episode average V value: 12.818591813246409\n",
      "Average (on the epoch) training loss: 49.95982360839844\n",
      "Episode average V value: 33.90461810429891\n",
      "Average (on the epoch) training loss: 49.84952926635742\n",
      "Episode average V value: 37.0109748840332\n",
      "Average (on the epoch) training loss: 49.68347930908203\n",
      "Episode average V value: 14.00521328051885\n",
      "Average (on the epoch) training loss: 49.10483169555664\n",
      "Episode average V value: 25.864284873008728\n",
      "Average (on the epoch) training loss: 50.261905670166016\n",
      "Episode average V value: 26.205810546875\n",
      "Average (on the epoch) training loss: 49.613216400146484\n",
      "Episode average V value: 14.419367790222168\n",
      "Average (on the epoch) training loss: 50.13198471069336\n",
      "Episode average V value: 33.916378021240234\n",
      "Average (on the epoch) training loss: 50.97102737426758\n",
      "Episode average V value: 20.082672079404194\n",
      "Average (on the epoch) training loss: 50.840538024902344\n",
      "Episode average V value: 15.075748096812855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 50.57412338256836\n",
      "Episode average V value: 36.588417053222656\n",
      "Average (on the epoch) training loss: 50.717227935791016\n",
      "Episode average V value: 17.611827214558918\n",
      "Average (on the epoch) training loss: 50.680259704589844\n",
      "Episode average V value: 18.33695848782857\n",
      "Average (on the epoch) training loss: 50.40119934082031\n",
      "Episode average V value: 27.321935335795086\n",
      "Average (on the epoch) training loss: 50.232845306396484\n",
      "Episode average V value: 30.617124557495117\n",
      "Average (on the epoch) training loss: 49.709007263183594\n",
      "Episode average V value: 21.86412239074707\n",
      "Average (on the epoch) training loss: 50.12919616699219\n",
      "Episode average V value: 43.40615463256836\n",
      "Average (on the epoch) training loss: 50.2187385559082\n",
      "Episode average V value: 9.351463586091995\n",
      "Average (on the epoch) training loss: 49.76298904418945\n",
      "Episode average V value: 24.796812057495117\n",
      "Average (on the epoch) training loss: 49.276058197021484\n",
      "Episode average V value: 19.316015243530273\n",
      "Average (on the epoch) training loss: 49.38239288330078\n",
      "Episode average V value: 33.38603210449219\n",
      "Average (on the epoch) training loss: 49.137088775634766\n",
      "Episode average V value: 26.796168565750122\n",
      "Average (on the epoch) training loss: 48.794883728027344\n",
      "Episode average V value: 34.84362030029297\n",
      "Average (on the epoch) training loss: 48.827335357666016\n",
      "Episode average V value: 33.204593658447266\n",
      "Average (on the epoch) training loss: 49.071144104003906\n",
      "Episode average V value: 35.86787207921346\n",
      "Average (on the epoch) training loss: 48.96652603149414\n",
      "Episode average V value: 36.649539947509766\n",
      "Average (on the epoch) training loss: 49.35306930541992\n",
      "Episode average V value: 25.568055311838787\n",
      "Average (on the epoch) training loss: 49.71145248413086\n",
      "Episode average V value: 31.174228350321453\n",
      "Average (on the epoch) training loss: 49.248023986816406\n",
      "Episode average V value: 31.749658584594727\n",
      "Average (on the epoch) training loss: 50.217369079589844\n",
      "Episode average V value: 42.74499273300171\n",
      "Average (on the epoch) training loss: 50.826751708984375\n",
      "Episode average V value: 32.111768901348114\n",
      "Average (on the epoch) training loss: 50.52416229248047\n",
      "Episode average V value: 24.749553680419922\n",
      "Average (on the epoch) training loss: 51.02579116821289\n",
      "Episode average V value: 30.810028076171875\n",
      "Average (on the epoch) training loss: 50.85354995727539\n",
      "Episode average V value: 33.41956329345703\n",
      "Average (on the epoch) training loss: 50.508670806884766\n",
      "Episode average V value: 39.18351745605469\n",
      "Average (on the epoch) training loss: 51.08475112915039\n",
      "Episode average V value: 29.97454770406087\n",
      "Average (on the epoch) training loss: 50.79745101928711\n",
      "Episode average V value: 23.579966458407316\n",
      "Average (on the epoch) training loss: 51.15060043334961\n",
      "Episode average V value: 26.118785858154297\n",
      "Average (on the epoch) training loss: 51.470481872558594\n",
      "Episode average V value: 23.36096429824829\n",
      "Average (on the epoch) training loss: 51.75165939331055\n",
      "Episode average V value: 30.344083150227863\n",
      "Average (on the epoch) training loss: 52.20709991455078\n",
      "Episode average V value: 33.91065129366788\n",
      "Average (on the epoch) training loss: 51.822574615478516\n",
      "Episode average V value: 32.72244612375895\n",
      "Average (on the epoch) training loss: 51.52383041381836\n",
      "Episode average V value: 14.7523795041171\n",
      "Average (on the epoch) training loss: 51.6375846862793\n",
      "Episode average V value: 33.409229358037315\n",
      "Average (on the epoch) training loss: 51.732181549072266\n",
      "Episode average V value: 24.55605669816335\n",
      "Average (on the epoch) training loss: 52.14762496948242\n",
      "Episode average V value: 39.387375354766846\n",
      "Average (on the epoch) training loss: 52.46101760864258\n",
      "Episode average V value: 35.57146588961283\n",
      "Average (on the epoch) training loss: 52.508914947509766\n",
      "Episode average V value: 51.02738571166992\n",
      "Average (on the epoch) training loss: 52.60429382324219\n",
      "Episode average V value: 24.989648898442585\n",
      "Average (on the epoch) training loss: 52.6779899597168\n",
      "Episode average V value: 30.110154628753662\n",
      "Average (on the epoch) training loss: 52.62124252319336\n",
      "Episode average V value: 51.32316207885742\n",
      "Average (on the epoch) training loss: 53.02360153198242\n",
      "Episode average V value: 31.02058844132857\n",
      "Average (on the epoch) training loss: 52.672027587890625\n",
      "Episode average V value: 30.357519149780273\n",
      "Average (on the epoch) training loss: 52.39181900024414\n",
      "Episode average V value: 39.76412868499756\n",
      "Average (on the epoch) training loss: 52.25749969482422\n",
      "Episode average V value: 34.20744323730469\n",
      "Average (on the epoch) training loss: 52.039268493652344\n",
      "Episode average V value: 54.00882339477539\n",
      "epoch 23:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 40.84526443481445\n",
      "Episode average V value: 37.302402843128554\n",
      "Average (on the epoch) training loss: 56.80088424682617\n",
      "Episode average V value: 45.053653717041016\n",
      "Average (on the epoch) training loss: 68.06471252441406\n",
      "Episode average V value: 30.85975130399068\n",
      "Average (on the epoch) training loss: 70.77340698242188\n",
      "Episode average V value: 32.74121856689453\n",
      "Average (on the epoch) training loss: 69.55803680419922\n",
      "Episode average V value: 36.53544410069784\n",
      "Average (on the epoch) training loss: 61.61591339111328\n",
      "Episode average V value: 33.459496758200906\n",
      "Average (on the epoch) training loss: 58.899444580078125\n",
      "Episode average V value: 35.40281295776367\n",
      "Average (on the epoch) training loss: 61.33793258666992\n",
      "Episode average V value: 45.0240044593811\n",
      "Average (on the epoch) training loss: 62.33775329589844\n",
      "Episode average V value: 21.119783719380695\n",
      "Average (on the epoch) training loss: 58.43668746948242\n",
      "Episode average V value: 31.72553825378418\n",
      "Average (on the epoch) training loss: 56.98992156982422\n",
      "Episode average V value: 36.061660607655845\n",
      "Average (on the epoch) training loss: 57.58171081542969\n",
      "Episode average V value: 30.728384256362915\n",
      "Average (on the epoch) training loss: 55.469608306884766\n",
      "Episode average V value: 36.91354751586914\n",
      "Average (on the epoch) training loss: 53.795654296875\n",
      "Episode average V value: 38.02656650543213\n",
      "Average (on the epoch) training loss: 55.61835861206055\n",
      "Episode average V value: 34.12620306015015\n",
      "Average (on the epoch) training loss: 56.39875411987305\n",
      "Episode average V value: 34.114627838134766\n",
      "Average (on the epoch) training loss: 55.65141677856445\n",
      "Episode average V value: 33.615236600240074\n",
      "Average (on the epoch) training loss: 56.820213317871094\n",
      "Episode average V value: 42.0125617980957\n",
      "Average (on the epoch) training loss: 54.92551040649414\n",
      "Episode average V value: 22.436871846516926\n",
      "Average (on the epoch) training loss: 56.43941879272461\n",
      "Episode average V value: 42.501898765563965\n",
      "Average (on the epoch) training loss: 57.3141975402832\n",
      "Episode average V value: 36.54267883300781\n",
      "Average (on the epoch) training loss: 55.94416427612305\n",
      "Episode average V value: 33.082985401153564\n",
      "Average (on the epoch) training loss: 55.32020950317383\n",
      "Episode average V value: 27.559968550999958\n",
      "Average (on the epoch) training loss: 56.35275650024414\n",
      "Episode average V value: 39.290799617767334\n",
      "Average (on the epoch) training loss: 54.812583923339844\n",
      "Episode average V value: 28.742058277130127\n",
      "Average (on the epoch) training loss: 53.540584564208984\n",
      "Episode average V value: 37.33019280433655\n",
      "Average (on the epoch) training loss: 53.121490478515625\n",
      "Episode average V value: 34.663522026755594\n",
      "Average (on the epoch) training loss: 52.501312255859375\n",
      "Episode average V value: 48.40018844604492\n",
      "Average (on the epoch) training loss: 51.56966781616211\n",
      "Episode average V value: 34.613311767578125\n",
      "Average (on the epoch) training loss: 52.32483673095703\n",
      "Episode average V value: 43.13968308766683\n",
      "Average (on the epoch) training loss: 51.389076232910156\n",
      "Episode average V value: 36.62014389038086\n",
      "Average (on the epoch) training loss: 50.93149948120117\n",
      "Episode average V value: 46.37679672241211\n",
      "Average (on the epoch) training loss: 50.4693603515625\n",
      "Episode average V value: 15.673778216044107\n",
      "Average (on the epoch) training loss: 49.838043212890625\n",
      "Episode average V value: 31.76152189572652\n",
      "Average (on the epoch) training loss: 49.25010681152344\n",
      "Episode average V value: 58.74885177612305\n",
      "Average (on the epoch) training loss: 48.818302154541016\n",
      "Episode average V value: 40.8298819065094\n",
      "Average (on the epoch) training loss: 48.243404388427734\n",
      "Episode average V value: 27.534482609141957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 49.20543670654297\n",
      "Episode average V value: 34.47731399536133\n",
      "Average (on the epoch) training loss: 48.590362548828125\n",
      "Episode average V value: 31.01902421315511\n",
      "Average (on the epoch) training loss: 47.91041946411133\n",
      "Episode average V value: 36.290252685546875\n",
      "Average (on the epoch) training loss: 47.483558654785156\n",
      "Episode average V value: 13.044699430465698\n",
      "Average (on the epoch) training loss: 47.01255416870117\n",
      "Episode average V value: 23.1697980707342\n",
      "Average (on the epoch) training loss: 48.859004974365234\n",
      "Episode average V value: 42.330196380615234\n",
      "Average (on the epoch) training loss: 48.574310302734375\n",
      "Episode average V value: 30.007234573364258\n",
      "Average (on the epoch) training loss: 48.030582427978516\n",
      "Episode average V value: 35.05106512705485\n",
      "Average (on the epoch) training loss: 47.51856994628906\n",
      "Episode average V value: 36.80037307739258\n",
      "Average (on the epoch) training loss: 47.2484130859375\n",
      "Episode average V value: 34.564175844192505\n",
      "Average (on the epoch) training loss: 46.96337127685547\n",
      "Episode average V value: -376.5331556002299\n",
      "Average (on the epoch) training loss: 46.64618682861328\n",
      "Episode average V value: 32.11619019508362\n",
      "Average (on the epoch) training loss: 47.23116683959961\n",
      "Episode average V value: 35.797980864842735\n",
      "Average (on the epoch) training loss: 47.240169525146484\n",
      "Episode average V value: 35.419403076171875\n",
      "Average (on the epoch) training loss: 46.57311248779297\n",
      "Episode average V value: 16.502099990844727\n",
      "Average (on the epoch) training loss: 46.35790252685547\n",
      "Episode average V value: 32.86665360132853\n",
      "Average (on the epoch) training loss: 46.08842086791992\n",
      "Episode average V value: 31.20489501953125\n",
      "Average (on the epoch) training loss: 45.69865798950195\n",
      "Episode average V value: 21.351622263590496\n",
      "Average (on the epoch) training loss: 45.44603729248047\n",
      "Episode average V value: 40.02832958915017\n",
      "Average (on the epoch) training loss: 45.091365814208984\n",
      "Episode average V value: 26.813376903533936\n",
      "Average (on the epoch) training loss: 44.76308822631836\n",
      "Episode average V value: 38.24536895751953\n",
      "Average (on the epoch) training loss: 44.441162109375\n",
      "Episode average V value: 31.10682487487793\n",
      "Average (on the epoch) training loss: 45.00344467163086\n",
      "Episode average V value: 16.50253222205422\n",
      "Average (on the epoch) training loss: 45.36289596557617\n",
      "Episode average V value: 29.509749094645183\n",
      "Average (on the epoch) training loss: 45.861785888671875\n",
      "Episode average V value: 26.067365487416584\n",
      "Average (on the epoch) training loss: 45.67085647583008\n",
      "Episode average V value: 31.1479549407959\n",
      "Average (on the epoch) training loss: 46.242889404296875\n",
      "Episode average V value: 24.05673521757126\n",
      "Average (on the epoch) training loss: 45.99146270751953\n",
      "Episode average V value: 19.517335891723633\n",
      "Average (on the epoch) training loss: 45.770606994628906\n",
      "Episode average V value: 34.2297248840332\n",
      "Average (on the epoch) training loss: 45.560142517089844\n",
      "Episode average V value: 32.7845573425293\n",
      "Average (on the epoch) training loss: 45.839969635009766\n",
      "Episode average V value: 25.708800236384075\n",
      "Average (on the epoch) training loss: 45.40800857543945\n",
      "Episode average V value: 22.72670555114746\n",
      "Average (on the epoch) training loss: 45.30895233154297\n",
      "Episode average V value: 24.42108492056529\n",
      "Average (on the epoch) training loss: 45.147769927978516\n",
      "Episode average V value: 11.905919194221497\n",
      "Average (on the epoch) training loss: 46.19184875488281\n",
      "Episode average V value: 32.61263235410055\n",
      "Average (on the epoch) training loss: 46.087684631347656\n",
      "Episode average V value: 16.108686606089275\n",
      "Average (on the epoch) training loss: 46.422855377197266\n",
      "Episode average V value: 30.802160263061523\n",
      "Average (on the epoch) training loss: 46.26945877075195\n",
      "Episode average V value: 20.155858039855957\n",
      "Average (on the epoch) training loss: 46.72981643676758\n",
      "Episode average V value: 27.546250104904175\n",
      "Average (on the epoch) training loss: 46.84189987182617\n",
      "Episode average V value: 23.016275485356648\n",
      "Average (on the epoch) training loss: 46.89944076538086\n",
      "Episode average V value: 26.409295082092285\n",
      "Average (on the epoch) training loss: 46.465267181396484\n",
      "Episode average V value: 23.141038179397583\n",
      "Average (on the epoch) training loss: 46.180320739746094\n",
      "Episode average V value: 31.18845142920812\n",
      "Average (on the epoch) training loss: 46.571205139160156\n",
      "Episode average V value: 24.6163387298584\n",
      "Average (on the epoch) training loss: 47.024620056152344\n",
      "Episode average V value: 21.868590875105426\n",
      "Average (on the epoch) training loss: 47.209320068359375\n",
      "Episode average V value: 24.90220069885254\n",
      "Average (on the epoch) training loss: 47.65108871459961\n",
      "Episode average V value: 30.435033480326336\n",
      "Average (on the epoch) training loss: 47.75242233276367\n",
      "Episode average V value: 17.19596250851949\n",
      "Average (on the epoch) training loss: 47.79987716674805\n",
      "Episode average V value: 16.253896713256836\n",
      "Average (on the epoch) training loss: 47.49506759643555\n",
      "Episode average V value: 16.390699299899016\n",
      "Average (on the epoch) training loss: 47.85310745239258\n",
      "Episode average V value: 2.9152297973632812\n",
      "Average (on the epoch) training loss: 47.58076858520508\n",
      "Episode average V value: 20.86470603942871\n",
      "Average (on the epoch) training loss: 47.49137496948242\n",
      "Episode average V value: 27.8194998105367\n",
      "Average (on the epoch) training loss: 47.39828109741211\n",
      "Episode average V value: 31.605623245239258\n",
      "Average (on the epoch) training loss: 47.19875717163086\n",
      "Episode average V value: 39.80244064331055\n",
      "Average (on the epoch) training loss: 47.41054153442383\n",
      "Episode average V value: 17.355580866336823\n",
      "Average (on the epoch) training loss: 47.556358337402344\n",
      "Episode average V value: 27.862472534179688\n",
      "Average (on the epoch) training loss: 47.28634262084961\n",
      "Episode average V value: 18.726075967152912\n",
      "Average (on the epoch) training loss: 47.06572341918945\n",
      "Episode average V value: 37.313533782958984\n",
      "Average (on the epoch) training loss: 46.934730529785156\n",
      "Episode average V value: 23.902090946833294\n",
      "Average (on the epoch) training loss: 46.85558319091797\n",
      "Episode average V value: 17.96401023864746\n",
      "Average (on the epoch) training loss: 46.8165168762207\n",
      "Episode average V value: 26.32362868569114\n",
      "Average (on the epoch) training loss: 47.2154541015625\n",
      "Episode average V value: 12.30874252319336\n",
      "epoch 24:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 58.20808792114258\n",
      "Episode average V value: 20.480922655625776\n",
      "Average (on the epoch) training loss: 57.39370346069336\n",
      "Episode average V value: 26.472158432006836\n",
      "Average (on the epoch) training loss: 46.03230667114258\n",
      "Episode average V value: 27.991832812627155\n",
      "Average (on the epoch) training loss: 38.619564056396484\n",
      "Episode average V value: 24.791733481667258\n",
      "Average (on the epoch) training loss: 36.83753967285156\n",
      "Episode average V value: 23.10451316833496\n",
      "Average (on the epoch) training loss: 47.09536361694336\n",
      "Episode average V value: 31.190340042114258\n",
      "Average (on the epoch) training loss: 47.63326644897461\n",
      "Episode average V value: 20.04264243443807\n",
      "Average (on the epoch) training loss: 49.02658462524414\n",
      "Episode average V value: 31.094411849975586\n",
      "Average (on the epoch) training loss: 52.32005310058594\n",
      "Episode average V value: 29.47132682800293\n",
      "Average (on the epoch) training loss: 52.00676727294922\n",
      "Episode average V value: 5.848610917727153\n",
      "Average (on the epoch) training loss: 48.67600631713867\n",
      "Episode average V value: 16.607690413792927\n",
      "Average (on the epoch) training loss: 47.74497604370117\n",
      "Episode average V value: 37.51416015625\n",
      "Average (on the epoch) training loss: 46.18790054321289\n",
      "Episode average V value: 15.850006004174551\n",
      "Average (on the epoch) training loss: 46.16790008544922\n",
      "Episode average V value: 35.15362532933553\n",
      "Average (on the epoch) training loss: 44.58833694458008\n",
      "Episode average V value: 32.94288609244607\n",
      "Average (on the epoch) training loss: 46.04807662963867\n",
      "Episode average V value: 25.570507049560547\n",
      "Average (on the epoch) training loss: 44.86427688598633\n",
      "Episode average V value: 16.84300422668457\n",
      "Average (on the epoch) training loss: 43.877445220947266\n",
      "Episode average V value: 36.273841857910156\n",
      "Average (on the epoch) training loss: 42.85505676269531\n",
      "Episode average V value: 35.8419303894043\n",
      "Average (on the epoch) training loss: 42.10029602050781\n",
      "Episode average V value: 25.748275756835938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 41.75148391723633\n",
      "Episode average V value: 4.6952775319417315\n",
      "Average (on the epoch) training loss: 40.925994873046875\n",
      "Episode average V value: 16.983339023590087\n",
      "Average (on the epoch) training loss: 42.97600173950195\n",
      "Episode average V value: 27.77533531188965\n",
      "Average (on the epoch) training loss: 42.53477478027344\n",
      "Episode average V value: 22.341249465942383\n",
      "Average (on the epoch) training loss: 41.768280029296875\n",
      "Episode average V value: 38.958412170410156\n",
      "Average (on the epoch) training loss: 41.12686538696289\n",
      "Episode average V value: 28.022803783416748\n",
      "Average (on the epoch) training loss: 40.62032699584961\n",
      "Episode average V value: 38.637006759643555\n",
      "Average (on the epoch) training loss: 40.158729553222656\n",
      "Episode average V value: 29.174771915782582\n",
      "Average (on the epoch) training loss: 39.529212951660156\n",
      "Episode average V value: 35.23057174682617\n",
      "Average (on the epoch) training loss: 40.63482666015625\n",
      "Episode average V value: 29.036867141723633\n",
      "Average (on the epoch) training loss: 39.94656753540039\n",
      "Episode average V value: 20.526787290970486\n",
      "Average (on the epoch) training loss: 39.506797790527344\n",
      "Episode average V value: 26.80643932024638\n",
      "Average (on the epoch) training loss: 39.06471633911133\n",
      "Episode average V value: 28.297024647394817\n",
      "Average (on the epoch) training loss: 39.39866638183594\n",
      "Episode average V value: 43.393985748291016\n",
      "Average (on the epoch) training loss: 39.17555618286133\n",
      "Episode average V value: 45.075801849365234\n",
      "Average (on the epoch) training loss: 40.615570068359375\n",
      "Episode average V value: 33.721379865299575\n",
      "Average (on the epoch) training loss: 40.256675720214844\n",
      "Episode average V value: 36.78097915649414\n",
      "Average (on the epoch) training loss: 39.9748649597168\n",
      "Episode average V value: 31.326016108194988\n",
      "Average (on the epoch) training loss: 39.72990036010742\n",
      "Episode average V value: -432.19300495494497\n",
      "Average (on the epoch) training loss: 39.528480529785156\n",
      "Episode average V value: -362.36119362711906\n",
      "Average (on the epoch) training loss: 39.54745864868164\n",
      "Episode average V value: 66.68878777821858\n",
      "Average (on the epoch) training loss: 39.31482696533203\n",
      "Episode average V value: 53.9350471496582\n",
      "Average (on the epoch) training loss: 39.041168212890625\n",
      "Episode average V value: 42.61583813753995\n",
      "Average (on the epoch) training loss: 38.93898010253906\n",
      "Episode average V value: 38.95646905899048\n",
      "Average (on the epoch) training loss: 38.971710205078125\n",
      "Episode average V value: 45.82791657881303\n",
      "Average (on the epoch) training loss: 38.77898406982422\n",
      "Episode average V value: 55.444881439208984\n",
      "Average (on the epoch) training loss: 38.60769271850586\n",
      "Episode average V value: 24.643465735695578\n",
      "Average (on the epoch) training loss: 38.62699890136719\n",
      "Episode average V value: 37.06509939829508\n",
      "Average (on the epoch) training loss: 40.387271881103516\n",
      "Episode average V value: 37.291324615478516\n",
      "Average (on the epoch) training loss: 41.63677215576172\n",
      "Episode average V value: 24.512199719746906\n",
      "Average (on the epoch) training loss: 41.94919967651367\n",
      "Episode average V value: 32.17960062893954\n",
      "Average (on the epoch) training loss: 43.203094482421875\n",
      "Episode average V value: 48.97178562482198\n",
      "Average (on the epoch) training loss: 44.069801330566406\n",
      "Episode average V value: 47.563629150390625\n",
      "Average (on the epoch) training loss: 44.30188751220703\n",
      "Episode average V value: 34.628090818723045\n",
      "Average (on the epoch) training loss: 44.23909378051758\n",
      "Episode average V value: 34.99023151397705\n",
      "Average (on the epoch) training loss: 44.52098846435547\n",
      "Episode average V value: 30.668891668319702\n",
      "Average (on the epoch) training loss: 44.197261810302734\n",
      "Episode average V value: 43.00614221890768\n",
      "Average (on the epoch) training loss: 44.69779586791992\n",
      "Episode average V value: 39.455997467041016\n",
      "Average (on the epoch) training loss: 45.0001335144043\n",
      "Episode average V value: 43.01211826006571\n",
      "Average (on the epoch) training loss: 45.86567306518555\n",
      "Episode average V value: 36.99861125151316\n",
      "Average (on the epoch) training loss: 46.329071044921875\n",
      "Episode average V value: 23.326508045196533\n",
      "Average (on the epoch) training loss: 46.72957992553711\n",
      "Episode average V value: 41.674163818359375\n",
      "Average (on the epoch) training loss: 47.402008056640625\n",
      "Episode average V value: 39.92714778582255\n",
      "Average (on the epoch) training loss: 47.286834716796875\n",
      "Episode average V value: 31.231393178304035\n",
      "Average (on the epoch) training loss: 47.19007873535156\n",
      "Episode average V value: 56.31657028198242\n",
      "Average (on the epoch) training loss: 47.888206481933594\n",
      "Episode average V value: 37.977433482805885\n",
      "Average (on the epoch) training loss: 47.6185188293457\n",
      "Episode average V value: 38.5284538269043\n",
      "Average (on the epoch) training loss: 48.11627960205078\n",
      "Episode average V value: 58.22683334350586\n",
      "Average (on the epoch) training loss: 48.658843994140625\n",
      "Episode average V value: 38.31544812520345\n",
      "Average (on the epoch) training loss: 48.59945297241211\n",
      "Episode average V value: 41.12652587890625\n",
      "Average (on the epoch) training loss: 48.78371810913086\n",
      "Episode average V value: 39.525256315867104\n",
      "Average (on the epoch) training loss: 48.45408248901367\n",
      "Episode average V value: 39.89127445220947\n",
      "Average (on the epoch) training loss: 48.46330642700195\n",
      "Episode average V value: 52.1457413037618\n",
      "Average (on the epoch) training loss: 48.2476806640625\n",
      "Episode average V value: 43.528900146484375\n",
      "Average (on the epoch) training loss: 49.07670974731445\n",
      "Episode average V value: 27.016843636830647\n",
      "Average (on the epoch) training loss: 49.186767578125\n",
      "Episode average V value: 41.57111740112305\n",
      "Average (on the epoch) training loss: 48.99688720703125\n",
      "Episode average V value: 35.71284103393555\n",
      "Average (on the epoch) training loss: 49.3729133605957\n",
      "Episode average V value: 46.4101448059082\n",
      "Average (on the epoch) training loss: 49.132328033447266\n",
      "Episode average V value: 41.81309509277344\n",
      "Average (on the epoch) training loss: 49.43092346191406\n",
      "Episode average V value: 36.17582321166992\n",
      "Average (on the epoch) training loss: 49.41581344604492\n",
      "Episode average V value: 29.58152707417806\n",
      "Average (on the epoch) training loss: 50.20008850097656\n",
      "Episode average V value: 34.31981341044108\n",
      "Average (on the epoch) training loss: 50.238487243652344\n",
      "Episode average V value: 32.41230197747549\n",
      "Average (on the epoch) training loss: 49.955291748046875\n",
      "Episode average V value: 48.47441809827631\n",
      "Average (on the epoch) training loss: 49.9812126159668\n",
      "Episode average V value: 38.81510309378306\n",
      "Average (on the epoch) training loss: 50.4278564453125\n",
      "Episode average V value: 38.34469755490621\n",
      "Average (on the epoch) training loss: 50.727752685546875\n",
      "Episode average V value: 33.86709098021189\n",
      "Average (on the epoch) training loss: 50.45698547363281\n",
      "Episode average V value: 47.28731918334961\n",
      "Average (on the epoch) training loss: 50.47566223144531\n",
      "Episode average V value: 30.118650436401367\n",
      "Average (on the epoch) training loss: 50.36630630493164\n",
      "Episode average V value: 41.48478317260742\n",
      "Average (on the epoch) training loss: 50.36901092529297\n",
      "Episode average V value: 32.950226267178856\n",
      "Average (on the epoch) training loss: 50.16897201538086\n",
      "Episode average V value: 48.88541030883789\n",
      "Average (on the epoch) training loss: 49.954376220703125\n",
      "Episode average V value: 35.486812591552734\n",
      "Average (on the epoch) training loss: 50.138423919677734\n",
      "Episode average V value: 51.36416244506836\n",
      "Average (on the epoch) training loss: 50.405399322509766\n",
      "Episode average V value: 27.71963044007619\n",
      "Average (on the epoch) training loss: 50.47870635986328\n",
      "Episode average V value: -377.5362761815389\n",
      "Average (on the epoch) training loss: 50.289459228515625\n",
      "Episode average V value: 46.30881881713867\n",
      "Average (on the epoch) training loss: 50.299983978271484\n",
      "Episode average V value: 45.22628529866537\n",
      "Average (on the epoch) training loss: 50.124759674072266\n",
      "Episode average V value: 45.35942761103312\n",
      "Average (on the epoch) training loss: 49.85380554199219\n",
      "Episode average V value: 34.393001556396484\n",
      "epoch 25:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 72.13602447509766\n",
      "Episode average V value: 46.00100655989213\n",
      "Average (on the epoch) training loss: 57.10806655883789\n",
      "Episode average V value: 52.417991638183594\n",
      "Average (on the epoch) training loss: 63.11455535888672\n",
      "Episode average V value: 30.534016132354736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 64.46599578857422\n",
      "Episode average V value: 36.26713991165161\n",
      "Average (on the epoch) training loss: 69.19392395019531\n",
      "Episode average V value: 37.9981575012207\n",
      "Average (on the epoch) training loss: 66.73422241210938\n",
      "Episode average V value: 39.43373425801595\n",
      "Average (on the epoch) training loss: 68.93904113769531\n",
      "Episode average V value: 35.55604684352875\n",
      "Average (on the epoch) training loss: 63.675811767578125\n",
      "Episode average V value: 38.11511115233103\n",
      "Average (on the epoch) training loss: 59.83346939086914\n",
      "Episode average V value: 62.760643005371094\n",
      "Average (on the epoch) training loss: 57.965877532958984\n",
      "Episode average V value: 38.658013343811035\n",
      "Average (on the epoch) training loss: 58.22492599487305\n",
      "Episode average V value: 63.50948715209961\n",
      "Average (on the epoch) training loss: 59.90080261230469\n",
      "Episode average V value: -368.85285870234173\n",
      "Average (on the epoch) training loss: 57.20407485961914\n",
      "Episode average V value: 39.170713583628334\n",
      "Average (on the epoch) training loss: 56.73031234741211\n",
      "Episode average V value: 44.39206059773763\n",
      "Average (on the epoch) training loss: 54.97710418701172\n",
      "Episode average V value: 48.699233531951904\n",
      "Average (on the epoch) training loss: 55.29266357421875\n",
      "Episode average V value: 36.47249343178489\n",
      "Average (on the epoch) training loss: 57.219703674316406\n",
      "Episode average V value: 53.387203216552734\n",
      "Average (on the epoch) training loss: 56.10313415527344\n",
      "Episode average V value: 18.188759605089825\n",
      "Average (on the epoch) training loss: 59.132503509521484\n",
      "Episode average V value: 29.067838668823242\n",
      "Average (on the epoch) training loss: 58.07358169555664\n",
      "Episode average V value: 21.53563419977824\n",
      "Average (on the epoch) training loss: 57.08648681640625\n",
      "Episode average V value: 41.48259735107422\n",
      "Average (on the epoch) training loss: 59.18081283569336\n",
      "Episode average V value: 24.899995883305866\n",
      "Average (on the epoch) training loss: 60.7054443359375\n",
      "Episode average V value: 28.906644264856975\n",
      "Average (on the epoch) training loss: 61.44056701660156\n",
      "Episode average V value: 30.28345598777135\n",
      "Average (on the epoch) training loss: 60.302433013916016\n",
      "Episode average V value: 20.892266114552815\n",
      "Average (on the epoch) training loss: 59.852882385253906\n",
      "Episode average V value: 31.467125459150836\n",
      "Average (on the epoch) training loss: 61.06749725341797\n",
      "Episode average V value: 41.80314254760742\n",
      "Average (on the epoch) training loss: 60.906471252441406\n",
      "Episode average V value: 18.652053197224934\n",
      "Average (on the epoch) training loss: 60.825172424316406\n",
      "Episode average V value: 38.3806037902832\n",
      "Average (on the epoch) training loss: 59.715309143066406\n",
      "Episode average V value: 34.258276505903765\n",
      "Average (on the epoch) training loss: 59.0402717590332\n",
      "Episode average V value: 40.3754997253418\n",
      "Average (on the epoch) training loss: 58.0684700012207\n",
      "Episode average V value: 37.02027225494385\n",
      "Average (on the epoch) training loss: 58.70936584472656\n",
      "Episode average V value: 27.211219867070515\n",
      "Average (on the epoch) training loss: 58.13956069946289\n",
      "Episode average V value: 34.07155990600586\n",
      "Average (on the epoch) training loss: 57.1675910949707\n",
      "Episode average V value: 26.13883451981978\n",
      "Average (on the epoch) training loss: 56.41610336303711\n",
      "Episode average V value: 38.73843765258789\n",
      "Average (on the epoch) training loss: 55.659488677978516\n",
      "Episode average V value: 36.194698333740234\n",
      "Average (on the epoch) training loss: 55.12202835083008\n",
      "Episode average V value: 40.27511978149414\n",
      "Average (on the epoch) training loss: 54.42913055419922\n",
      "Episode average V value: 53.56743240356445\n",
      "Average (on the epoch) training loss: 53.76268768310547\n",
      "Episode average V value: 29.0632266998291\n",
      "Average (on the epoch) training loss: 54.13956832885742\n",
      "Episode average V value: 47.71297836303711\n",
      "Average (on the epoch) training loss: 54.559913635253906\n",
      "Episode average V value: 35.42485157648722\n",
      "Average (on the epoch) training loss: 53.94411849975586\n",
      "Episode average V value: 33.718821128209434\n",
      "Average (on the epoch) training loss: 54.230995178222656\n",
      "Episode average V value: 33.96511427561442\n",
      "Average (on the epoch) training loss: 54.77113723754883\n",
      "Episode average V value: 35.991519927978516\n",
      "Average (on the epoch) training loss: 54.66438674926758\n",
      "Episode average V value: 17.116504351298016\n",
      "Average (on the epoch) training loss: 54.94853210449219\n",
      "Episode average V value: 37.50795213381449\n",
      "Average (on the epoch) training loss: 54.24760055541992\n",
      "Episode average V value: 24.454317410786945\n",
      "Average (on the epoch) training loss: 53.67021560668945\n",
      "Episode average V value: 42.72975540161133\n",
      "Average (on the epoch) training loss: 53.75632858276367\n",
      "Episode average V value: 31.144378662109375\n",
      "Average (on the epoch) training loss: 53.3477668762207\n",
      "Episode average V value: 30.87140127023061\n",
      "Average (on the epoch) training loss: 52.82706069946289\n",
      "Episode average V value: 36.279495557149254\n",
      "Average (on the epoch) training loss: 53.289432525634766\n",
      "Episode average V value: 24.38632806142171\n",
      "Average (on the epoch) training loss: 53.43434143066406\n",
      "Episode average V value: 29.45468258857727\n",
      "Average (on the epoch) training loss: 52.95808029174805\n",
      "Episode average V value: 16.81030209859212\n",
      "Average (on the epoch) training loss: 53.1821403503418\n",
      "Episode average V value: 19.080797715620562\n",
      "Average (on the epoch) training loss: 53.61192321777344\n",
      "Episode average V value: 34.249810775121055\n",
      "Average (on the epoch) training loss: 53.2457389831543\n",
      "Episode average V value: 27.894264221191406\n",
      "Average (on the epoch) training loss: 53.563663482666016\n",
      "Episode average V value: 29.06555636723836\n",
      "Average (on the epoch) training loss: 53.035377502441406\n",
      "Episode average V value: 31.62230857213338\n",
      "Average (on the epoch) training loss: 52.56947326660156\n",
      "Episode average V value: 40.438785552978516\n",
      "Average (on the epoch) training loss: 52.445396423339844\n",
      "Episode average V value: 43.663543701171875\n",
      "Average (on the epoch) training loss: 52.74094772338867\n",
      "Episode average V value: 27.01797546039928\n",
      "Average (on the epoch) training loss: 52.14993667602539\n",
      "Episode average V value: 26.214628219604492\n",
      "Average (on the epoch) training loss: 51.73731994628906\n",
      "Episode average V value: 34.67622637748718\n",
      "Average (on the epoch) training loss: 51.25678634643555\n",
      "Episode average V value: 29.213913599650066\n",
      "Average (on the epoch) training loss: 50.881309509277344\n",
      "Episode average V value: 50.872440338134766\n",
      "Average (on the epoch) training loss: 50.79058837890625\n",
      "Episode average V value: 26.3576602935791\n",
      "Average (on the epoch) training loss: 50.58290100097656\n",
      "Episode average V value: 36.70115661621094\n",
      "Average (on the epoch) training loss: 50.681846618652344\n",
      "Episode average V value: 37.216224670410156\n",
      "Average (on the epoch) training loss: 50.50794219970703\n",
      "Episode average V value: 22.652980883916218\n",
      "Average (on the epoch) training loss: 50.340675354003906\n",
      "Episode average V value: 41.67646945606578\n",
      "Average (on the epoch) training loss: 50.010040283203125\n",
      "Episode average V value: 29.008550557223234\n",
      "Average (on the epoch) training loss: 50.259700775146484\n",
      "Episode average V value: 41.426700592041016\n",
      "Average (on the epoch) training loss: 49.99978256225586\n",
      "Episode average V value: 14.957343101501465\n",
      "Average (on the epoch) training loss: 49.730918884277344\n",
      "Episode average V value: 29.07983112335205\n",
      "Average (on the epoch) training loss: 49.370025634765625\n",
      "Episode average V value: 32.685195732116696\n",
      "Average (on the epoch) training loss: 49.20122146606445\n",
      "Episode average V value: 41.41272735595703\n",
      "Average (on the epoch) training loss: 48.93971633911133\n",
      "Episode average V value: 44.86295096079508\n",
      "Average (on the epoch) training loss: 49.33279800415039\n",
      "Episode average V value: 24.69337813059489\n",
      "Average (on the epoch) training loss: 49.0129508972168\n",
      "Episode average V value: 20.39859390258789\n",
      "Average (on the epoch) training loss: 49.20365524291992\n",
      "Episode average V value: 38.27957979838053\n",
      "Average (on the epoch) training loss: 49.49073028564453\n",
      "Episode average V value: 20.248853365580242\n",
      "Average (on the epoch) training loss: 49.46022415161133\n",
      "Episode average V value: 27.812120957808062\n",
      "Average (on the epoch) training loss: 49.2755126953125\n",
      "Episode average V value: 40.813148498535156\n",
      "Average (on the epoch) training loss: 49.049964904785156\n",
      "Episode average V value: 39.6297137538592\n",
      "Average (on the epoch) training loss: 49.25469970703125\n",
      "Episode average V value: 32.545509338378906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 48.962646484375\n",
      "Episode average V value: 19.589228848616283\n",
      "Average (on the epoch) training loss: 48.730430603027344\n",
      "Episode average V value: 25.248184204101562\n",
      "Average (on the epoch) training loss: 48.715972900390625\n",
      "Episode average V value: 27.98136027654012\n",
      "Average (on the epoch) training loss: 48.4735107421875\n",
      "Episode average V value: 17.89497725168864\n",
      "Average (on the epoch) training loss: 48.259090423583984\n",
      "Episode average V value: 49.2231559753418\n",
      "Average (on the epoch) training loss: 47.99675750732422\n",
      "Episode average V value: 34.637304147084556\n",
      "Average (on the epoch) training loss: 48.3638801574707\n",
      "Episode average V value: 44.79428482055664\n",
      "Average (on the epoch) training loss: 48.58712387084961\n",
      "Episode average V value: 24.621301849683125\n",
      "Average (on the epoch) training loss: 48.75733947753906\n",
      "Episode average V value: 22.83411979675293\n",
      "Average (on the epoch) training loss: 49.02885437011719\n",
      "Episode average V value: 42.5494270324707\n",
      "Average (on the epoch) training loss: 49.32474899291992\n",
      "Episode average V value: -380.88265959421796\n",
      "Average (on the epoch) training loss: 49.17680740356445\n",
      "Episode average V value: 30.367456436157227\n",
      "Average (on the epoch) training loss: 49.678714752197266\n",
      "Episode average V value: 28.40545654296875\n",
      "epoch 26:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 65.19953155517578\n",
      "Episode average V value: 39.2841637134552\n",
      "Average (on the epoch) training loss: 45.73615646362305\n",
      "Episode average V value: -373.6597340106964\n",
      "Average (on the epoch) training loss: 48.623046875\n",
      "Episode average V value: 27.887270390987396\n",
      "Average (on the epoch) training loss: 59.60348129272461\n",
      "Episode average V value: 14.931900024414062\n",
      "Average (on the epoch) training loss: 51.99986267089844\n",
      "Episode average V value: 20.448900560537975\n",
      "Average (on the epoch) training loss: 56.710323333740234\n",
      "Episode average V value: 32.06637032826742\n",
      "Average (on the epoch) training loss: 51.2785758972168\n",
      "Episode average V value: 19.325687328974407\n",
      "Average (on the epoch) training loss: 47.68040084838867\n",
      "Episode average V value: 25.50445166501132\n",
      "Average (on the epoch) training loss: 49.09961700439453\n",
      "Episode average V value: 28.906452655792236\n",
      "Average (on the epoch) training loss: 51.69886779785156\n",
      "Episode average V value: 24.651161193847656\n",
      "Average (on the epoch) training loss: 51.977760314941406\n",
      "Episode average V value: 26.427663803100586\n",
      "Average (on the epoch) training loss: 49.40716552734375\n",
      "Episode average V value: 25.487331867218018\n",
      "Average (on the epoch) training loss: 49.72624969482422\n",
      "Episode average V value: 23.331985343586314\n",
      "Average (on the epoch) training loss: 48.2598876953125\n",
      "Episode average V value: -413.19804763793945\n",
      "Average (on the epoch) training loss: 46.688411712646484\n",
      "Episode average V value: 34.870540618896484\n",
      "Average (on the epoch) training loss: 46.01164627075195\n",
      "Episode average V value: 28.394736448923748\n",
      "Average (on the epoch) training loss: 44.71646499633789\n",
      "Episode average V value: 15.401619651100852\n",
      "Average (on the epoch) training loss: 46.83257293701172\n",
      "Episode average V value: 29.397686004638672\n",
      "Average (on the epoch) training loss: 45.34922790527344\n",
      "Episode average V value: 21.310384273529053\n",
      "Average (on the epoch) training loss: 48.62849807739258\n",
      "Episode average V value: 25.10409515554255\n",
      "Average (on the epoch) training loss: 48.83158874511719\n",
      "Episode average V value: 23.58524010398171\n",
      "Average (on the epoch) training loss: 47.71607971191406\n",
      "Episode average V value: 19.470088243484497\n",
      "Average (on the epoch) training loss: 47.846031188964844\n",
      "Episode average V value: 22.730755647023518\n",
      "Average (on the epoch) training loss: 47.04999923706055\n",
      "Episode average V value: 15.431775093078613\n",
      "Average (on the epoch) training loss: 46.13026428222656\n",
      "Episode average V value: 26.700326919555664\n",
      "Average (on the epoch) training loss: 45.38902282714844\n",
      "Episode average V value: 34.38226433595022\n",
      "Average (on the epoch) training loss: 44.16466522216797\n",
      "Episode average V value: 16.325112024943035\n",
      "Average (on the epoch) training loss: 43.50306701660156\n",
      "Episode average V value: 37.90052032470703\n",
      "Average (on the epoch) training loss: 45.08812713623047\n",
      "Episode average V value: 28.795203526814777\n",
      "Average (on the epoch) training loss: 46.201908111572266\n",
      "Episode average V value: 21.424593058499422\n",
      "Average (on the epoch) training loss: 45.67403793334961\n",
      "Episode average V value: -375.70317924022675\n",
      "Average (on the epoch) training loss: 44.92573165893555\n",
      "Episode average V value: 23.677968502044678\n",
      "Average (on the epoch) training loss: 44.35345458984375\n",
      "Episode average V value: 31.176420211791992\n",
      "Average (on the epoch) training loss: 45.40373992919922\n",
      "Episode average V value: 32.46644973754883\n",
      "Average (on the epoch) training loss: 44.74726486206055\n",
      "Episode average V value: 14.104662934939066\n",
      "Average (on the epoch) training loss: 44.541236877441406\n",
      "Episode average V value: 30.434274673461914\n",
      "Average (on the epoch) training loss: 43.820152282714844\n",
      "Episode average V value: 25.969695170720417\n",
      "Average (on the epoch) training loss: 43.49179458618164\n",
      "Episode average V value: 28.867223898569744\n",
      "Average (on the epoch) training loss: 44.445396423339844\n",
      "Episode average V value: 23.260144233703613\n",
      "Average (on the epoch) training loss: 43.8374137878418\n",
      "Episode average V value: 24.03899574279785\n",
      "Average (on the epoch) training loss: 44.328643798828125\n",
      "Episode average V value: 11.971701939900717\n",
      "Average (on the epoch) training loss: 43.99073791503906\n",
      "Episode average V value: 17.03784118096034\n",
      "Average (on the epoch) training loss: 44.44862365722656\n",
      "Episode average V value: 28.13054096698761\n",
      "Average (on the epoch) training loss: 43.92390060424805\n",
      "Episode average V value: 20.09014900525411\n",
      "Average (on the epoch) training loss: 44.10881805419922\n",
      "Episode average V value: 22.88997459411621\n",
      "Average (on the epoch) training loss: 43.71918869018555\n",
      "Episode average V value: 35.03919219970703\n",
      "Average (on the epoch) training loss: 43.178428649902344\n",
      "Episode average V value: 22.812413771947224\n",
      "Average (on the epoch) training loss: 43.67586898803711\n",
      "Episode average V value: 29.411521911621094\n",
      "Average (on the epoch) training loss: 43.14535903930664\n",
      "Episode average V value: 27.73333168029785\n",
      "Average (on the epoch) training loss: 43.36819076538086\n",
      "Episode average V value: 23.138935804367065\n",
      "Average (on the epoch) training loss: 43.4338493347168\n",
      "Episode average V value: 25.657012939453125\n",
      "Average (on the epoch) training loss: 44.01650619506836\n",
      "Episode average V value: 31.21650505065918\n",
      "Average (on the epoch) training loss: 43.505252838134766\n",
      "Episode average V value: 25.277502059936523\n",
      "Average (on the epoch) training loss: 43.594661712646484\n",
      "Episode average V value: 31.59130533536275\n",
      "Average (on the epoch) training loss: 43.45185852050781\n",
      "Episode average V value: 19.315290451049805\n",
      "Average (on the epoch) training loss: 43.31473922729492\n",
      "Episode average V value: 28.189075311024983\n",
      "Average (on the epoch) training loss: 42.97343826293945\n",
      "Episode average V value: 28.110522717237473\n",
      "Average (on the epoch) training loss: 42.808258056640625\n",
      "Episode average V value: 35.454612731933594\n",
      "Average (on the epoch) training loss: 43.29692840576172\n",
      "Episode average V value: 27.192834854125977\n",
      "Average (on the epoch) training loss: 43.16426467895508\n",
      "Episode average V value: 23.371504147847492\n",
      "Average (on the epoch) training loss: 43.6425895690918\n",
      "Episode average V value: 26.2903498953039\n",
      "Average (on the epoch) training loss: 43.38745880126953\n",
      "Episode average V value: 14.685841162999472\n",
      "Average (on the epoch) training loss: 43.2260856628418\n",
      "Episode average V value: 29.26344045003255\n",
      "Average (on the epoch) training loss: 42.90966796875\n",
      "Episode average V value: 19.86286735534668\n",
      "Average (on the epoch) training loss: 43.581329345703125\n",
      "Episode average V value: 38.08616256713867\n",
      "Average (on the epoch) training loss: 43.86690139770508\n",
      "Episode average V value: 21.90966010093689\n",
      "Average (on the epoch) training loss: 43.58856201171875\n",
      "Episode average V value: 25.45829200744629\n",
      "Average (on the epoch) training loss: 43.99156951904297\n",
      "Episode average V value: 27.34691047668457\n",
      "Average (on the epoch) training loss: 43.73286437988281\n",
      "Episode average V value: 20.00845718383789\n",
      "Average (on the epoch) training loss: 44.14859390258789\n",
      "Episode average V value: 31.70874786376953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 43.84640121459961\n",
      "Episode average V value: 9.874221404393515\n",
      "Average (on the epoch) training loss: 44.47951126098633\n",
      "Episode average V value: 28.605846007664997\n",
      "Average (on the epoch) training loss: 44.661258697509766\n",
      "Episode average V value: 22.603634516398113\n",
      "Average (on the epoch) training loss: 44.73025894165039\n",
      "Episode average V value: 12.415432532628378\n",
      "Average (on the epoch) training loss: 44.7287483215332\n",
      "Episode average V value: 15.600946108500162\n",
      "Average (on the epoch) training loss: 44.42298126220703\n",
      "Episode average V value: 22.54360095659892\n",
      "Average (on the epoch) training loss: 44.53557205200195\n",
      "Episode average V value: 27.826505661010742\n",
      "Average (on the epoch) training loss: 44.92509078979492\n",
      "Episode average V value: 22.31331737836202\n",
      "Average (on the epoch) training loss: 44.90642166137695\n",
      "Episode average V value: 22.56621825695038\n",
      "Average (on the epoch) training loss: 44.77047348022461\n",
      "Episode average V value: 19.260286887486775\n",
      "Average (on the epoch) training loss: 44.677581787109375\n",
      "Episode average V value: 28.558930158615112\n",
      "Average (on the epoch) training loss: 45.31180953979492\n",
      "Episode average V value: 33.071964263916016\n",
      "Average (on the epoch) training loss: 44.993370056152344\n",
      "Episode average V value: 25.93526268005371\n",
      "Average (on the epoch) training loss: 45.1872673034668\n",
      "Episode average V value: 16.56369423866272\n",
      "Average (on the epoch) training loss: 45.02939987182617\n",
      "Episode average V value: 34.37695590655009\n",
      "Average (on the epoch) training loss: 45.1676139831543\n",
      "Episode average V value: 28.224170077930797\n",
      "Average (on the epoch) training loss: 45.34614562988281\n",
      "Episode average V value: 38.00292189915975\n",
      "Average (on the epoch) training loss: 45.94482421875\n",
      "Episode average V value: -427.0055394606157\n",
      "Average (on the epoch) training loss: 45.773921966552734\n",
      "Episode average V value: 41.18617057800293\n",
      "Average (on the epoch) training loss: 45.6237678527832\n",
      "Episode average V value: 42.87681579589844\n",
      "Average (on the epoch) training loss: 45.72066879272461\n",
      "Episode average V value: 43.65196332064542\n",
      "Average (on the epoch) training loss: 45.80144119262695\n",
      "Episode average V value: 53.7715950012207\n",
      "Average (on the epoch) training loss: 45.79364013671875\n",
      "Episode average V value: 40.974246978759766\n",
      "Average (on the epoch) training loss: 45.81010437011719\n",
      "Episode average V value: 63.04538345336914\n",
      "Average (on the epoch) training loss: 45.65760803222656\n",
      "Episode average V value: 30.338014602661133\n",
      "Average (on the epoch) training loss: 46.02707290649414\n",
      "Episode average V value: -433.55101585388184\n",
      "Average (on the epoch) training loss: 45.993045806884766\n",
      "Episode average V value: 34.10683071613312\n",
      "Average (on the epoch) training loss: 45.76792907714844\n",
      "Episode average V value: 41.72148291269938\n",
      "Average (on the epoch) training loss: 46.6387825012207\n",
      "Episode average V value: 43.23040771484375\n",
      "Average (on the epoch) training loss: 47.1531982421875\n",
      "Episode average V value: 33.59711982806524\n",
      "epoch 27:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 48.225643157958984\n",
      "Episode average V value: 58.24814987182617\n",
      "Average (on the epoch) training loss: 59.04203414916992\n",
      "Episode average V value: 35.58860802650452\n",
      "Average (on the epoch) training loss: 63.94817352294922\n",
      "Episode average V value: 43.144355614980064\n",
      "Average (on the epoch) training loss: 65.20574951171875\n",
      "Episode average V value: 42.24775695800781\n",
      "Average (on the epoch) training loss: 58.55479431152344\n",
      "Episode average V value: 49.070334116617836\n",
      "Average (on the epoch) training loss: 57.57056427001953\n",
      "Episode average V value: 50.89085006713867\n",
      "Average (on the epoch) training loss: 57.44773483276367\n",
      "Episode average V value: 51.295101165771484\n",
      "Average (on the epoch) training loss: 53.79827880859375\n",
      "Episode average V value: 39.359745025634766\n",
      "Average (on the epoch) training loss: 51.60715866088867\n",
      "Episode average V value: 54.31394958496094\n",
      "Average (on the epoch) training loss: 53.96309280395508\n",
      "Episode average V value: 43.23790065447489\n",
      "Average (on the epoch) training loss: 51.7869758605957\n",
      "Episode average V value: 35.51328659057617\n",
      "Average (on the epoch) training loss: 52.74924087524414\n",
      "Episode average V value: -355.09209567308426\n",
      "Average (on the epoch) training loss: 51.2558479309082\n",
      "Episode average V value: 45.29937744140625\n",
      "Average (on the epoch) training loss: 49.821197509765625\n",
      "Episode average V value: 49.58358649412791\n",
      "Average (on the epoch) training loss: 50.81562423706055\n",
      "Episode average V value: 51.253692626953125\n",
      "Average (on the epoch) training loss: 51.16538619995117\n",
      "Episode average V value: 40.80983638763428\n",
      "Average (on the epoch) training loss: 51.51267623901367\n",
      "Episode average V value: -359.0899730523427\n",
      "Average (on the epoch) training loss: 50.32872009277344\n",
      "Episode average V value: 45.439791997273765\n",
      "Average (on the epoch) training loss: 51.330867767333984\n",
      "Episode average V value: 37.48254861434301\n",
      "Average (on the epoch) training loss: 51.849365234375\n",
      "Episode average V value: 43.215495586395264\n",
      "Average (on the epoch) training loss: 51.27381896972656\n",
      "Episode average V value: 33.267259101072945\n",
      "Average (on the epoch) training loss: 50.53688049316406\n",
      "Episode average V value: 41.59853744506836\n",
      "Average (on the epoch) training loss: 50.732208251953125\n",
      "Episode average V value: 48.223856608072914\n",
      "Average (on the epoch) training loss: 49.97407531738281\n",
      "Episode average V value: 42.34178473732688\n",
      "Average (on the epoch) training loss: 49.14497375488281\n",
      "Episode average V value: 49.25791549682617\n",
      "Average (on the epoch) training loss: 50.521175384521484\n",
      "Episode average V value: 47.311641693115234\n",
      "Average (on the epoch) training loss: 49.847713470458984\n",
      "Episode average V value: 47.28158950805664\n",
      "Average (on the epoch) training loss: 49.730690002441406\n",
      "Episode average V value: 42.15495363871256\n",
      "Average (on the epoch) training loss: 51.172847747802734\n",
      "Episode average V value: 48.56177806854248\n",
      "Average (on the epoch) training loss: 51.804725646972656\n",
      "Episode average V value: -376.42036604881287\n",
      "Average (on the epoch) training loss: 52.31608200073242\n",
      "Episode average V value: -342.3305670420329\n",
      "Average (on the epoch) training loss: 53.46084213256836\n",
      "Episode average V value: 58.2641487121582\n",
      "Average (on the epoch) training loss: 52.56850051879883\n",
      "Episode average V value: 48.15388107299805\n",
      "Average (on the epoch) training loss: 53.49147033691406\n",
      "Episode average V value: 40.3894157409668\n",
      "Average (on the epoch) training loss: 52.82856750488281\n",
      "Episode average V value: 45.60118865966797\n",
      "Average (on the epoch) training loss: 52.12910079956055\n",
      "Episode average V value: -424.675388509577\n",
      "Average (on the epoch) training loss: 51.696537017822266\n",
      "Episode average V value: 57.84813976287842\n",
      "Average (on the epoch) training loss: 53.40029525756836\n",
      "Episode average V value: 46.438106536865234\n",
      "Average (on the epoch) training loss: 52.888797760009766\n",
      "Episode average V value: 46.82447369893392\n",
      "Average (on the epoch) training loss: 53.138038635253906\n",
      "Episode average V value: 40.412219206492104\n",
      "Average (on the epoch) training loss: 53.033084869384766\n",
      "Episode average V value: 42.392460664113365\n",
      "Average (on the epoch) training loss: 53.00804901123047\n",
      "Episode average V value: -390.5076134999593\n",
      "Average (on the epoch) training loss: 54.19846725463867\n",
      "Episode average V value: 28.44832773009936\n",
      "Average (on the epoch) training loss: 54.0116081237793\n",
      "Episode average V value: 36.709797382354736\n",
      "Average (on the epoch) training loss: 54.19108963012695\n",
      "Episode average V value: 32.84693622589111\n",
      "Average (on the epoch) training loss: 54.06074142456055\n",
      "Episode average V value: -393.17844192186993\n",
      "Average (on the epoch) training loss: 54.09992218017578\n",
      "Episode average V value: 46.37151822176847\n",
      "Average (on the epoch) training loss: 53.53621292114258\n",
      "Episode average V value: -424.02146876942027\n",
      "Average (on the epoch) training loss: 53.32350158691406\n",
      "Episode average V value: 42.4219856262207\n",
      "Average (on the epoch) training loss: 52.828426361083984\n",
      "Episode average V value: -431.4714189009233\n",
      "Average (on the epoch) training loss: 52.66508483886719\n",
      "Episode average V value: 46.20967229207357\n",
      "Average (on the epoch) training loss: 52.29335021972656\n",
      "Episode average V value: 54.589788814385734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 53.069698333740234\n",
      "Episode average V value: 43.54972354571024\n",
      "Average (on the epoch) training loss: 52.563507080078125\n",
      "Episode average V value: 43.63456789652506\n",
      "Average (on the epoch) training loss: 52.22216033935547\n",
      "Episode average V value: 56.95476150512695\n",
      "Average (on the epoch) training loss: 51.886417388916016\n",
      "Episode average V value: 32.98516448338827\n",
      "Average (on the epoch) training loss: 51.44744110107422\n",
      "Episode average V value: 38.743284463882446\n",
      "Average (on the epoch) training loss: 51.29120635986328\n",
      "Episode average V value: 35.92461013793945\n",
      "Average (on the epoch) training loss: 51.034912109375\n",
      "Episode average V value: 46.49124256769816\n",
      "Average (on the epoch) training loss: 51.95368957519531\n",
      "Episode average V value: -380.2001416683197\n",
      "Average (on the epoch) training loss: 52.71112060546875\n",
      "Episode average V value: 36.220975485715\n",
      "Average (on the epoch) training loss: 52.693485260009766\n",
      "Episode average V value: 23.066969752311707\n",
      "Average (on the epoch) training loss: 52.271873474121094\n",
      "Episode average V value: 41.634082555770874\n",
      "Average (on the epoch) training loss: 51.9945068359375\n",
      "Episode average V value: 49.48064960132945\n",
      "Average (on the epoch) training loss: 51.83268356323242\n",
      "Episode average V value: 39.115809539953865\n",
      "Average (on the epoch) training loss: 51.537967681884766\n",
      "Episode average V value: 40.23163410027822\n",
      "Average (on the epoch) training loss: 51.365196228027344\n",
      "Episode average V value: 46.131710052490234\n",
      "Average (on the epoch) training loss: 51.510379791259766\n",
      "Episode average V value: 56.57205581665039\n",
      "Average (on the epoch) training loss: 51.31523132324219\n",
      "Episode average V value: 44.68014144897461\n",
      "Average (on the epoch) training loss: 51.21554946899414\n",
      "Episode average V value: 18.988558451334637\n",
      "Average (on the epoch) training loss: 51.897117614746094\n",
      "Episode average V value: 40.86631361643473\n",
      "Average (on the epoch) training loss: 51.60124969482422\n",
      "Episode average V value: 38.53837585449219\n",
      "Average (on the epoch) training loss: 51.3557014465332\n",
      "Episode average V value: 49.904052734375\n",
      "Average (on the epoch) training loss: 51.12468338012695\n",
      "Episode average V value: -379.62253793080646\n",
      "Average (on the epoch) training loss: 51.582786560058594\n",
      "Episode average V value: 23.14909553527832\n",
      "Average (on the epoch) training loss: 51.34034729003906\n",
      "Episode average V value: 44.8396110534668\n",
      "Average (on the epoch) training loss: 51.664817810058594\n",
      "Episode average V value: 53.178035736083984\n",
      "Average (on the epoch) training loss: 51.466522216796875\n",
      "Episode average V value: 40.98156599564986\n",
      "Average (on the epoch) training loss: 51.2412109375\n",
      "Episode average V value: 45.90973011652628\n",
      "Average (on the epoch) training loss: 51.23550796508789\n",
      "Episode average V value: 47.869343280792236\n",
      "Average (on the epoch) training loss: 51.061431884765625\n",
      "Episode average V value: 36.53015184402466\n",
      "Average (on the epoch) training loss: 51.0440559387207\n",
      "Episode average V value: 51.19093704223633\n",
      "Average (on the epoch) training loss: 51.513954162597656\n",
      "Episode average V value: 48.43838119506836\n",
      "Average (on the epoch) training loss: 51.281776428222656\n",
      "Episode average V value: 33.48332214355469\n",
      "Average (on the epoch) training loss: 51.599632263183594\n",
      "Episode average V value: 34.23638916015625\n",
      "Average (on the epoch) training loss: 51.64691162109375\n",
      "Episode average V value: 51.105712890625\n",
      "Average (on the epoch) training loss: 51.45833969116211\n",
      "Episode average V value: 32.714347610870995\n",
      "Average (on the epoch) training loss: 51.19415283203125\n",
      "Episode average V value: 30.942553798357647\n",
      "Average (on the epoch) training loss: 51.02134323120117\n",
      "Episode average V value: 54.92635726928711\n",
      "Average (on the epoch) training loss: 51.644432067871094\n",
      "Episode average V value: 53.41176732381185\n",
      "Average (on the epoch) training loss: 52.08556365966797\n",
      "Episode average V value: 33.08472514152527\n",
      "Average (on the epoch) training loss: 51.83949661254883\n",
      "Episode average V value: 30.49872938791911\n",
      "Average (on the epoch) training loss: 52.46977996826172\n",
      "Episode average V value: 47.471540451049805\n",
      "Average (on the epoch) training loss: 52.37758255004883\n",
      "Episode average V value: 32.024399836858116\n",
      "Average (on the epoch) training loss: 52.3701286315918\n",
      "Episode average V value: -369.04502932230633\n",
      "Average (on the epoch) training loss: 52.16521453857422\n",
      "Episode average V value: 46.25934982299805\n",
      "Average (on the epoch) training loss: 52.67500686645508\n",
      "Episode average V value: 40.64194037697532\n",
      "Average (on the epoch) training loss: 53.02656555175781\n",
      "Episode average V value: 39.999981005986534\n",
      "Average (on the epoch) training loss: 53.288368225097656\n",
      "Episode average V value: 33.13099352518717\n",
      "Average (on the epoch) training loss: 53.60223388671875\n",
      "Episode average V value: 50.62439560890198\n",
      "epoch 28:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 96.1305923461914\n",
      "Episode average V value: 35.740144888559975\n",
      "Average (on the epoch) training loss: 94.40182495117188\n",
      "Episode average V value: 47.61925379435221\n",
      "Average (on the epoch) training loss: 71.53736114501953\n",
      "Episode average V value: 42.28268051147461\n",
      "Average (on the epoch) training loss: 66.5587387084961\n",
      "Episode average V value: 30.680356582005818\n",
      "Average (on the epoch) training loss: 63.395626068115234\n",
      "Episode average V value: 54.538822174072266\n",
      "Average (on the epoch) training loss: 57.77955627441406\n",
      "Episode average V value: 48.21297541531649\n",
      "Average (on the epoch) training loss: 54.442039489746094\n",
      "Episode average V value: -382.7088599205017\n",
      "Average (on the epoch) training loss: 61.022701263427734\n",
      "Episode average V value: 50.81928253173828\n",
      "Average (on the epoch) training loss: 58.57680892944336\n",
      "Episode average V value: 39.08019129435221\n",
      "Average (on the epoch) training loss: 60.542625427246094\n",
      "Episode average V value: 55.610904693603516\n",
      "Average (on the epoch) training loss: 60.718048095703125\n",
      "Episode average V value: 42.584354400634766\n",
      "Average (on the epoch) training loss: 58.74958038330078\n",
      "Episode average V value: 47.466917991638184\n",
      "Average (on the epoch) training loss: 62.24525451660156\n",
      "Episode average V value: 47.838054895401\n",
      "Average (on the epoch) training loss: 63.6221923828125\n",
      "Episode average V value: 40.537032734264024\n",
      "Average (on the epoch) training loss: 65.62834167480469\n",
      "Episode average V value: 49.63233947753906\n",
      "Average (on the epoch) training loss: 63.24542236328125\n",
      "Episode average V value: 43.71166229248047\n",
      "Average (on the epoch) training loss: 61.34395217895508\n",
      "Episode average V value: 49.3073844909668\n",
      "Average (on the epoch) training loss: 61.820735931396484\n",
      "Episode average V value: 45.97255325317383\n",
      "Average (on the epoch) training loss: 60.98585510253906\n",
      "Episode average V value: 41.89962196350098\n",
      "Average (on the epoch) training loss: 61.432823181152344\n",
      "Episode average V value: 51.80509567260742\n",
      "Average (on the epoch) training loss: 63.712650299072266\n",
      "Episode average V value: 49.04957580566406\n",
      "Average (on the epoch) training loss: 62.10311508178711\n",
      "Episode average V value: 40.733615954717\n",
      "Average (on the epoch) training loss: 61.980369567871094\n",
      "Episode average V value: 32.13557746193626\n",
      "Average (on the epoch) training loss: 61.40873336791992\n",
      "Episode average V value: 39.04999407132467\n",
      "Average (on the epoch) training loss: 60.409271240234375\n",
      "Episode average V value: 33.75433514334939\n",
      "Average (on the epoch) training loss: 61.3642463684082\n",
      "Episode average V value: 44.75315475463867\n",
      "Average (on the epoch) training loss: 60.3447265625\n",
      "Episode average V value: 39.215965588887535\n",
      "Average (on the epoch) training loss: 63.478084564208984\n",
      "Episode average V value: 41.0065803527832\n",
      "Average (on the epoch) training loss: 62.893028259277344\n",
      "Episode average V value: 39.05259641011556\n",
      "Average (on the epoch) training loss: 61.90677261352539\n",
      "Episode average V value: 37.99196934700012\n",
      "Average (on the epoch) training loss: 62.69636917114258\n",
      "Episode average V value: 51.862525939941406\n",
      "Average (on the epoch) training loss: 63.62617874145508\n",
      "Episode average V value: 42.30642429987589\n",
      "Average (on the epoch) training loss: 62.58849334716797\n",
      "Episode average V value: 47.224971771240234\n",
      "Average (on the epoch) training loss: 62.868202209472656\n",
      "Episode average V value: 57.147403717041016\n",
      "Average (on the epoch) training loss: 62.458595275878906\n",
      "Episode average V value: 49.082576751708984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 63.05891799926758\n",
      "Episode average V value: 42.50988974571228\n",
      "Average (on the epoch) training loss: 63.72191619873047\n",
      "Episode average V value: 32.79009654305198\n",
      "Average (on the epoch) training loss: 63.69855499267578\n",
      "Episode average V value: 36.83121236165365\n",
      "Average (on the epoch) training loss: 65.13941192626953\n",
      "Episode average V value: 42.18209457397461\n",
      "Average (on the epoch) training loss: 65.155517578125\n",
      "Episode average V value: 45.716328938802086\n",
      "Average (on the epoch) training loss: 64.95555114746094\n",
      "Episode average V value: 36.592124938964844\n",
      "Average (on the epoch) training loss: 64.91931915283203\n",
      "Episode average V value: 41.608943939208984\n",
      "Average (on the epoch) training loss: 65.15007781982422\n",
      "Episode average V value: 42.21567153930664\n",
      "Average (on the epoch) training loss: 64.97177124023438\n",
      "Episode average V value: 40.815566619237266\n",
      "Average (on the epoch) training loss: 66.08026123046875\n",
      "Episode average V value: 46.14744520187378\n",
      "Average (on the epoch) training loss: 65.5795669555664\n",
      "Episode average V value: 45.15383044156161\n",
      "Average (on the epoch) training loss: 66.34337615966797\n",
      "Episode average V value: 38.801358024279274\n",
      "Average (on the epoch) training loss: 65.83462524414062\n",
      "Episode average V value: 45.506763978437945\n",
      "Average (on the epoch) training loss: 65.181640625\n",
      "Episode average V value: 45.255243142445885\n",
      "Average (on the epoch) training loss: 64.82061004638672\n",
      "Episode average V value: 54.468141873677574\n",
      "Average (on the epoch) training loss: 64.4146499633789\n",
      "Episode average V value: 47.21421265602112\n",
      "Average (on the epoch) training loss: 63.94847869873047\n",
      "Episode average V value: 48.230335076649986\n",
      "Average (on the epoch) training loss: 63.422813415527344\n",
      "Episode average V value: 40.61849229986017\n",
      "Average (on the epoch) training loss: 64.69630432128906\n",
      "Episode average V value: 46.00300645828247\n",
      "Average (on the epoch) training loss: 64.32771301269531\n",
      "Episode average V value: 37.08223509788513\n",
      "Average (on the epoch) training loss: 63.694122314453125\n",
      "Episode average V value: 42.61786651611328\n",
      "Average (on the epoch) training loss: 63.17664337158203\n",
      "Episode average V value: 44.8260498046875\n",
      "Average (on the epoch) training loss: 62.7052116394043\n",
      "Episode average V value: 48.515092849731445\n",
      "Average (on the epoch) training loss: 62.14903259277344\n",
      "Episode average V value: 42.50427659352621\n",
      "Average (on the epoch) training loss: 62.631126403808594\n",
      "Episode average V value: 47.8668909072876\n",
      "Average (on the epoch) training loss: 62.16653823852539\n",
      "Episode average V value: 38.61954148610433\n",
      "Average (on the epoch) training loss: 61.70512008666992\n",
      "Episode average V value: 52.85655212402344\n",
      "Average (on the epoch) training loss: 61.31283950805664\n",
      "Episode average V value: 53.1562614440918\n",
      "Average (on the epoch) training loss: 60.83366394042969\n",
      "Episode average V value: 40.713264067967735\n",
      "Average (on the epoch) training loss: 61.71061706542969\n",
      "Episode average V value: 37.93991986910502\n",
      "Average (on the epoch) training loss: 62.27701950073242\n",
      "Episode average V value: 46.259260614713035\n",
      "Average (on the epoch) training loss: 62.35012435913086\n",
      "Episode average V value: 33.977358384565875\n",
      "Average (on the epoch) training loss: 62.08467483520508\n",
      "Episode average V value: 40.599204977353416\n",
      "Average (on the epoch) training loss: 61.60004425048828\n",
      "Episode average V value: 39.95044469833374\n",
      "Average (on the epoch) training loss: 61.745887756347656\n",
      "Episode average V value: 66.5738525390625\n",
      "Average (on the epoch) training loss: 61.65534210205078\n",
      "Episode average V value: 39.51482963562012\n",
      "Average (on the epoch) training loss: 61.15147018432617\n",
      "Episode average V value: 39.45612716674805\n",
      "Average (on the epoch) training loss: 60.83868408203125\n",
      "Episode average V value: 49.50920041402181\n",
      "Average (on the epoch) training loss: 61.20398712158203\n",
      "Episode average V value: 33.109802881876625\n",
      "Average (on the epoch) training loss: 61.52820587158203\n",
      "Episode average V value: 42.41982130209605\n",
      "Average (on the epoch) training loss: 61.48500061035156\n",
      "Episode average V value: 46.923404693603516\n",
      "Average (on the epoch) training loss: 61.11155700683594\n",
      "Episode average V value: 36.200321197509766\n",
      "Average (on the epoch) training loss: 60.803741455078125\n",
      "Episode average V value: 48.615692138671875\n",
      "Average (on the epoch) training loss: 60.86021041870117\n",
      "Episode average V value: 39.373180866241455\n",
      "Average (on the epoch) training loss: 60.855045318603516\n",
      "Episode average V value: 38.266658782958984\n",
      "Average (on the epoch) training loss: 60.86574172973633\n",
      "Episode average V value: 35.51818450291952\n",
      "Average (on the epoch) training loss: 60.660762786865234\n",
      "Episode average V value: 46.247072792053224\n",
      "Average (on the epoch) training loss: 60.685760498046875\n",
      "Episode average V value: 38.424705505371094\n",
      "Average (on the epoch) training loss: 60.368736267089844\n",
      "Episode average V value: 36.92233339945475\n",
      "Average (on the epoch) training loss: 60.0065803527832\n",
      "Episode average V value: 19.051453669865925\n",
      "Average (on the epoch) training loss: 59.84892654418945\n",
      "Episode average V value: 35.82643973827362\n",
      "Average (on the epoch) training loss: 59.54464340209961\n",
      "Episode average V value: 65.44345092773438\n",
      "Average (on the epoch) training loss: 59.593475341796875\n",
      "Episode average V value: 33.40443309148153\n",
      "Average (on the epoch) training loss: 59.83493423461914\n",
      "Episode average V value: 48.2609748840332\n",
      "Average (on the epoch) training loss: 59.728885650634766\n",
      "Episode average V value: 37.24241495132446\n",
      "Average (on the epoch) training loss: 59.586509704589844\n",
      "Episode average V value: 39.58245225386186\n",
      "Average (on the epoch) training loss: 59.262630462646484\n",
      "Episode average V value: 47.71187845865885\n",
      "Average (on the epoch) training loss: 59.69813537597656\n",
      "Episode average V value: 44.538184801737465\n",
      "Average (on the epoch) training loss: 59.695030212402344\n",
      "Episode average V value: 45.994075775146484\n",
      "Average (on the epoch) training loss: 59.96540069580078\n",
      "Episode average V value: 46.744066874186196\n",
      "Average (on the epoch) training loss: 59.92080307006836\n",
      "Episode average V value: 41.090309143066406\n",
      "Average (on the epoch) training loss: 59.66673278808594\n",
      "Episode average V value: 38.38389007250468\n",
      "Average (on the epoch) training loss: 59.34210968017578\n",
      "Episode average V value: 38.76076567173004\n",
      "Average (on the epoch) training loss: 59.041988372802734\n",
      "Episode average V value: 39.78873602549235\n",
      "Average (on the epoch) training loss: 58.98432922363281\n",
      "Episode average V value: 56.255619049072266\n",
      "epoch 29:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 69.28926849365234\n",
      "Episode average V value: 41.55520566304525\n",
      "Average (on the epoch) training loss: 84.72514343261719\n",
      "Episode average V value: 48.66509819030762\n",
      "Average (on the epoch) training loss: 70.98640441894531\n",
      "Episode average V value: 48.09172058105469\n",
      "Average (on the epoch) training loss: 67.9567642211914\n",
      "Episode average V value: 40.13114639123281\n",
      "Average (on the epoch) training loss: 68.17851257324219\n",
      "Episode average V value: 44.75384521484375\n",
      "Average (on the epoch) training loss: 72.14427185058594\n",
      "Episode average V value: 45.61841458082199\n",
      "Average (on the epoch) training loss: 66.25452423095703\n",
      "Episode average V value: 43.062446753184\n",
      "Average (on the epoch) training loss: 61.7901725769043\n",
      "Episode average V value: 46.31822566986084\n",
      "Average (on the epoch) training loss: 60.336421966552734\n",
      "Episode average V value: 46.2964768409729\n",
      "Average (on the epoch) training loss: 60.85871505737305\n",
      "Episode average V value: 51.184452056884766\n",
      "Average (on the epoch) training loss: 62.11237716674805\n",
      "Episode average V value: 38.32775115966797\n",
      "Average (on the epoch) training loss: 61.92777633666992\n",
      "Episode average V value: 48.309934775034584\n",
      "Average (on the epoch) training loss: 62.44330978393555\n",
      "Episode average V value: -425.2245621247725\n",
      "Average (on the epoch) training loss: 59.876285552978516\n",
      "Episode average V value: 42.805829207102455\n",
      "Average (on the epoch) training loss: 59.04914093017578\n",
      "Episode average V value: 40.15102585156759\n",
      "Average (on the epoch) training loss: 57.36494064331055\n",
      "Episode average V value: 50.148468017578125\n",
      "Average (on the epoch) training loss: 58.974857330322266\n",
      "Episode average V value: 57.83161926269531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 57.70508575439453\n",
      "Episode average V value: 42.14656396706899\n",
      "Average (on the epoch) training loss: 57.79266357421875\n",
      "Episode average V value: 50.22248331705729\n",
      "Average (on the epoch) training loss: 56.817928314208984\n",
      "Episode average V value: 62.818617502848305\n",
      "Average (on the epoch) training loss: 57.91585159301758\n",
      "Episode average V value: 58.446564356486\n",
      "Average (on the epoch) training loss: 56.68095016479492\n",
      "Episode average V value: 42.21980667114258\n",
      "Average (on the epoch) training loss: 55.87140655517578\n",
      "Episode average V value: 42.35929218928019\n",
      "Average (on the epoch) training loss: 56.66400909423828\n",
      "Episode average V value: 49.26952624320984\n",
      "Average (on the epoch) training loss: 55.982696533203125\n",
      "Episode average V value: 44.410640716552734\n",
      "Average (on the epoch) training loss: 55.37922668457031\n",
      "Episode average V value: 29.979715607383035\n",
      "Average (on the epoch) training loss: 55.668235778808594\n",
      "Episode average V value: 52.80414835611979\n",
      "Average (on the epoch) training loss: 54.98930358886719\n",
      "Episode average V value: 60.74284744262695\n",
      "Average (on the epoch) training loss: 54.214866638183594\n",
      "Episode average V value: 39.71405746539434\n",
      "Average (on the epoch) training loss: 53.47979736328125\n",
      "Episode average V value: 45.479092597961426\n",
      "Average (on the epoch) training loss: 52.900115966796875\n",
      "Episode average V value: 46.337466398874916\n",
      "Average (on the epoch) training loss: 52.82951736450195\n",
      "Episode average V value: 58.86801528930664\n",
      "Average (on the epoch) training loss: 53.55778884887695\n",
      "Episode average V value: 49.91730880737305\n",
      "Average (on the epoch) training loss: 53.1533203125\n",
      "Episode average V value: 38.89135913054148\n",
      "Average (on the epoch) training loss: 52.859375\n",
      "Episode average V value: 25.944671869277954\n",
      "Average (on the epoch) training loss: 51.999046325683594\n",
      "Episode average V value: 34.097915967305504\n",
      "Average (on the epoch) training loss: 51.36924362182617\n",
      "Episode average V value: 32.23002020517985\n",
      "Average (on the epoch) training loss: 50.83196258544922\n",
      "Episode average V value: 36.63647413253784\n",
      "Average (on the epoch) training loss: 50.46059036254883\n",
      "Episode average V value: 32.99183511734009\n",
      "Average (on the epoch) training loss: 51.20014953613281\n",
      "Episode average V value: 43.10738754272461\n",
      "Average (on the epoch) training loss: 50.63930130004883\n",
      "Episode average V value: 23.247107696533202\n",
      "Average (on the epoch) training loss: 51.99980545043945\n",
      "Episode average V value: 27.94291877746582\n",
      "Average (on the epoch) training loss: 53.37662124633789\n",
      "Episode average V value: 35.75964585940043\n",
      "Average (on the epoch) training loss: 53.78805160522461\n",
      "Episode average V value: 30.470125198364258\n",
      "Average (on the epoch) training loss: 54.2194938659668\n",
      "Episode average V value: 32.53572312990824\n",
      "Average (on the epoch) training loss: 53.61372756958008\n",
      "Episode average V value: 24.89896535873413\n",
      "Average (on the epoch) training loss: 53.7338752746582\n",
      "Episode average V value: 28.33363628387451\n",
      "Average (on the epoch) training loss: 53.2430534362793\n",
      "Episode average V value: 54.522090911865234\n",
      "Average (on the epoch) training loss: 52.67589569091797\n",
      "Episode average V value: 25.756198088328045\n",
      "Average (on the epoch) training loss: 53.087398529052734\n",
      "Episode average V value: 38.76275666554769\n",
      "Average (on the epoch) training loss: 52.81232833862305\n",
      "Episode average V value: 31.449731826782227\n",
      "Average (on the epoch) training loss: 52.2535514831543\n",
      "Episode average V value: 34.883982398293234\n",
      "Average (on the epoch) training loss: 51.735801696777344\n",
      "Episode average V value: 35.52522277832031\n",
      "Average (on the epoch) training loss: 51.384788513183594\n",
      "Episode average V value: 31.355298678080242\n",
      "Average (on the epoch) training loss: 50.99233627319336\n",
      "Episode average V value: 45.70780563354492\n",
      "Average (on the epoch) training loss: 50.5366096496582\n",
      "Episode average V value: 34.0720651547114\n",
      "Average (on the epoch) training loss: 50.31681823730469\n",
      "Episode average V value: 38.358821868896484\n",
      "Average (on the epoch) training loss: 51.678619384765625\n",
      "Episode average V value: 35.445064544677734\n",
      "Average (on the epoch) training loss: 52.18732833862305\n",
      "Episode average V value: 23.478066444396973\n",
      "Average (on the epoch) training loss: 51.67780303955078\n",
      "Episode average V value: 29.21616554260254\n",
      "Average (on the epoch) training loss: 51.450904846191406\n",
      "Episode average V value: 38.68724875016646\n",
      "Average (on the epoch) training loss: 51.123897552490234\n",
      "Episode average V value: 41.100868225097656\n",
      "Average (on the epoch) training loss: 50.69647979736328\n",
      "Episode average V value: 28.322874704996746\n",
      "Average (on the epoch) training loss: 50.465667724609375\n",
      "Episode average V value: 44.258846282958984\n",
      "Average (on the epoch) training loss: 49.99557876586914\n",
      "Episode average V value: 26.737319548924763\n",
      "Average (on the epoch) training loss: 49.6744384765625\n",
      "Episode average V value: 31.04221471150716\n",
      "Average (on the epoch) training loss: 49.41569519042969\n",
      "Episode average V value: 23.696619868278503\n",
      "Average (on the epoch) training loss: 49.15456008911133\n",
      "Episode average V value: 9.975102598016912\n",
      "Average (on the epoch) training loss: 48.86444091796875\n",
      "Episode average V value: 48.9121208190918\n",
      "Average (on the epoch) training loss: 48.537811279296875\n",
      "Episode average V value: 39.365689277648926\n",
      "Average (on the epoch) training loss: 49.35264587402344\n",
      "Episode average V value: 52.006290435791016\n",
      "Average (on the epoch) training loss: 49.92367935180664\n",
      "Episode average V value: 30.6552791595459\n",
      "Average (on the epoch) training loss: 50.02189636230469\n",
      "Episode average V value: 47.62286376953125\n",
      "Average (on the epoch) training loss: 50.23972702026367\n",
      "Episode average V value: 24.320085207621258\n",
      "Average (on the epoch) training loss: 50.39809799194336\n",
      "Episode average V value: 34.64931869506836\n",
      "Average (on the epoch) training loss: 51.008514404296875\n",
      "Episode average V value: 36.15170896053314\n",
      "Average (on the epoch) training loss: 50.8726692199707\n",
      "Episode average V value: 25.652597427368164\n",
      "Average (on the epoch) training loss: 50.92108154296875\n",
      "Episode average V value: 35.01608808835348\n",
      "Average (on the epoch) training loss: 51.06449508666992\n",
      "Episode average V value: 34.150333404541016\n",
      "Average (on the epoch) training loss: 51.38658142089844\n",
      "Episode average V value: 47.57181167602539\n",
      "Average (on the epoch) training loss: 50.994808197021484\n",
      "Episode average V value: 21.213998794555664\n",
      "Average (on the epoch) training loss: 50.63698959350586\n",
      "Episode average V value: 26.202784697214764\n",
      "Average (on the epoch) training loss: 50.52931213378906\n",
      "Episode average V value: 45.590511322021484\n",
      "Average (on the epoch) training loss: 50.75990676879883\n",
      "Episode average V value: 36.95362255790017\n",
      "Average (on the epoch) training loss: 50.42458724975586\n",
      "Episode average V value: 28.567920684814453\n",
      "Average (on the epoch) training loss: 50.27582550048828\n",
      "Episode average V value: 23.06927134773948\n",
      "Average (on the epoch) training loss: 50.26164245605469\n",
      "Episode average V value: 44.58732986450195\n",
      "Average (on the epoch) training loss: 51.02978515625\n",
      "Episode average V value: 32.557369232177734\n",
      "Average (on the epoch) training loss: 50.709041595458984\n",
      "Episode average V value: 27.476701927185058\n",
      "Average (on the epoch) training loss: 50.56129455566406\n",
      "Episode average V value: 35.25095287958781\n",
      "Average (on the epoch) training loss: 51.00807571411133\n",
      "Episode average V value: 34.63950220743815\n",
      "Average (on the epoch) training loss: 51.124916076660156\n",
      "Episode average V value: 34.10857391357422\n",
      "Average (on the epoch) training loss: 51.032833099365234\n",
      "Episode average V value: 29.533929268519085\n",
      "Average (on the epoch) training loss: 51.07307052612305\n",
      "Episode average V value: 29.89592344110662\n",
      "Average (on the epoch) training loss: 50.81922912597656\n",
      "Episode average V value: 34.22045135498047\n",
      "Average (on the epoch) training loss: 51.25876235961914\n",
      "Episode average V value: 35.538658142089844\n",
      "Average (on the epoch) training loss: 51.428287506103516\n",
      "Episode average V value: 30.00052833557129\n",
      "Average (on the epoch) training loss: 51.13729476928711\n",
      "Episode average V value: 37.36447334289551\n",
      "Average (on the epoch) training loss: 51.6456298828125\n",
      "Episode average V value: 28.02153771573847\n",
      "Average (on the epoch) training loss: 52.39773941040039\n",
      "Episode average V value: 29.95979881286621\n",
      "epoch 30:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 39.842227935791016\n",
      "Episode average V value: 36.289608001708984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 31.994157791137695\n",
      "Episode average V value: 24.42313226064046\n",
      "Average (on the epoch) training loss: 46.13079833984375\n",
      "Episode average V value: 31.262670516967773\n",
      "Average (on the epoch) training loss: 45.79026412963867\n",
      "Episode average V value: 35.7094612121582\n",
      "Average (on the epoch) training loss: 47.22045135498047\n",
      "Episode average V value: 36.05006082852682\n",
      "Average (on the epoch) training loss: 44.650856018066406\n",
      "Episode average V value: 32.91910990079244\n",
      "Average (on the epoch) training loss: 41.73149490356445\n",
      "Episode average V value: 39.73108943303426\n",
      "Average (on the epoch) training loss: 46.9461784362793\n",
      "Episode average V value: 48.27577416102091\n",
      "Average (on the epoch) training loss: 48.10531997680664\n",
      "Episode average V value: 34.87656784057617\n",
      "Average (on the epoch) training loss: 46.559608459472656\n",
      "Episode average V value: 28.858626127243042\n",
      "Average (on the epoch) training loss: 44.70327377319336\n",
      "Episode average V value: 42.02667681376139\n",
      "Average (on the epoch) training loss: 51.02023696899414\n",
      "Episode average V value: 40.279608726501465\n",
      "Average (on the epoch) training loss: 52.41929626464844\n",
      "Episode average V value: 25.847519318262737\n",
      "Average (on the epoch) training loss: 56.640811920166016\n",
      "Episode average V value: 40.46971130371094\n",
      "Average (on the epoch) training loss: 54.91194152832031\n",
      "Episode average V value: 26.671275456746418\n",
      "Average (on the epoch) training loss: 56.25105667114258\n",
      "Episode average V value: 32.20770263671875\n",
      "Average (on the epoch) training loss: 54.21669006347656\n",
      "Episode average V value: 28.06037203470866\n",
      "Average (on the epoch) training loss: 56.76611328125\n",
      "Episode average V value: 32.5741016070048\n",
      "Average (on the epoch) training loss: 56.77061462402344\n",
      "Episode average V value: 21.117094820195977\n",
      "Average (on the epoch) training loss: 54.890357971191406\n",
      "Episode average V value: 14.548536539077759\n",
      "Average (on the epoch) training loss: 54.86028289794922\n",
      "Episode average V value: 22.225662404840644\n",
      "Average (on the epoch) training loss: 56.904415130615234\n",
      "Episode average V value: 20.732235431671143\n",
      "Average (on the epoch) training loss: 56.27119445800781\n",
      "Episode average V value: 14.297299464543661\n",
      "Average (on the epoch) training loss: 57.22990036010742\n",
      "Episode average V value: 17.548565407594044\n",
      "Average (on the epoch) training loss: 57.09963607788086\n",
      "Episode average V value: 20.36885380744934\n",
      "Average (on the epoch) training loss: 56.73954391479492\n",
      "Episode average V value: 24.66601153937253\n",
      "Average (on the epoch) training loss: 57.9980354309082\n",
      "Episode average V value: 30.147454847892124\n",
      "Average (on the epoch) training loss: 57.21041488647461\n",
      "Episode average V value: 18.168724298477173\n",
      "Average (on the epoch) training loss: 56.29690170288086\n",
      "Episode average V value: 31.094064156214397\n",
      "Average (on the epoch) training loss: 55.08140182495117\n",
      "Episode average V value: 25.346102794011433\n",
      "Average (on the epoch) training loss: 55.19010925292969\n",
      "Episode average V value: 32.025634765625\n",
      "Average (on the epoch) training loss: 54.1121826171875\n",
      "Episode average V value: 24.659284830093384\n",
      "Average (on the epoch) training loss: 53.8252067565918\n",
      "Episode average V value: 38.121437072753906\n",
      "Average (on the epoch) training loss: 53.89952087402344\n",
      "Episode average V value: 16.658500909805298\n",
      "Average (on the epoch) training loss: 54.656890869140625\n",
      "Episode average V value: 28.466614549810235\n",
      "Average (on the epoch) training loss: 55.86115646362305\n",
      "Episode average V value: 28.587289810180664\n",
      "Average (on the epoch) training loss: 56.09970474243164\n",
      "Episode average V value: 25.830583890279133\n",
      "Average (on the epoch) training loss: 55.61234664916992\n",
      "Episode average V value: 29.157187938690186\n",
      "Average (on the epoch) training loss: 55.303802490234375\n",
      "Episode average V value: 29.842883110046387\n",
      "Average (on the epoch) training loss: 55.66402816772461\n",
      "Episode average V value: 33.07501220703125\n",
      "Average (on the epoch) training loss: 54.72798538208008\n",
      "Episode average V value: 22.190933227539062\n",
      "Average (on the epoch) training loss: 54.18881607055664\n",
      "Episode average V value: 29.47666358947754\n",
      "Average (on the epoch) training loss: 54.42216873168945\n",
      "Episode average V value: 25.19052799542745\n",
      "Average (on the epoch) training loss: 54.295719146728516\n",
      "Episode average V value: 18.20548525723544\n",
      "Average (on the epoch) training loss: 53.71718215942383\n",
      "Episode average V value: 16.14635957280795\n",
      "Average (on the epoch) training loss: 53.39178466796875\n",
      "Episode average V value: 29.47938088575999\n",
      "Average (on the epoch) training loss: 52.81496047973633\n",
      "Episode average V value: 12.591344833374023\n",
      "Average (on the epoch) training loss: 52.168827056884766\n",
      "Episode average V value: -537.9063550101387\n",
      "Average (on the epoch) training loss: 51.62302017211914\n",
      "Episode average V value: 30.57499885559082\n",
      "Average (on the epoch) training loss: 51.41640090942383\n",
      "Episode average V value: 36.91800308227539\n",
      "Average (on the epoch) training loss: 51.96311950683594\n",
      "Episode average V value: 24.630139748255413\n",
      "Average (on the epoch) training loss: 51.4333381652832\n",
      "Episode average V value: 16.28307791550954\n",
      "Average (on the epoch) training loss: 50.91164016723633\n",
      "Episode average V value: 29.72539710998535\n",
      "Average (on the epoch) training loss: 51.43343734741211\n",
      "Episode average V value: 26.37616777420044\n",
      "Average (on the epoch) training loss: 51.169105529785156\n",
      "Episode average V value: 22.607938766479492\n",
      "Average (on the epoch) training loss: 52.17387390136719\n",
      "Episode average V value: 27.761085510253906\n",
      "Average (on the epoch) training loss: 52.52090072631836\n",
      "Episode average V value: 28.116727828979492\n",
      "Average (on the epoch) training loss: 53.24625015258789\n",
      "Episode average V value: 24.96170129776001\n",
      "Average (on the epoch) training loss: 52.89677047729492\n",
      "Episode average V value: 20.414182949066163\n",
      "Average (on the epoch) training loss: 52.370914459228516\n",
      "Episode average V value: 26.111730575561523\n",
      "Average (on the epoch) training loss: 52.43711471557617\n",
      "Episode average V value: 28.64777946472168\n",
      "Average (on the epoch) training loss: 53.497074127197266\n",
      "Episode average V value: 35.18549156188965\n",
      "Average (on the epoch) training loss: 53.66021728515625\n",
      "Episode average V value: 21.775853902101517\n",
      "Average (on the epoch) training loss: 53.53181076049805\n",
      "Episode average V value: 19.91223414738973\n",
      "Average (on the epoch) training loss: 53.89226150512695\n",
      "Episode average V value: 23.177735328674316\n",
      "Average (on the epoch) training loss: 53.33868408203125\n",
      "Episode average V value: 24.10035487016042\n",
      "Average (on the epoch) training loss: 53.63066482543945\n",
      "Episode average V value: 28.604005813598633\n",
      "Average (on the epoch) training loss: 54.383148193359375\n",
      "Episode average V value: 15.333474000295004\n",
      "Average (on the epoch) training loss: 53.89392852783203\n",
      "Episode average V value: 18.82343848546346\n",
      "Average (on the epoch) training loss: 53.412254333496094\n",
      "Episode average V value: 19.18403857946396\n",
      "Average (on the epoch) training loss: 52.98623275756836\n",
      "Episode average V value: 27.933719257513683\n",
      "Average (on the epoch) training loss: 52.751155853271484\n",
      "Episode average V value: 15.860432841561057\n",
      "Average (on the epoch) training loss: 52.84023666381836\n",
      "Episode average V value: 19.643425623575848\n",
      "Average (on the epoch) training loss: 52.90705108642578\n",
      "Episode average V value: 31.827089150746662\n",
      "Average (on the epoch) training loss: 53.237953186035156\n",
      "Episode average V value: 30.24229621887207\n",
      "Average (on the epoch) training loss: 54.019649505615234\n",
      "Episode average V value: 23.988848209381104\n",
      "Average (on the epoch) training loss: 54.243812561035156\n",
      "Episode average V value: 14.740071614583334\n",
      "Average (on the epoch) training loss: 54.10346603393555\n",
      "Episode average V value: 30.66358296076457\n",
      "Average (on the epoch) training loss: 53.677249908447266\n",
      "Episode average V value: 29.470947265625\n",
      "Average (on the epoch) training loss: 54.08571243286133\n",
      "Episode average V value: 15.28214661280314\n",
      "Average (on the epoch) training loss: 54.092159271240234\n",
      "Episode average V value: 30.237037658691406\n",
      "Average (on the epoch) training loss: 54.036502838134766\n",
      "Episode average V value: 17.816845496495564\n",
      "Average (on the epoch) training loss: 54.56346893310547\n",
      "Episode average V value: 21.66225849498402\n",
      "Average (on the epoch) training loss: 54.87982177734375\n",
      "Episode average V value: 21.315686623255413\n",
      "Average (on the epoch) training loss: 54.571895599365234\n",
      "Episode average V value: 23.95359532038371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 54.1907958984375\n",
      "Episode average V value: 27.343271255493164\n",
      "Average (on the epoch) training loss: 53.837127685546875\n",
      "Episode average V value: 28.3065007130305\n",
      "Average (on the epoch) training loss: 53.73112869262695\n",
      "Episode average V value: 37.835792541503906\n",
      "Average (on the epoch) training loss: 53.33122634887695\n",
      "Episode average V value: 22.352969566981\n",
      "Average (on the epoch) training loss: 52.988922119140625\n",
      "Episode average V value: -401.6650704542796\n",
      "Average (on the epoch) training loss: 52.70596694946289\n",
      "Episode average V value: 29.484888076782227\n",
      "Average (on the epoch) training loss: 53.0770149230957\n",
      "Episode average V value: 25.69058585166931\n",
      "Average (on the epoch) training loss: 52.68324279785156\n",
      "Episode average V value: 19.229456802209217\n",
      "Average (on the epoch) training loss: 52.64950180053711\n",
      "Episode average V value: 29.17613983154297\n",
      "Average (on the epoch) training loss: 52.50039291381836\n",
      "Episode average V value: 26.523170731284402\n",
      "Average (on the epoch) training loss: 52.6528205871582\n",
      "Episode average V value: 27.341707865397137\n",
      "Average (on the epoch) training loss: 53.197505950927734\n",
      "Episode average V value: 23.461368719736736\n",
      "Average (on the epoch) training loss: 52.90990447998047\n",
      "Episode average V value: 22.96461296081543\n",
      "Average (on the epoch) training loss: 52.98743438720703\n",
      "Episode average V value: 16.140141487121582\n",
      "Average (on the epoch) training loss: 52.614601135253906\n",
      "Episode average V value: 19.164618889490765\n",
      "epoch 31:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 50.951873779296875\n",
      "Episode average V value: 38.655991077423096\n",
      "Average (on the epoch) training loss: 51.622867584228516\n",
      "Episode average V value: 53.71315670013428\n",
      "Average (on the epoch) training loss: 49.900962829589844\n",
      "Episode average V value: 56.13747024536133\n",
      "Average (on the epoch) training loss: 46.477298736572266\n",
      "Episode average V value: 49.75039291381836\n",
      "Average (on the epoch) training loss: 55.69729995727539\n",
      "Episode average V value: 38.499563217163086\n",
      "Average (on the epoch) training loss: 53.699058532714844\n",
      "Episode average V value: 44.40341345469157\n",
      "Average (on the epoch) training loss: 58.70927429199219\n",
      "Episode average V value: 41.96450901031494\n",
      "Average (on the epoch) training loss: 61.82674789428711\n",
      "Episode average V value: 37.54183610280355\n",
      "Average (on the epoch) training loss: 59.29203414916992\n",
      "Episode average V value: 33.08457704023881\n",
      "Average (on the epoch) training loss: 62.750301361083984\n",
      "Episode average V value: 40.75554609298706\n",
      "Average (on the epoch) training loss: 61.31205749511719\n",
      "Episode average V value: 49.27524185180664\n",
      "Average (on the epoch) training loss: 64.35611724853516\n",
      "Episode average V value: 50.35936737060547\n",
      "Average (on the epoch) training loss: 61.38845443725586\n",
      "Episode average V value: 32.891849199930824\n",
      "Average (on the epoch) training loss: 63.9306755065918\n",
      "Episode average V value: 52.75956726074219\n",
      "Average (on the epoch) training loss: 62.733985900878906\n",
      "Episode average V value: 43.30343453089396\n",
      "Average (on the epoch) training loss: 65.33878326416016\n",
      "Episode average V value: 55.23537826538086\n",
      "Average (on the epoch) training loss: 64.99945068359375\n",
      "Episode average V value: 36.76455036799113\n",
      "Average (on the epoch) training loss: 65.85709381103516\n",
      "Episode average V value: 38.28282721837362\n",
      "Average (on the epoch) training loss: 63.96229934692383\n",
      "Episode average V value: 36.610080440839134\n",
      "Average (on the epoch) training loss: 62.83379364013672\n",
      "Episode average V value: 47.823135217030845\n",
      "Average (on the epoch) training loss: 63.10655975341797\n",
      "Episode average V value: 41.541083017985024\n",
      "Average (on the epoch) training loss: 62.98310089111328\n",
      "Episode average V value: 42.73617172241211\n",
      "Average (on the epoch) training loss: 61.67424011230469\n",
      "Episode average V value: 36.55221541722616\n",
      "Average (on the epoch) training loss: 64.35453033447266\n",
      "Episode average V value: 48.593952655792236\n",
      "Average (on the epoch) training loss: 66.201904296875\n",
      "Episode average V value: 47.23507655750621\n",
      "Average (on the epoch) training loss: 64.60660552978516\n",
      "Episode average V value: 34.462235710837625\n",
      "Average (on the epoch) training loss: 64.58500671386719\n",
      "Episode average V value: 41.36547088623047\n",
      "Average (on the epoch) training loss: 63.23624801635742\n",
      "Episode average V value: 39.35174973805746\n",
      "Average (on the epoch) training loss: 63.011905670166016\n",
      "Episode average V value: 55.46503829956055\n",
      "Average (on the epoch) training loss: 63.7617301940918\n",
      "Episode average V value: 42.94749450683594\n",
      "Average (on the epoch) training loss: 62.73430252075195\n",
      "Episode average V value: 38.201579570770264\n",
      "Average (on the epoch) training loss: 62.89780807495117\n",
      "Episode average V value: 42.66861343383789\n",
      "Average (on the epoch) training loss: 64.67173767089844\n",
      "Episode average V value: 42.77600028298118\n",
      "Average (on the epoch) training loss: 64.29344940185547\n",
      "Episode average V value: 44.61694590250651\n",
      "Average (on the epoch) training loss: 64.18276977539062\n",
      "Episode average V value: 46.14581298828125\n",
      "Average (on the epoch) training loss: 63.22914505004883\n",
      "Episode average V value: 28.76181189219157\n",
      "Average (on the epoch) training loss: 63.01250457763672\n",
      "Episode average V value: 38.042239687659524\n",
      "Average (on the epoch) training loss: 62.06340026855469\n",
      "Episode average V value: 48.6879997253418\n",
      "Average (on the epoch) training loss: 62.875728607177734\n",
      "Episode average V value: 45.10538101196289\n",
      "Average (on the epoch) training loss: 62.479122161865234\n",
      "Episode average V value: 48.49697891871134\n",
      "Average (on the epoch) training loss: 62.06473922729492\n",
      "Episode average V value: 40.54702043533325\n",
      "Average (on the epoch) training loss: 64.69880676269531\n",
      "Episode average V value: -362.9856602350871\n",
      "Average (on the epoch) training loss: 65.05750274658203\n",
      "Episode average V value: 43.645572662353516\n",
      "Average (on the epoch) training loss: 64.66999053955078\n",
      "Episode average V value: 42.723259925842285\n",
      "Average (on the epoch) training loss: 64.04102325439453\n",
      "Episode average V value: 52.338165283203125\n",
      "Average (on the epoch) training loss: 63.21913146972656\n",
      "Episode average V value: 53.943450927734375\n",
      "Average (on the epoch) training loss: 64.10980987548828\n",
      "Episode average V value: 49.60744698842367\n",
      "Average (on the epoch) training loss: 63.36421585083008\n",
      "Episode average V value: 33.64992173512777\n",
      "Average (on the epoch) training loss: 62.892845153808594\n",
      "Episode average V value: 57.310903549194336\n",
      "Average (on the epoch) training loss: 62.3031005859375\n",
      "Episode average V value: 42.9359016418457\n",
      "Average (on the epoch) training loss: 62.64485549926758\n",
      "Episode average V value: 45.86609133084615\n",
      "Average (on the epoch) training loss: 62.56254196166992\n",
      "Episode average V value: 40.2904167175293\n",
      "Average (on the epoch) training loss: 63.1296501159668\n",
      "Episode average V value: 50.465118408203125\n",
      "Average (on the epoch) training loss: 63.53375244140625\n",
      "Episode average V value: 30.212737625295464\n",
      "Average (on the epoch) training loss: 64.02005004882812\n",
      "Episode average V value: 48.879329681396484\n",
      "Average (on the epoch) training loss: 63.34579086303711\n",
      "Episode average V value: 46.208980560302734\n",
      "Average (on the epoch) training loss: 63.5345458984375\n",
      "Episode average V value: 48.37080764770508\n",
      "Average (on the epoch) training loss: 63.255027770996094\n",
      "Episode average V value: 46.95973205566406\n",
      "Average (on the epoch) training loss: 63.1435432434082\n",
      "Episode average V value: 52.870635986328125\n",
      "Average (on the epoch) training loss: 62.694156646728516\n",
      "Episode average V value: 44.78031539916992\n",
      "Average (on the epoch) training loss: 63.11699676513672\n",
      "Episode average V value: 49.00669132579457\n",
      "Average (on the epoch) training loss: 62.51587677001953\n",
      "Episode average V value: 44.074649810791016\n",
      "Average (on the epoch) training loss: 61.95010757446289\n",
      "Episode average V value: 42.76482359568278\n",
      "Average (on the epoch) training loss: 61.80789566040039\n",
      "Episode average V value: 60.037412325541176\n",
      "Average (on the epoch) training loss: 62.818904876708984\n",
      "Episode average V value: 48.43664232889811\n",
      "Average (on the epoch) training loss: 63.2835693359375\n",
      "Episode average V value: 39.64497923851013\n",
      "Average (on the epoch) training loss: 63.2320671081543\n",
      "Episode average V value: 38.055588165918984\n",
      "Average (on the epoch) training loss: 63.2924690246582\n",
      "Episode average V value: 42.16104485591253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 63.11646270751953\n",
      "Episode average V value: 45.55009651184082\n",
      "Average (on the epoch) training loss: 62.64283752441406\n",
      "Episode average V value: 43.35884111577814\n",
      "Average (on the epoch) training loss: 62.39244079589844\n",
      "Episode average V value: 52.43679428100586\n",
      "Average (on the epoch) training loss: 61.99277877807617\n",
      "Episode average V value: 49.146493673324585\n",
      "Average (on the epoch) training loss: 61.54800796508789\n",
      "Episode average V value: 46.045309702555336\n",
      "Average (on the epoch) training loss: 61.89189147949219\n",
      "Episode average V value: 39.631367206573486\n",
      "Average (on the epoch) training loss: 61.90278625488281\n",
      "Episode average V value: 43.40885543823242\n",
      "Average (on the epoch) training loss: 61.87066650390625\n",
      "Episode average V value: 43.644361114501955\n",
      "Average (on the epoch) training loss: 61.642982482910156\n",
      "Episode average V value: 42.10345458984375\n",
      "Average (on the epoch) training loss: 61.21910095214844\n",
      "Episode average V value: 47.310658888383344\n",
      "Average (on the epoch) training loss: 60.84282302856445\n",
      "Episode average V value: 40.80859136581421\n",
      "Average (on the epoch) training loss: 60.606971740722656\n",
      "Episode average V value: 37.45983626625755\n",
      "Average (on the epoch) training loss: 60.967750549316406\n",
      "Episode average V value: 52.79240417480469\n",
      "Average (on the epoch) training loss: 60.63828659057617\n",
      "Episode average V value: 44.89113998413086\n",
      "Average (on the epoch) training loss: 61.0313720703125\n",
      "Episode average V value: 49.9472009340922\n",
      "Average (on the epoch) training loss: 60.7923698425293\n",
      "Episode average V value: 42.4000244140625\n",
      "Average (on the epoch) training loss: 60.40550231933594\n",
      "Episode average V value: 28.3731689453125\n",
      "Average (on the epoch) training loss: 60.47113800048828\n",
      "Episode average V value: 33.59998559951782\n",
      "Average (on the epoch) training loss: 60.63050842285156\n",
      "Episode average V value: 23.864573260148365\n",
      "Average (on the epoch) training loss: 60.84427261352539\n",
      "Episode average V value: 17.989649673302967\n",
      "Average (on the epoch) training loss: 60.62278366088867\n",
      "Episode average V value: 33.5275162783536\n",
      "Average (on the epoch) training loss: 60.29936218261719\n",
      "Episode average V value: 30.855798721313477\n",
      "Average (on the epoch) training loss: 59.98332977294922\n",
      "Episode average V value: 29.663881460825603\n",
      "Average (on the epoch) training loss: 59.58676528930664\n",
      "Episode average V value: 27.786749521891277\n",
      "Average (on the epoch) training loss: 59.218345642089844\n",
      "Episode average V value: 35.63707137107849\n",
      "Average (on the epoch) training loss: 59.324676513671875\n",
      "Episode average V value: 33.18672362963358\n",
      "Average (on the epoch) training loss: 59.00862121582031\n",
      "Episode average V value: 24.85120153427124\n",
      "Average (on the epoch) training loss: 58.97337341308594\n",
      "Episode average V value: 36.49647808074951\n",
      "Average (on the epoch) training loss: 58.9849853515625\n",
      "Episode average V value: 29.490318298339844\n",
      "Average (on the epoch) training loss: 58.76392364501953\n",
      "Episode average V value: 37.390602111816406\n",
      "Average (on the epoch) training loss: 58.946693420410156\n",
      "Episode average V value: 40.866493225097656\n",
      "Average (on the epoch) training loss: 58.72650909423828\n",
      "Episode average V value: 30.48517417907715\n",
      "epoch 32:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 34.750850677490234\n",
      "Episode average V value: 33.55998992919922\n",
      "Average (on the epoch) training loss: 32.907501220703125\n",
      "Episode average V value: 31.916893005371094\n",
      "Average (on the epoch) training loss: 32.20794677734375\n",
      "Episode average V value: 42.29775619506836\n",
      "Average (on the epoch) training loss: 30.578893661499023\n",
      "Episode average V value: 40.270865281422935\n",
      "Average (on the epoch) training loss: 28.797651290893555\n",
      "Episode average V value: 27.970437049865723\n",
      "Average (on the epoch) training loss: 39.22969055175781\n",
      "Episode average V value: 52.84776306152344\n",
      "Average (on the epoch) training loss: 36.9709358215332\n",
      "Episode average V value: 24.596981742165305\n",
      "Average (on the epoch) training loss: 35.79996109008789\n",
      "Episode average V value: 29.793675740559895\n",
      "Average (on the epoch) training loss: 44.605892181396484\n",
      "Episode average V value: 30.01397297779719\n",
      "Average (on the epoch) training loss: 48.89514923095703\n",
      "Episode average V value: 30.151145935058594\n",
      "Average (on the epoch) training loss: 48.584251403808594\n",
      "Episode average V value: 27.441757758458454\n",
      "Average (on the epoch) training loss: 50.293426513671875\n",
      "Episode average V value: 40.1506462097168\n",
      "Average (on the epoch) training loss: 48.56067657470703\n",
      "Episode average V value: 24.62568187713623\n",
      "Average (on the epoch) training loss: 47.44293975830078\n",
      "Episode average V value: 29.31020164489746\n",
      "Average (on the epoch) training loss: 45.67634582519531\n",
      "Episode average V value: 29.616103410720825\n",
      "Average (on the epoch) training loss: 44.4656867980957\n",
      "Episode average V value: 41.484674973921344\n",
      "Average (on the epoch) training loss: 43.0910530090332\n",
      "Episode average V value: 27.468950271606445\n",
      "Average (on the epoch) training loss: 42.335079193115234\n",
      "Episode average V value: 24.22138277689616\n",
      "Average (on the epoch) training loss: 41.15461730957031\n",
      "Episode average V value: 33.36960220336914\n",
      "Average (on the epoch) training loss: 40.577415466308594\n",
      "Episode average V value: 33.11330032348633\n",
      "Average (on the epoch) training loss: 39.9876594543457\n",
      "Episode average V value: -397.24769322077435\n",
      "Average (on the epoch) training loss: 39.10104751586914\n",
      "Episode average V value: 29.923678744922984\n",
      "Average (on the epoch) training loss: 40.78974914550781\n",
      "Episode average V value: 32.10576629638672\n",
      "Average (on the epoch) training loss: 40.911712646484375\n",
      "Episode average V value: 21.7036288579305\n",
      "Average (on the epoch) training loss: 39.928958892822266\n",
      "Episode average V value: 31.406652450561523\n",
      "Average (on the epoch) training loss: 39.29799270629883\n",
      "Episode average V value: 35.999114990234375\n",
      "Average (on the epoch) training loss: 38.72888946533203\n",
      "Episode average V value: 29.090753121809527\n",
      "Average (on the epoch) training loss: 38.23488235473633\n",
      "Episode average V value: 39.756500244140625\n",
      "Average (on the epoch) training loss: 38.021663665771484\n",
      "Episode average V value: 35.3546978632609\n",
      "Average (on the epoch) training loss: 37.499019622802734\n",
      "Episode average V value: 34.54964510599772\n",
      "Average (on the epoch) training loss: 37.35367202758789\n",
      "Episode average V value: 39.05449914932251\n",
      "Average (on the epoch) training loss: 37.045143127441406\n",
      "Episode average V value: 22.990660270055134\n",
      "Average (on the epoch) training loss: 38.343528747558594\n",
      "Episode average V value: 30.983659664789837\n",
      "Average (on the epoch) training loss: 37.7869758605957\n",
      "Episode average V value: 22.37746500968933\n",
      "Average (on the epoch) training loss: 37.457496643066406\n",
      "Episode average V value: 28.229814529418945\n",
      "Average (on the epoch) training loss: 37.266136169433594\n",
      "Episode average V value: 36.04785998662313\n",
      "Average (on the epoch) training loss: 38.38056182861328\n",
      "Episode average V value: 33.32162857055664\n",
      "Average (on the epoch) training loss: 38.95869445800781\n",
      "Episode average V value: 26.90626843770345\n",
      "Average (on the epoch) training loss: 39.044612884521484\n",
      "Episode average V value: 27.242448806762695\n",
      "Average (on the epoch) training loss: 38.53535079956055\n",
      "Episode average V value: 23.828126907348633\n",
      "Average (on the epoch) training loss: 39.448543548583984\n",
      "Episode average V value: 38.23821632067362\n",
      "Average (on the epoch) training loss: 38.92823791503906\n",
      "Episode average V value: 11.609663645426432\n",
      "Average (on the epoch) training loss: 38.44109344482422\n",
      "Episode average V value: 30.464820861816406\n",
      "Average (on the epoch) training loss: 39.526153564453125\n",
      "Episode average V value: 33.616402884324394\n",
      "Average (on the epoch) training loss: 39.019229888916016\n",
      "Episode average V value: 32.0737419128418\n",
      "Average (on the epoch) training loss: 39.82267379760742\n",
      "Episode average V value: 35.054500579833984\n",
      "Average (on the epoch) training loss: 39.62265396118164\n",
      "Episode average V value: 25.118555068969727\n",
      "Average (on the epoch) training loss: 39.94993209838867\n",
      "Episode average V value: 31.068328857421875\n",
      "Average (on the epoch) training loss: 40.406314849853516\n",
      "Episode average V value: 29.514074325561523\n",
      "Average (on the epoch) training loss: 39.99104690551758\n",
      "Episode average V value: 27.007373650868733\n",
      "Average (on the epoch) training loss: 40.47382354736328\n",
      "Episode average V value: 28.422945578893025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 40.78338623046875\n",
      "Episode average V value: 29.726685603459675\n",
      "Average (on the epoch) training loss: 41.37445831298828\n",
      "Episode average V value: 23.021490693092346\n",
      "Average (on the epoch) training loss: 41.773780822753906\n",
      "Episode average V value: 30.732916196187336\n",
      "Average (on the epoch) training loss: 41.554988861083984\n",
      "Episode average V value: 35.74079895019531\n",
      "Average (on the epoch) training loss: 42.06673812866211\n",
      "Episode average V value: 28.159842491149902\n",
      "Average (on the epoch) training loss: 41.76339340209961\n",
      "Episode average V value: 31.855865478515625\n",
      "Average (on the epoch) training loss: 41.94931411743164\n",
      "Episode average V value: 31.505186875661213\n",
      "Average (on the epoch) training loss: 42.460227966308594\n",
      "Episode average V value: 24.23155379295349\n",
      "Average (on the epoch) training loss: 42.55390167236328\n",
      "Episode average V value: 33.163126389185585\n",
      "Average (on the epoch) training loss: 42.63713455200195\n",
      "Episode average V value: 28.84549903869629\n",
      "Average (on the epoch) training loss: 42.66423034667969\n",
      "Episode average V value: 32.747482458750405\n",
      "Average (on the epoch) training loss: 42.602500915527344\n",
      "Episode average V value: 35.4113655090332\n",
      "Average (on the epoch) training loss: 42.63227462768555\n",
      "Episode average V value: 31.572954351251777\n",
      "Average (on the epoch) training loss: 43.21049118041992\n",
      "Episode average V value: 32.79566891988119\n",
      "Average (on the epoch) training loss: 43.13832473754883\n",
      "Episode average V value: 28.336814880371094\n",
      "Average (on the epoch) training loss: 42.91450881958008\n",
      "Episode average V value: 41.37771224975586\n",
      "Average (on the epoch) training loss: 44.03947448730469\n",
      "Episode average V value: 45.16575241088867\n",
      "Average (on the epoch) training loss: 43.815486907958984\n",
      "Episode average V value: 44.00239642461141\n",
      "Average (on the epoch) training loss: 44.29014587402344\n",
      "Episode average V value: 49.96977233886719\n",
      "Average (on the epoch) training loss: 44.48631286621094\n",
      "Episode average V value: 32.124157667160034\n",
      "Average (on the epoch) training loss: 44.91872024536133\n",
      "Episode average V value: 41.205805937449135\n",
      "Average (on the epoch) training loss: 45.10576248168945\n",
      "Episode average V value: 44.29255032539368\n",
      "Average (on the epoch) training loss: 44.92974090576172\n",
      "Episode average V value: 47.25205612182617\n",
      "Average (on the epoch) training loss: 44.69257736206055\n",
      "Episode average V value: 45.249977111816406\n",
      "Average (on the epoch) training loss: 44.955421447753906\n",
      "Episode average V value: 43.422748724619545\n",
      "Average (on the epoch) training loss: 44.90324783325195\n",
      "Episode average V value: 38.59157506624857\n",
      "Average (on the epoch) training loss: 44.70354080200195\n",
      "Episode average V value: 48.3585090637207\n",
      "Average (on the epoch) training loss: 45.051761627197266\n",
      "Episode average V value: 49.6750602722168\n",
      "Average (on the epoch) training loss: 45.27850341796875\n",
      "Episode average V value: 56.92892837524414\n",
      "Average (on the epoch) training loss: 45.705814361572266\n",
      "Episode average V value: 50.50923156738281\n",
      "Average (on the epoch) training loss: 45.78437042236328\n",
      "Episode average V value: 50.88071060180664\n",
      "Average (on the epoch) training loss: 45.71192932128906\n",
      "Episode average V value: 45.844000498453774\n",
      "Average (on the epoch) training loss: 45.49274826049805\n",
      "Episode average V value: 50.32389831542969\n",
      "Average (on the epoch) training loss: 45.73143768310547\n",
      "Episode average V value: 44.1081166267395\n",
      "Average (on the epoch) training loss: 45.839115142822266\n",
      "Episode average V value: 50.79261779785156\n",
      "Average (on the epoch) training loss: 45.989776611328125\n",
      "Episode average V value: 39.314350843429565\n",
      "Average (on the epoch) training loss: 46.30609130859375\n",
      "Episode average V value: 30.105982173572887\n",
      "Average (on the epoch) training loss: 46.27539825439453\n",
      "Episode average V value: 37.505820194880165\n",
      "Average (on the epoch) training loss: 46.02640914916992\n",
      "Episode average V value: 43.02573013305664\n",
      "Average (on the epoch) training loss: 45.819549560546875\n",
      "Episode average V value: 47.44672775268555\n",
      "Average (on the epoch) training loss: 45.65523910522461\n",
      "Episode average V value: 29.20735151117498\n",
      "Average (on the epoch) training loss: 45.52663040161133\n",
      "Episode average V value: 31.217699845631916\n",
      "Average (on the epoch) training loss: 45.39958953857422\n",
      "Episode average V value: 29.275945229963824\n",
      "Average (on the epoch) training loss: 45.22138977050781\n",
      "Episode average V value: 45.46984259287516\n",
      "Average (on the epoch) training loss: 45.58888244628906\n",
      "Episode average V value: 35.14448388417562\n",
      "Average (on the epoch) training loss: 45.48438262939453\n",
      "Episode average V value: 42.60799789428711\n",
      "Average (on the epoch) training loss: 45.31644058227539\n",
      "Episode average V value: 42.727919260660805\n",
      "Average (on the epoch) training loss: 45.11896896362305\n",
      "Episode average V value: 40.44827318191528\n",
      "Average (on the epoch) training loss: 45.107845306396484\n",
      "Episode average V value: 51.28934097290039\n",
      "epoch 33:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 29.47873878479004\n",
      "Episode average V value: 39.621329047463156\n",
      "Average (on the epoch) training loss: 34.88620376586914\n",
      "Episode average V value: 46.47302929560343\n",
      "Average (on the epoch) training loss: 48.16365051269531\n",
      "Episode average V value: 56.70882797241211\n",
      "Average (on the epoch) training loss: 42.24824142456055\n",
      "Episode average V value: 49.12335205078125\n",
      "Average (on the epoch) training loss: 39.74854278564453\n",
      "Episode average V value: 44.309814453125\n",
      "Average (on the epoch) training loss: 44.79637145996094\n",
      "Episode average V value: 54.14979934692383\n",
      "Average (on the epoch) training loss: 42.046104431152344\n",
      "Episode average V value: 44.16486913507635\n",
      "Average (on the epoch) training loss: 42.05652618408203\n",
      "Episode average V value: 39.57255554199219\n",
      "Average (on the epoch) training loss: 46.67766571044922\n",
      "Episode average V value: 39.327117602030434\n",
      "Average (on the epoch) training loss: 50.00732421875\n",
      "Episode average V value: 52.61301040649414\n",
      "Average (on the epoch) training loss: 47.75370788574219\n",
      "Episode average V value: 39.29552234302867\n",
      "Average (on the epoch) training loss: 46.43175506591797\n",
      "Episode average V value: 47.345672607421875\n",
      "Average (on the epoch) training loss: 44.652408599853516\n",
      "Episode average V value: 31.810300254821776\n",
      "Average (on the epoch) training loss: 46.97879409790039\n",
      "Episode average V value: 49.9612343528054\n",
      "Average (on the epoch) training loss: 45.946044921875\n",
      "Episode average V value: 44.93246841430664\n",
      "Average (on the epoch) training loss: 44.56235122680664\n",
      "Episode average V value: 43.701940059661865\n",
      "Average (on the epoch) training loss: 46.345088958740234\n",
      "Episode average V value: 39.069199879964195\n",
      "Average (on the epoch) training loss: 45.95564651489258\n",
      "Episode average V value: 41.24995040893555\n",
      "Average (on the epoch) training loss: 44.90426254272461\n",
      "Episode average V value: 48.72475369771322\n",
      "Average (on the epoch) training loss: 44.01609802246094\n",
      "Episode average V value: 38.09269952774048\n",
      "Average (on the epoch) training loss: 45.91572952270508\n",
      "Episode average V value: 52.39748764038086\n",
      "Average (on the epoch) training loss: 44.95402908325195\n",
      "Episode average V value: 51.09881591796875\n",
      "Average (on the epoch) training loss: 44.294166564941406\n",
      "Episode average V value: 54.04195785522461\n",
      "Average (on the epoch) training loss: 45.72933578491211\n",
      "Episode average V value: 41.66824984550476\n",
      "Average (on the epoch) training loss: 46.99456787109375\n",
      "Episode average V value: 49.068965911865234\n",
      "Average (on the epoch) training loss: 46.372962951660156\n",
      "Episode average V value: 46.12681579589844\n",
      "Average (on the epoch) training loss: 46.10459899902344\n",
      "Episode average V value: 43.64397923151652\n",
      "Average (on the epoch) training loss: 45.415897369384766\n",
      "Episode average V value: 41.203051726023354\n",
      "Average (on the epoch) training loss: 44.89164352416992\n",
      "Episode average V value: 39.43137966502797\n",
      "Average (on the epoch) training loss: 45.02310562133789\n",
      "Episode average V value: 47.43845729033152\n",
      "Average (on the epoch) training loss: 44.62907409667969\n",
      "Episode average V value: 42.516090393066406\n",
      "Average (on the epoch) training loss: 45.65842056274414\n",
      "Episode average V value: 52.07212829589844\n",
      "Average (on the epoch) training loss: 45.64731216430664\n",
      "Episode average V value: 45.3992706934611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 45.14918899536133\n",
      "Episode average V value: 33.77649766748602\n",
      "Average (on the epoch) training loss: 44.59389114379883\n",
      "Episode average V value: 49.78413009643555\n",
      "Average (on the epoch) training loss: 46.536800384521484\n",
      "Episode average V value: 35.21331230799357\n",
      "Average (on the epoch) training loss: 47.14873123168945\n",
      "Episode average V value: 35.18899345397949\n",
      "Average (on the epoch) training loss: 47.076507568359375\n",
      "Episode average V value: 42.68622016906738\n",
      "Average (on the epoch) training loss: 47.41560745239258\n",
      "Episode average V value: 48.7790412902832\n",
      "Average (on the epoch) training loss: 48.303897857666016\n",
      "Episode average V value: 44.897032737731934\n",
      "Average (on the epoch) training loss: 47.85702896118164\n",
      "Episode average V value: 46.2844352722168\n",
      "Average (on the epoch) training loss: 47.888694763183594\n",
      "Episode average V value: 60.40451431274414\n",
      "Average (on the epoch) training loss: 47.34248733520508\n",
      "Episode average V value: 42.16225814819336\n",
      "Average (on the epoch) training loss: 47.28789138793945\n",
      "Episode average V value: 40.05466079711914\n",
      "Average (on the epoch) training loss: 46.82612991333008\n",
      "Episode average V value: 45.81253641301935\n",
      "Average (on the epoch) training loss: 46.3199462890625\n",
      "Episode average V value: 33.16826152801514\n",
      "Average (on the epoch) training loss: 46.143524169921875\n",
      "Episode average V value: 48.47331174214681\n",
      "Average (on the epoch) training loss: 46.88616943359375\n",
      "Episode average V value: 49.91999117533366\n",
      "Average (on the epoch) training loss: 47.02314376831055\n",
      "Episode average V value: 49.00200271606445\n",
      "Average (on the epoch) training loss: 46.70985794067383\n",
      "Episode average V value: 38.97626027193937\n",
      "Average (on the epoch) training loss: 46.57271957397461\n",
      "Episode average V value: 42.903656005859375\n",
      "Average (on the epoch) training loss: 47.94408416748047\n",
      "Episode average V value: 20.088247458140057\n",
      "Average (on the epoch) training loss: 48.11664581298828\n",
      "Episode average V value: 24.61784953872363\n",
      "Average (on the epoch) training loss: 48.200050354003906\n",
      "Episode average V value: -364.71899394194287\n",
      "Average (on the epoch) training loss: 47.95697784423828\n",
      "Episode average V value: 29.92142677307129\n",
      "Average (on the epoch) training loss: 48.445987701416016\n",
      "Episode average V value: 28.07701873779297\n",
      "Average (on the epoch) training loss: 48.407310485839844\n",
      "Episode average V value: 23.866227865219116\n",
      "Average (on the epoch) training loss: 49.061893463134766\n",
      "Episode average V value: 24.85420799255371\n",
      "Average (on the epoch) training loss: 49.20252990722656\n",
      "Episode average V value: 25.917556762695312\n",
      "Average (on the epoch) training loss: 49.06912612915039\n",
      "Episode average V value: 24.58608055114746\n",
      "Average (on the epoch) training loss: 49.131351470947266\n",
      "Episode average V value: 17.99089463551839\n",
      "Average (on the epoch) training loss: 49.14620590209961\n",
      "Episode average V value: 17.95325477917989\n",
      "Average (on the epoch) training loss: 48.94866943359375\n",
      "Episode average V value: 24.4435977935791\n",
      "Average (on the epoch) training loss: 48.576229095458984\n",
      "Episode average V value: 27.16676902770996\n",
      "Average (on the epoch) training loss: 48.44398880004883\n",
      "Episode average V value: 21.410714666048687\n",
      "Average (on the epoch) training loss: 48.10087203979492\n",
      "Episode average V value: 18.643474578857422\n",
      "Average (on the epoch) training loss: 48.388145446777344\n",
      "Episode average V value: 24.29058774312337\n",
      "Average (on the epoch) training loss: 48.85621643066406\n",
      "Episode average V value: 28.370055834452312\n",
      "Average (on the epoch) training loss: 48.435970306396484\n",
      "Episode average V value: 20.03827492396037\n",
      "Average (on the epoch) training loss: 48.92259216308594\n",
      "Episode average V value: 33.07842095692953\n",
      "Average (on the epoch) training loss: 49.23749542236328\n",
      "Episode average V value: 27.138450980186462\n",
      "Average (on the epoch) training loss: 49.107845306396484\n",
      "Episode average V value: 19.865022738774616\n",
      "Average (on the epoch) training loss: 49.83604431152344\n",
      "Episode average V value: 22.885305325190227\n",
      "Average (on the epoch) training loss: 49.63547134399414\n",
      "Episode average V value: 18.7116641998291\n",
      "Average (on the epoch) training loss: 50.07044982910156\n",
      "Episode average V value: 16.02744819720586\n",
      "Average (on the epoch) training loss: 49.68701171875\n",
      "Episode average V value: 22.37516736984253\n",
      "Average (on the epoch) training loss: 49.28770446777344\n",
      "Episode average V value: 24.77360455195109\n",
      "Average (on the epoch) training loss: 49.24549102783203\n",
      "Episode average V value: 33.80266189575195\n",
      "Average (on the epoch) training loss: 49.54597091674805\n",
      "Episode average V value: 16.41442108154297\n",
      "Average (on the epoch) training loss: 49.31749725341797\n",
      "Episode average V value: 21.1440279006958\n",
      "Average (on the epoch) training loss: 49.05793762207031\n",
      "Episode average V value: 30.44331169128418\n",
      "Average (on the epoch) training loss: 48.75614547729492\n",
      "Episode average V value: 20.49358908335368\n",
      "Average (on the epoch) training loss: 48.485755920410156\n",
      "Episode average V value: 37.56049728393555\n",
      "Average (on the epoch) training loss: 48.279930114746094\n",
      "Episode average V value: 26.73219871520996\n",
      "Average (on the epoch) training loss: 49.18444061279297\n",
      "Episode average V value: 26.693571090698242\n",
      "Average (on the epoch) training loss: 48.79866027832031\n",
      "Episode average V value: 19.996948328885164\n",
      "Average (on the epoch) training loss: 48.70256805419922\n",
      "Episode average V value: 21.583552273837004\n",
      "Average (on the epoch) training loss: 48.40690231323242\n",
      "Episode average V value: 31.095399220784504\n",
      "Average (on the epoch) training loss: 48.76262664794922\n",
      "Episode average V value: 34.33950424194336\n",
      "Average (on the epoch) training loss: 48.872859954833984\n",
      "Episode average V value: 15.743366241455078\n",
      "Average (on the epoch) training loss: 48.705101013183594\n",
      "Episode average V value: 20.28001594543457\n",
      "Average (on the epoch) training loss: 49.38441467285156\n",
      "Episode average V value: 26.770143508911133\n",
      "Average (on the epoch) training loss: 49.96347427368164\n",
      "Episode average V value: -354.3635833263397\n",
      "Average (on the epoch) training loss: 49.69614791870117\n",
      "Episode average V value: 18.163343747456867\n",
      "Average (on the epoch) training loss: 49.39466094970703\n",
      "Episode average V value: 28.23337423801422\n",
      "Average (on the epoch) training loss: 49.27591323852539\n",
      "Episode average V value: 24.49240191777547\n",
      "Average (on the epoch) training loss: 49.026798248291016\n",
      "Episode average V value: 29.1497000058492\n",
      "Average (on the epoch) training loss: 48.774391174316406\n",
      "Episode average V value: 24.40204212882302\n",
      "Average (on the epoch) training loss: 49.01835250854492\n",
      "Episode average V value: 23.229752620061237\n",
      "Average (on the epoch) training loss: 48.87640380859375\n",
      "Episode average V value: 20.625170071919758\n",
      "epoch 34:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 33.93063735961914\n",
      "Episode average V value: 31.26894187927246\n",
      "Average (on the epoch) training loss: 42.44583511352539\n",
      "Episode average V value: 14.893817702929178\n",
      "Average (on the epoch) training loss: 49.11002731323242\n",
      "Episode average V value: 18.35866928100586\n",
      "Average (on the epoch) training loss: 43.55109786987305\n",
      "Episode average V value: 25.402432123819988\n",
      "Average (on the epoch) training loss: 45.47426986694336\n",
      "Episode average V value: 22.948542952537537\n",
      "Average (on the epoch) training loss: 43.655418395996094\n",
      "Episode average V value: 15.944044689337412\n",
      "Average (on the epoch) training loss: 44.05797576904297\n",
      "Episode average V value: 27.728572130203247\n",
      "Average (on the epoch) training loss: 48.98048782348633\n",
      "Episode average V value: 34.2380485534668\n",
      "Average (on the epoch) training loss: 48.826717376708984\n",
      "Episode average V value: 18.94016619523366\n",
      "Average (on the epoch) training loss: 55.19355392456055\n",
      "Episode average V value: 32.01438522338867\n",
      "Average (on the epoch) training loss: 53.94750213623047\n",
      "Episode average V value: 31.39164408047994\n",
      "Average (on the epoch) training loss: 52.81730270385742\n",
      "Episode average V value: 26.663450717926025\n",
      "Average (on the epoch) training loss: 50.493133544921875\n",
      "Episode average V value: 28.040779451529186\n",
      "Average (on the epoch) training loss: 48.757568359375\n",
      "Episode average V value: 39.55184555053711\n",
      "Average (on the epoch) training loss: 47.67902374267578\n",
      "Episode average V value: 22.29674748579661\n",
      "Average (on the epoch) training loss: 49.53279495239258\n",
      "Episode average V value: 32.933804750442505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 48.59899139404297\n",
      "Episode average V value: 16.21338725090027\n",
      "Average (on the epoch) training loss: 49.99076843261719\n",
      "Episode average V value: 24.814834594726562\n",
      "Average (on the epoch) training loss: 51.17871856689453\n",
      "Episode average V value: 19.702256361643474\n",
      "Average (on the epoch) training loss: 50.440372467041016\n",
      "Episode average V value: 16.4738982518514\n",
      "Average (on the epoch) training loss: 49.398590087890625\n",
      "Episode average V value: 28.042593955993652\n",
      "Average (on the epoch) training loss: 50.15193557739258\n",
      "Episode average V value: 27.053451538085938\n",
      "Average (on the epoch) training loss: 51.941184997558594\n",
      "Episode average V value: 25.7850341796875\n",
      "Average (on the epoch) training loss: 52.65597152709961\n",
      "Episode average V value: 22.268836975097656\n",
      "Average (on the epoch) training loss: 52.05412673950195\n",
      "Episode average V value: 26.195013999938965\n",
      "Average (on the epoch) training loss: 50.81664276123047\n",
      "Episode average V value: 22.9883527358373\n",
      "Average (on the epoch) training loss: 51.98191452026367\n",
      "Episode average V value: 41.10484313964844\n",
      "Average (on the epoch) training loss: 51.7485237121582\n",
      "Episode average V value: 19.608715613683064\n",
      "Average (on the epoch) training loss: 52.846981048583984\n",
      "Episode average V value: 27.49993324279785\n",
      "Average (on the epoch) training loss: 52.035160064697266\n",
      "Episode average V value: 20.413559277852375\n",
      "Average (on the epoch) training loss: 51.12321853637695\n",
      "Episode average V value: 23.84294080734253\n",
      "Average (on the epoch) training loss: 51.52461624145508\n",
      "Episode average V value: 25.08381152153015\n",
      "Average (on the epoch) training loss: 51.16339111328125\n",
      "Episode average V value: 28.900338866493918\n",
      "Average (on the epoch) training loss: 51.82010269165039\n",
      "Episode average V value: 30.323192162947223\n",
      "Average (on the epoch) training loss: 53.12470245361328\n",
      "Episode average V value: 14.585025449593862\n",
      "Average (on the epoch) training loss: 52.70161437988281\n",
      "Episode average V value: 7.410908894105391\n",
      "Average (on the epoch) training loss: 51.64176940917969\n",
      "Episode average V value: 15.11631735165914\n",
      "Average (on the epoch) training loss: 51.026485443115234\n",
      "Episode average V value: 24.668819427490234\n",
      "Average (on the epoch) training loss: 50.41744613647461\n",
      "Episode average V value: 26.95831973354022\n",
      "Average (on the epoch) training loss: 50.66862106323242\n",
      "Episode average V value: 16.05958487590154\n",
      "Average (on the epoch) training loss: 49.858882904052734\n",
      "Episode average V value: 13.099311828613281\n",
      "Average (on the epoch) training loss: 49.80237579345703\n",
      "Episode average V value: 17.488258361816406\n",
      "Average (on the epoch) training loss: 49.94426727294922\n",
      "Episode average V value: 20.97856903076172\n",
      "Average (on the epoch) training loss: 50.85429382324219\n",
      "Episode average V value: 18.595718502998352\n",
      "Average (on the epoch) training loss: 50.16340255737305\n",
      "Episode average V value: 13.644157409667969\n",
      "Average (on the epoch) training loss: 50.0230712890625\n",
      "Episode average V value: 22.289317651228473\n",
      "Average (on the epoch) training loss: 49.586097717285156\n",
      "Episode average V value: 6.762326618035634\n",
      "Average (on the epoch) training loss: 48.985347747802734\n",
      "Episode average V value: 26.59873676300049\n",
      "Average (on the epoch) training loss: 49.25997543334961\n",
      "Episode average V value: 14.158370018005371\n",
      "Average (on the epoch) training loss: 49.703556060791016\n",
      "Episode average V value: 19.840156078338623\n",
      "Average (on the epoch) training loss: 49.7568359375\n",
      "Episode average V value: 11.932235479354858\n",
      "Average (on the epoch) training loss: 49.27849197387695\n",
      "Episode average V value: 14.00932522614797\n",
      "Average (on the epoch) training loss: 49.06254196166992\n",
      "Episode average V value: 12.127499341964722\n",
      "Average (on the epoch) training loss: 49.46356201171875\n",
      "Episode average V value: 11.765829086303711\n",
      "Average (on the epoch) training loss: 49.36017990112305\n",
      "Episode average V value: 23.784311294555664\n",
      "Average (on the epoch) training loss: 49.02790069580078\n",
      "Episode average V value: 22.63416646917661\n",
      "Average (on the epoch) training loss: 48.468482971191406\n",
      "Episode average V value: 17.953733503818512\n",
      "Average (on the epoch) training loss: 48.023719787597656\n",
      "Episode average V value: 7.6310340364774065\n",
      "Average (on the epoch) training loss: 47.663814544677734\n",
      "Episode average V value: 15.469956398010254\n",
      "Average (on the epoch) training loss: 48.082298278808594\n",
      "Episode average V value: 16.977928486737337\n",
      "Average (on the epoch) training loss: 47.59636306762695\n",
      "Episode average V value: 16.811325073242188\n",
      "Average (on the epoch) training loss: 47.11601257324219\n",
      "Episode average V value: 20.55844497680664\n",
      "Average (on the epoch) training loss: 46.6978759765625\n",
      "Episode average V value: 20.13283634185791\n",
      "Average (on the epoch) training loss: 46.391387939453125\n",
      "Episode average V value: 11.911105155944824\n",
      "Average (on the epoch) training loss: 46.00847244262695\n",
      "Episode average V value: 23.50887680053711\n",
      "Average (on the epoch) training loss: 45.6612548828125\n",
      "Episode average V value: 25.409940719604492\n",
      "Average (on the epoch) training loss: 45.3297004699707\n",
      "Episode average V value: 16.435729046662647\n",
      "Average (on the epoch) training loss: 44.96648025512695\n",
      "Episode average V value: 16.760327100753784\n",
      "Average (on the epoch) training loss: 45.57190704345703\n",
      "Episode average V value: 10.428571701049805\n",
      "Average (on the epoch) training loss: 45.702674865722656\n",
      "Episode average V value: 14.65457820892334\n",
      "Average (on the epoch) training loss: 45.88474655151367\n",
      "Episode average V value: 6.336401462554932\n",
      "Average (on the epoch) training loss: 46.18366622924805\n",
      "Episode average V value: 17.392041842142742\n",
      "Average (on the epoch) training loss: 45.72725296020508\n",
      "Episode average V value: 11.515778541564941\n",
      "Average (on the epoch) training loss: 46.130550384521484\n",
      "Episode average V value: 13.538238922754923\n",
      "Average (on the epoch) training loss: 45.75286865234375\n",
      "Episode average V value: 17.978891372680664\n",
      "Average (on the epoch) training loss: 46.282840728759766\n",
      "Episode average V value: 22.309263229370117\n",
      "Average (on the epoch) training loss: 46.099021911621094\n",
      "Episode average V value: -351.62009676297504\n",
      "Average (on the epoch) training loss: 45.74585723876953\n",
      "Episode average V value: 13.247779260079065\n",
      "Average (on the epoch) training loss: 45.8061637878418\n",
      "Episode average V value: 24.068458557128906\n",
      "Average (on the epoch) training loss: 45.96364212036133\n",
      "Episode average V value: 19.760742257038753\n",
      "Average (on the epoch) training loss: 45.893428802490234\n",
      "Episode average V value: 13.50207856297493\n",
      "Average (on the epoch) training loss: 45.78375244140625\n",
      "Episode average V value: 18.847769021987915\n",
      "Average (on the epoch) training loss: 45.67707443237305\n",
      "Episode average V value: 22.05580711364746\n",
      "Average (on the epoch) training loss: 45.362491607666016\n",
      "Episode average V value: 25.958582043647766\n",
      "Average (on the epoch) training loss: 45.72474670410156\n",
      "Episode average V value: 23.507152130206425\n",
      "Average (on the epoch) training loss: 45.42532730102539\n",
      "Episode average V value: 13.154250144958496\n",
      "Average (on the epoch) training loss: 45.69388961791992\n",
      "Episode average V value: 16.329957962036133\n",
      "Average (on the epoch) training loss: 45.46103286743164\n",
      "Episode average V value: 13.22362995147705\n",
      "Average (on the epoch) training loss: 45.30402755737305\n",
      "Episode average V value: 20.077730178833008\n",
      "Average (on the epoch) training loss: 45.982723236083984\n",
      "Episode average V value: 31.00574493408203\n",
      "Average (on the epoch) training loss: 45.794490814208984\n",
      "Episode average V value: 12.230429649353027\n",
      "Average (on the epoch) training loss: 45.658180236816406\n",
      "Episode average V value: 14.419566531976065\n",
      "Average (on the epoch) training loss: 45.40278625488281\n",
      "Episode average V value: 25.5778751373291\n",
      "Average (on the epoch) training loss: 45.26343536376953\n",
      "Episode average V value: 23.139917373657227\n",
      "Average (on the epoch) training loss: 45.58445358276367\n",
      "Episode average V value: 16.411550521850586\n",
      "Average (on the epoch) training loss: 46.22129821777344\n",
      "Episode average V value: 17.79193687438965\n",
      "Average (on the epoch) training loss: 45.9759635925293\n",
      "Episode average V value: 18.555517196655273\n",
      "Average (on the epoch) training loss: 45.68069076538086\n",
      "Episode average V value: 7.036829749743144\n",
      "Average (on the epoch) training loss: 45.52147674560547\n",
      "Episode average V value: 21.52800750732422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 45.18681716918945\n",
      "Episode average V value: 19.13071060180664\n",
      "epoch 35:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n",
      "Average (on the epoch) training loss: 68.5705337524414\n",
      "Episode average V value: 20.56004524230957\n",
      "Average (on the epoch) training loss: 40.88493728637695\n",
      "Episode average V value: 14.094719886779785\n",
      "Average (on the epoch) training loss: 65.23153686523438\n",
      "Episode average V value: 29.82871437072754\n",
      "Average (on the epoch) training loss: 64.36961364746094\n",
      "Episode average V value: 15.416409427469427\n",
      "Average (on the epoch) training loss: 58.559452056884766\n",
      "Episode average V value: 14.248237868150076\n",
      "Average (on the epoch) training loss: 54.44569778442383\n",
      "Episode average V value: 22.732833862304688\n",
      "Average (on the epoch) training loss: 49.188446044921875\n",
      "Episode average V value: 28.039052963256836\n",
      "Average (on the epoch) training loss: 51.55450439453125\n",
      "Episode average V value: 22.353639602661133\n",
      "Average (on the epoch) training loss: 48.97237777709961\n",
      "Episode average V value: 12.500346819559732\n",
      "Average (on the epoch) training loss: 47.09480667114258\n",
      "Episode average V value: 18.66484820842743\n",
      "Average (on the epoch) training loss: 44.66926956176758\n",
      "Episode average V value: 20.736263275146484\n",
      "Average (on the epoch) training loss: 42.638404846191406\n",
      "Episode average V value: 20.764228343963623\n",
      "Average (on the epoch) training loss: 47.60506820678711\n",
      "Episode average V value: 15.201722939809164\n",
      "Average (on the epoch) training loss: 45.978240966796875\n",
      "Episode average V value: 11.393563270568848\n",
      "Average (on the epoch) training loss: 45.98171615600586\n",
      "Episode average V value: 19.562822818756104\n",
      "Average (on the epoch) training loss: 47.54465866088867\n",
      "Episode average V value: -357.0483082135518\n",
      "Average (on the epoch) training loss: 45.91024398803711\n",
      "Episode average V value: 12.501748959223429\n",
      "Average (on the epoch) training loss: 47.039676666259766\n",
      "Episode average V value: 26.26798439025879\n",
      "Average (on the epoch) training loss: 45.479286193847656\n",
      "Episode average V value: 15.026876866817474\n",
      "Average (on the epoch) training loss: 44.09615707397461\n",
      "Episode average V value: 25.551856821233574\n",
      "Average (on the epoch) training loss: 42.831451416015625\n",
      "Episode average V value: 22.208002885182697\n",
      "Average (on the epoch) training loss: 42.3282470703125\n",
      "Episode average V value: 31.540372848510742\n",
      "Average (on the epoch) training loss: 42.14980697631836\n",
      "Episode average V value: 27.977354049682617\n",
      "Average (on the epoch) training loss: 41.20382308959961\n",
      "Episode average V value: 22.87322207291921\n",
      "Average (on the epoch) training loss: 40.9916877746582\n",
      "Episode average V value: 25.583677291870117\n",
      "Average (on the epoch) training loss: 40.273311614990234\n",
      "Episode average V value: 25.310050010681152\n",
      "Average (on the epoch) training loss: 40.14853286743164\n",
      "Episode average V value: 24.576021591822307\n",
      "Average (on the epoch) training loss: 42.74376678466797\n",
      "Episode average V value: 29.01041603088379\n",
      "Average (on the epoch) training loss: 42.37018585205078\n",
      "Episode average V value: 10.188557227452597\n",
      "Average (on the epoch) training loss: 41.58298110961914\n",
      "Episode average V value: 13.985053221384684\n",
      "Average (on the epoch) training loss: 42.90192794799805\n",
      "Episode average V value: 25.566383361816406\n",
      "Average (on the epoch) training loss: 43.19407272338867\n",
      "Episode average V value: 19.89357038338979\n",
      "Average (on the epoch) training loss: 42.469390869140625\n",
      "Episode average V value: 13.222099304199219\n",
      "Average (on the epoch) training loss: 42.005523681640625\n",
      "Episode average V value: 33.75716781616211\n",
      "Average (on the epoch) training loss: 41.88642883300781\n",
      "Episode average V value: -438.93232957522076\n",
      "Average (on the epoch) training loss: 41.440330505371094\n",
      "Episode average V value: 25.691839059193928\n",
      "Average (on the epoch) training loss: 42.12978744506836\n",
      "Episode average V value: 21.647083918253582\n",
      "Average (on the epoch) training loss: 41.720726013183594\n",
      "Episode average V value: 16.001067956288654\n",
      "Average (on the epoch) training loss: 41.13800811767578\n",
      "Episode average V value: 21.48041756947835\n",
      "Average (on the epoch) training loss: 40.87187194824219\n",
      "Episode average V value: 25.715749899546307\n",
      "Average (on the epoch) training loss: 41.593536376953125\n",
      "Episode average V value: 24.625709533691406\n",
      "Average (on the epoch) training loss: 41.009254455566406\n",
      "Episode average V value: 20.758982102076214\n",
      "Average (on the epoch) training loss: 41.35063934326172\n",
      "Episode average V value: 24.25788116455078\n",
      "Average (on the epoch) training loss: 42.62125778198242\n",
      "Episode average V value: 21.44563865661621\n",
      "Average (on the epoch) training loss: 42.03995895385742\n",
      "Episode average V value: 15.954421043395996\n",
      "Average (on the epoch) training loss: 42.19831466674805\n",
      "Episode average V value: 28.804545879364014\n",
      "Average (on the epoch) training loss: 42.36399459838867\n",
      "Episode average V value: 22.038103103637695\n",
      "Average (on the epoch) training loss: 42.00232696533203\n",
      "Episode average V value: 17.742599149545033\n",
      "Average (on the epoch) training loss: 41.905147552490234\n",
      "Episode average V value: 22.70060227134011\n",
      "Average (on the epoch) training loss: 42.52922058105469\n",
      "Episode average V value: 21.075393120447796\n",
      "Average (on the epoch) training loss: 43.77195739746094\n",
      "Episode average V value: 28.86515235900879\n",
      "Average (on the epoch) training loss: 43.55837631225586\n",
      "Episode average V value: 21.592674255371094\n",
      "Average (on the epoch) training loss: 43.02886962890625\n",
      "Episode average V value: 23.498001098632812\n",
      "Average (on the epoch) training loss: 44.706336975097656\n",
      "Episode average V value: 37.413861989974976\n",
      "Average (on the epoch) training loss: 44.36682891845703\n",
      "Episode average V value: 17.795719146728516\n",
      "Average (on the epoch) training loss: 44.89896011352539\n",
      "Episode average V value: 10.191456000010172\n",
      "Average (on the epoch) training loss: 45.129661560058594\n",
      "Episode average V value: 23.16827376683553\n",
      "Average (on the epoch) training loss: 44.694053649902344\n",
      "Episode average V value: 25.53812845547994\n",
      "Average (on the epoch) training loss: 44.29478454589844\n",
      "Episode average V value: 23.931488227844238\n",
      "Average (on the epoch) training loss: 44.197994232177734\n",
      "Episode average V value: 22.92754329334606\n",
      "Average (on the epoch) training loss: 43.93788528442383\n",
      "Episode average V value: 24.105565706888836\n",
      "Average (on the epoch) training loss: 43.627750396728516\n",
      "Episode average V value: 33.44943618774414\n",
      "Average (on the epoch) training loss: 43.20882034301758\n",
      "Episode average V value: 16.01791884501775\n",
      "Average (on the epoch) training loss: 43.81370162963867\n",
      "Episode average V value: 24.95232794682185\n",
      "Average (on the epoch) training loss: 44.104557037353516\n",
      "Episode average V value: 19.713933771306817\n",
      "Average (on the epoch) training loss: 43.76607894897461\n",
      "Episode average V value: 14.173645079135895\n",
      "Average (on the epoch) training loss: 43.5796012878418\n",
      "Episode average V value: 22.0574893951416\n",
      "Average (on the epoch) training loss: 43.19168472290039\n",
      "Episode average V value: 24.854554653167725\n",
      "Average (on the epoch) training loss: 43.654754638671875\n",
      "Episode average V value: 25.923995971679688\n",
      "Average (on the epoch) training loss: 43.5152587890625\n",
      "Episode average V value: 21.559059286117552\n",
      "Average (on the epoch) training loss: 43.22755432128906\n",
      "Episode average V value: 18.65484619140625\n",
      "Average (on the epoch) training loss: 43.02119064331055\n",
      "Episode average V value: 27.23303985595703\n",
      "Average (on the epoch) training loss: 42.74541473388672\n",
      "Episode average V value: 28.218477249145508\n",
      "Average (on the epoch) training loss: 42.54278564453125\n",
      "Episode average V value: 27.081516981124878\n",
      "Average (on the epoch) training loss: 42.89761734008789\n",
      "Episode average V value: 23.27479362487793\n",
      "Average (on the epoch) training loss: 42.6760368347168\n",
      "Episode average V value: 16.55804991722107\n",
      "Average (on the epoch) training loss: 42.49029541015625\n",
      "Episode average V value: 21.449900887229226\n",
      "Average (on the epoch) training loss: 42.24964904785156\n",
      "Episode average V value: 20.87852907180786\n",
      "Average (on the epoch) training loss: 43.16942596435547\n",
      "Episode average V value: 17.558415174484253\n",
      "Average (on the epoch) training loss: 43.063926696777344\n",
      "Episode average V value: 18.450635353724163\n",
      "Average (on the epoch) training loss: 42.79306411743164\n",
      "Episode average V value: 22.415067672729492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average (on the epoch) training loss: 42.72103500366211\n",
      "Episode average V value: 22.0566463470459\n",
      "Average (on the epoch) training loss: 43.214359283447266\n",
      "Episode average V value: 19.05458554354581\n",
      "Average (on the epoch) training loss: 43.59043884277344\n",
      "Episode average V value: 16.083146413167317\n",
      "Average (on the epoch) training loss: 43.809913635253906\n",
      "Episode average V value: 19.73652712504069\n",
      "Average (on the epoch) training loss: 43.76011276245117\n",
      "Episode average V value: 21.94398359818892\n",
      "Average (on the epoch) training loss: 44.1307258605957\n",
      "Episode average V value: 19.32749040921529\n",
      "Average (on the epoch) training loss: 44.56980895996094\n",
      "Episode average V value: 28.13748654452237\n",
      "Average (on the epoch) training loss: 44.32625961303711\n",
      "Episode average V value: 15.901372035344442\n",
      "Average (on the epoch) training loss: 44.04007339477539\n",
      "Episode average V value: 15.832846959431967\n",
      "Average (on the epoch) training loss: 43.74894332885742\n",
      "Episode average V value: 20.739064931869507\n",
      "Average (on the epoch) training loss: 43.752220153808594\n",
      "Episode average V value: 12.854687387293035\n",
      "Average (on the epoch) training loss: 43.43444061279297\n",
      "Episode average V value: 19.597650137814608\n",
      "Average (on the epoch) training loss: 43.88877868652344\n",
      "Episode average V value: 23.1336190700531\n",
      "Average (on the epoch) training loss: 43.540733337402344\n",
      "Episode average V value: 15.109997034072876\n",
      "Average (on the epoch) training loss: 43.599422454833984\n",
      "Episode average V value: 28.7638676961263\n",
      "Average (on the epoch) training loss: 43.33852767944336\n",
      "Episode average V value: 19.224491141059183\n",
      "Average (on the epoch) training loss: 43.55882263183594\n",
      "Episode average V value: 26.595369338989258\n",
      "Average (on the epoch) training loss: 43.91776657104492\n",
      "Episode average V value: 20.176185131072998\n",
      "Average (on the epoch) training loss: 43.60143280029297\n",
      "Episode average V value: 11.597271064917246\n",
      "epoch 36:\n",
      "Learning rate: 0.005\n",
      "Discount factor: 0.9\n",
      "Epsilon: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Train agent\n",
    "agent.run(n_epochs=40, epoch_length=numberSamples_trainAgent*T_trainAgent)\n",
    "print('Agent Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate test data\n",
    "numberSamples_test=10\n",
    "T_test=T\n",
    "(objectives_test,measurements_test)=estimator.generateSequence(T_test,numberSamples=numberSamples_test)\n",
    "\n",
    "# Results of the inference on test data\n",
    "(sigmas_test,rewards_test,estimates_test)=agentInference(agent,objectives_test,measurements_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sample=0\n",
    "plotErrors(objectives_test,estimates_test,sigmas_test,idx_sample=idx_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
